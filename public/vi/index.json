[
{
	"uri": "//localhost:1313/vi/",
	"title": "Báo cáo thực tập",
	"tags": [],
	"description": "",
	"content": "Báo cáo thực tập Thông tin sinh viên: Họ và tên: Nguyễn Trí Dũng\nSố điện thoại: 032 986 2337\nEmail: nt.dung1297@gmail.com\nTrường: Đại học FPT TP.Hồ Chí Minh\nNgành: Trí tuệ nhân tạo\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 08/09/2025 đến ngày 00/12/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "
},
{
	"uri": "//localhost:1313/vi/5-workshop/5.4-s3-onprem/5.4.1-prepare/",
	"title": "Chuẩn bị tài nguyên",
	"tags": [],
	"description": "",
	"content": "Để chuẩn bị cho phần này của workshop, bạn sẽ cần phải:\nTriển khai CloudFormation stack Sửa đổi bảng định tuyến VPC. Các thành phần này hoạt động cùng nhau để mô phỏng DNS forwarding và name resolution.\nTriển khai CloudFormation stack Mẫu CloudFormation sẽ tạo các dịch vụ bổ sung để hỗ trợ mô phỏng môi trường truyền thống:\nMột Route 53 Private Hosted Zone lưu trữ các bản ghi Bí danh (Alias records) cho điểm cuối PrivateLink S3 Một Route 53 Inbound Resolver endpoint cho phép \u0026ldquo;VPC Cloud\u0026rdquo; giải quyết các yêu cầu resolve DNS gửi đến Private Hosted Zone Một Route 53 Outbound Resolver endpoint cho phép \u0026ldquo;VPC On-prem\u0026rdquo; chuyển tiếp các yêu cầu DNS cho S3 sang \u0026ldquo;VPC Cloud\u0026rdquo; Click link sau để mở AWS CloudFormation console. Mẫu yêu cầu sẽ được tải sẵn vào menu. Chấp nhận tất cả mặc định và nhấp vào Tạo stack. Có thể mất vài phút để triển khai stack hoàn tất. Bạn có thể tiếp tục với bước tiếp theo mà không cần đợi quá trình triển khai kết thúc.\nCập nhật bảng định tuyến private on-premise Workshop này sử dụng StrongSwan VPN chạy trên EC2 instance để mô phỏng khả năng kết nối giữa trung tâm dữ liệu truyền thống và môi trường cloud AWS. Hầu hết các thành phần bắt buộc đều được cung cấp trước khi bạn bắt đầu. Để hoàn tất cấu hình VPN, bạn sẽ sửa đổi bảng định tuyến \u0026ldquo;VPC on-prem\u0026rdquo; để hướng lưu lượng đến cloud đi qua StrongSwan VPN instance.\nMở Amazon EC2 console\nChọn instance tên infra-vpngw-test. Từ Details tab, copy Instance ID và paste vào text editor của bạn để sử dụng ở những bước tiếp theo\nĐi đến VPC menu bằng cách gõ \u0026ldquo;VPC\u0026rdquo; vào Search box\nClick vào Route Tables, chọn RT Private On-prem route table, chọn Routes tab, và click Edit Routes.\nClick Add route. Destination: CIDR block của Cloud VPC Target: ID của infra-vpngw-test instance (bạn đã lưu lại ở bước trên) Click Save changes "
},
{
	"uri": "//localhost:1313/vi/5-workshop/5.1-workshop-overview/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": "Giới thiệu về VPC Endpoint Điểm cuối VPC (endpoint) là thiết bị ảo. Chúng là các thành phần VPC có thể mở rộng theo chiều ngang, dự phòng và có tính sẵn sàng cao. Chúng cho phép giao tiếp giữa tài nguyên điện toán của bạn và dịch vụ AWS mà không gây ra rủi ro về tính sẵn sàng. Tài nguyên điện toán đang chạy trong VPC có thể truy cập Amazon S3 bằng cách sử dụng điểm cuối Gateway. Interface Endpoint PrivateLink có thể được sử dụng bởi tài nguyên chạy trong VPC hoặc tại TTDL. Tổng quan về workshop Trong workshop này, bạn sẽ sử dụng hai VPC.\n\u0026ldquo;VPC Cloud\u0026rdquo; dành cho các tài nguyên cloud như Gateway endpoint và EC2 instance để kiểm tra. \u0026ldquo;VPC On-Prem\u0026rdquo; mô phỏng môi trường truyền thống như nhà máy hoặc trung tâm dữ liệu của công ty. Một EC2 Instance chạy phần mềm StrongSwan VPN đã được triển khai trong \u0026ldquo;VPC On-prem\u0026rdquo; và được cấu hình tự động để thiết lập đường hầm VPN Site-to-Site với AWS Transit Gateway. VPN này mô phỏng kết nối từ một vị trí tại TTDL (on-prem) với AWS cloud. Để giảm thiểu chi phí, chỉ một phiên bản VPN được cung cấp để hỗ trợ workshop này. Khi lập kế hoạch kết nối VPN cho production workloads của bạn, AWS khuyên bạn nên sử dụng nhiều thiết bị VPN để có tính sẵn sàng cao. "
},
{
	"uri": "//localhost:1313/vi/3-blogstranslated/3.1-blog1/",
	"title": "Lớp truy cập hợp nhất đa phương thức cho Poe của Quora sử dụng Amazon Bedrock",
	"tags": [],
	"description": "",
	"content": "Tác giả: Gilbert V. Lepadatu và Nick Huber | Ngày đăng: 16/09/2025 | Danh mục: Amazon Bedrock, Customer Solutions, Foundation models, Generative AI\nCác tổ chức đang tìm kiếm lợi thế cạnh tranh bằng cách triển khai và tích hợp nhanh chóng các mô hình trí tuệ nhân tạo sinh (Generative AI) thông qua kiến trúc Generative AI Gateway. Cách tiếp cận với giao diện hợp nhất này giúp đơn giản hóa việc truy cập vào nhiều mô hình nền tảng (foundation models – FMs), giải quyết một thách thức quan trọng: sự bùng nổ của các mô hình AI chuyên biệt, mỗi mô hình có khả năng, API và yêu cầu vận hành riêng biệt. Thay vì phải xây dựng và duy trì nhiều điểm tích hợp riêng lẻ cho từng mô hình, giải pháp thông minh là tạo ra một lớp trừu tượng (abstraction layer) để chuẩn hóa các khác biệt này đằng sau một API thống nhất và nhất quán.\nTrung tâm Đổi mới Generative AI của AWS (AWS Generative AI Innovation Center) và Quora gần đây đã hợp tác để phát triển một giải pháp sáng tạo nhằm giải quyết chính thách thức này. Hai bên đã xây dựng một khung API bao bọc hợp nhất (unified wrapper API framework) giúp tăng tốc triển khai các mô hình nền tảng của Amazon Bedrock trên hệ thống Poe của Quora. Kiến trúc này mang lại khả năng “xây dựng một lần, triển khai nhiều mô hình” (build once, deploy multiple models), giúp rút ngắn đáng kể thời gian triển khai và công sức kỹ thuật, với mã cầu nối giao thức thực tế được thể hiện xuyên suốt trong mã nguồn.\nĐối với các nhà lãnh đạo công nghệ và nhà phát triển đang làm việc với triển khai nhiều mô hình AI ở quy mô lớn, khung này minh chứng cho cách thiết kế trừu tượng thông minh và dịch giao thức (protocol translation) có thể tăng tốc chu kỳ đổi mới trong khi vẫn duy trì kiểm soát vận hành.\nTrong bài viết này, chúng tôi sẽ trình bày chi tiết về cách AWS Generative AI Innovation Center và Quora hợp tác để xây dựng một khung API bao bọc hợp nhất, giúp tăng tốc đáng kể việc triển khai các mô hình nền tảng của Amazon Bedrock trên hệ thống Poe. Chúng tôi cũng sẽ phân tích kiến trúc kỹ thuật giúp kết nối giao thức ServerSentEvents theo hướng sự kiện của Poe với API REST của Amazon Bedrock, trình bày cách hệ thống cấu hình theo mẫu (template-based) giúp rút ngắn thời gian triển khai từ vài ngày xuống còn 15 phút, và chia sẻ các mẫu triển khai cho việc dịch giao thức, xử lý lỗi và hỗ trợ đa phương thức. Cách tiếp cận “xây dựng một lần, triển khai nhiều mô hình” này đã giúp Poe tích hợp hơn 30 mô hình Amazon Bedrock bao gồm văn bản, hình ảnh và video, đồng thời giảm tới 95% lượng thay đổi mã nguồn cần thiết.\nQuora và Amazon Bedrock Poe.com là một hệ thống trí tuệ nhân tạo (AI) do Quora phát triển, cho phép người dùng và các nhà phát triển tương tác với một loạt các mô hình AI và trợ lý tiên tiến đến từ nhiều nhà cung cấp khác nhau. Hệ thống này hỗ trợ truy cập đa mô hình (multi-model access), cho phép người dùng trò chuyện song song với nhiều chatbot AI, phục vụ cho các tác vụ như hiểu ngôn ngữ tự nhiên, tạo nội dung, tạo hình ảnh, và nhiều ứng dụng khác.\nẢnh chụp màn hình dưới đây minh họa giao diện người dùng (UI) của Poe, nền tảng AI được Quora phát triển. Hình ảnh thể hiện thư viện phong phú các mô hình AI của Poe, được trình bày dưới dạng các “chatbot” riêng biệt mà người dùng có thể lựa chọn để tương tác.\nHình minh họa 1: Giao diện thư viện mô hình AI của Poe\nẢnh chụp tiếp theo cung cấp cái nhìn về “Model Catalog” trong Amazon Bedrock, một dịch vụ được quản lý toàn phần (fully managed) của Amazon Web Services (AWS). Danh mục này hoạt động như một trung tâm tập trung, giúp các nhà phát triển khám phá, đánh giá và truy cập các mô hình AI nền tảng (Foundation Models – FMs) tiên tiến đến từ nhiều nhà cung cấp khác nhau.\nHình minh họa 2: Giao diện danh mục mô hình (Model Catalog) trong Amazon Bedrock\nBan đầu, việc tích hợp các mô hình nền tảng đa dạng có sẵn trong Amazon Bedrock đã đặt ra nhiều thách thức kỹ thuật lớn đối với nhóm phát triển của Poe.com. Quá trình này đòi hỏi nguồn lực kỹ thuật đáng kể để thiết lập kết nối với từng mô hình riêng lẻ, đồng thời duy trì hiệu năng và độ tin cậy nhất quán giữa các mô hình. Tính dễ bảo trì (maintainability) cũng nhanh chóng trở thành một yếu tố then chốt, cùng với khả năng tích hợp nhanh các mô hình mới khi chúng được phát hành — hai yếu tố này làm tăng đáng kể độ phức tạp của quá trình tích hợp.\nThách thức kỹ thuật: Kết nối các hệ thống khác nhau Việc tích hợp giữa Poe và Amazon Bedrock đã đặt ra những thách thức kiến trúc cơ bản, đòi hỏi các giải pháp sáng tạo.\nHai hệ thống này được xây dựng dựa trên triết lý thiết kế và mô hình giao tiếp hoàn toàn khác nhau, tạo nên một khoảng cách kỹ thuật lớn mà API bao bọc (wrapper API) phải đóng vai trò cầu nối để giải quyết.\nSự khác biệt về kiến trúc Thách thức cốt lõi nằm ở sự khác biệt về kiến trúc giữa hai hệ thống. Việc hiểu rõ những khác biệt này là điều cần thiết để đánh giá mức độ phức tạp của giải pháp tích hợp. Poe vận hành dựa trên kiến trúc hiện đại, phản ứng thời gian thực (reactive architecture), sử dụng giao thức ServerSentEvents (SSE) thông qua thư viện FastAPI (fastapi_poe). Kiến trúc này được tối ưu hóa cho các tương tác thời gian thực (stream-optimized), hoạt động theo mô hình phản hồi dựa trên sự kiện (event-driven response model), được thiết kế để hỗ trợ AI hội thoại liên tục (conversational AI). Amazon Bedrock, ngược lại, hoạt động như một dịch vụ đám mây doanh nghiệp (enterprise cloud service). Nó cung cấp giao diện REST với mẫu truy cập qua AWS SDK, yêu cầu chứng thực SigV4, có phạm vi mô hình giới hạn theo vùng AWS Region, và sử dụng mô hình yêu cầu–phản hồi (request–response) truyền thống, có hỗ trợ streaming. Sự không tương thích giữa các API này tạo ra nhiều thách thức kỹ thuật mà wrapper API của Poe phải xử lý, được tóm tắt trong bảng dưới đây.\nBảng: Các thách thức tích hợp giữa Poe và Amazon Bedrock Danh mục thách thức Vấn đề kỹ thuật Giao thức nguồn (Source) Giao thức đích (Target) Độ phức tạp tích hợp Dịch giao thức (Protocol Translation) Chuyển đổi giữa giao thức dựa trên WebSocket và API REST WebSocket (hai chiều, duy trì kết nối) REST (yêu cầu/đáp ứng, phi trạng thái) Cao – yêu cầu xây dựng cầu nối giao thức Liên kết xác thực (Authentication Bridging) Kết nối xác thực JWT với cơ chế ký AWS SigV4 Xác thực bằng token JWT Xác thực AWS SigV4 Trung bình – cần chuyển đổi thông tin xác thực Chuyển đổi định dạng phản hồi (Response Format Transformation) Chuyển đổi dữ liệu JSON sang định dạng yêu cầu JSON tiêu chuẩn Định dạng tùy chỉnh Trung bình – cần ánh xạ cấu trúc dữ liệu Đồng bộ hóa luồng dữ liệu (Streaming Reconciliation) Chuyển đổi phản hồi phân mảnh (chunked responses) sang luồng SSE Phản hồi HTTP dạng phân mảnh Luồng ServerSentEvents Cao – yêu cầu chuyển đổi luồng dữ liệu thời gian thực Chuẩn hóa tham số (Parameter Standardization) Tạo không gian tham số thống nhất cho nhiều mô hình khác nhau Tham số riêng của từng mô hình Giao diện tham số chuẩn hóa Trung bình – cần chuẩn hóa cấu trúc tham số Tiến hóa của API và Converse API Vào tháng 5 năm 2024, Amazon Bedrock giới thiệu Converse API, mang lại nhiều lợi ích về chuẩn hóa, giúp đơn giản hóa đáng kể kiến trúc tích hợp. Các điểm nổi bật của Converse API bao gồm:\nGiao diện thống nhất cho nhiều nhà cung cấp mô hình khác nhau (như Anthropic, Meta, Mistral, v.v.). Bộ nhớ hội thoại (conversation memory) với khả năng xử lý lịch sử trò chuyện một cách thống nhất. Hỗ trợ cả chế độ streaming và non-streaming trong cùng một mô hình API duy nhất. Hỗ trợ đa phương thức (multimodal) cho văn bản, hình ảnh và dữ liệu có cấu trúc. Chuẩn hóa tham số (parameter normalization), giảm thiểu sự khác biệt trong cách triển khai của từng mô hình. Tích hợp sẵn tính năng kiểm duyệt nội dung (built-in content moderation). Giải pháp được trình bày trong bài viết này sử dụng Converse API khi phù hợp, đồng thời duy trì khả năng tương thích với các API riêng biệt của từng mô hình để khai thác các năng lực chuyên biệt. Cách tiếp cận lai (hybrid approach) này mang lại sự linh hoạt cao, đồng thời tận dụng tối đa lợi ích chuẩn hóa của Converse API.\nTổng quan giải pháp Framework API bao bọc (wrapper API framework) cung cấp một giao diện thống nhất (unified interface) giữa Poe và các mô hình trong Amazon Bedrock.\nNó hoạt động như một lớp dịch (translation layer) giúp chuẩn hóa các khác biệt giữa các mô hình và giao thức, đồng thời vẫn giữ nguyên các khả năng riêng biệt (unique capabilities) của từng mô hình AI.\nGiải pháp được thiết kế dựa trên kiến trúc mô-đun (modular design), tách biệt rõ các chức năng độc lập (separation of concerns) và cho phép mở rộng linh hoạt (flexible scaling), như được minh họa trong sơ đồ dưới đây.\nHình minh họa 3: Kiến trúc tổng thể của framework Wrapper API giữa Poe và Amazon Bedrock\nGiải pháp wrapper API bao gồm nhiều thành phần chính, hoạt động phối hợp để mang lại trải nghiệm tích hợp liền mạch (seamless integration experience):\nClient: Đây là điểm đầu vào (entry point) nơi người dùng tương tác với các khả năng AI thông qua nhiều giao diện khác nhau (trình duyệt web, ứng dụng di động, API…). Lớp Poe bao gồm: Poe UI: Chịu trách nhiệm về trải nghiệm người dùng (user experience), bao gồm việc tạo yêu cầu (request formation), quản lý tham số (parameter control), xử lý tải tệp (file uploads), và hiển thị phản hồi từ AI (response visualization). Poe FastAPI: Chuẩn hóa các tương tác của người dùng, đồng thời quản lý giao tiếp giữa client và các hệ thống nền tảng. Đây là lớp trung gian xử lý giao thức (protocol management layer), giúp duy trì tính nhất quán trong quá trình truyền tải dữ liệu và phản hồi. Bot Factory: Đây là một cơ chế “nhà máy mô hình” (factory pattern), có nhiệm vụ tạo động (dynamically create) các bộ xử lý mô hình (model handlers) phù hợp với loại mô hình được yêu cầu — ví dụ: chat model (mô hình hội thoại), image model (mô hình tạo hình ảnh), video model (mô hình xử lý video).\nCấu trúc này cho phép hệ thống dễ dàng mở rộng (extensible) để hỗ trợ các loại mô hình mới hoặc biến thể khác nhau của mô hình hiện có trong tương lai. Dưới đây là một đoạn mã minh họa cách hoạt động của Bot Factory, thể hiện cách lựa chọn mô hình phù hợp dựa trên loại yêu cầu của người dùng:\n#From core/bot_factory.py - Actual implementation class BotFactory: \u0026quot;\u0026quot;\u0026quot; Factory for creating different types of bots. Handles bot creation based on the bot type and configuration. \u0026quot;\u0026quot;\u0026quot; @staticmethod def create_bot(bot_config: BotConfig) -\u0026gt; PoeBot: # Check if a custom bot class is specified if hasattr(bot_config, 'bot_class') and bot_config.bot_class: # Use the custom bot class directly bot = bot_config.bot_class(bot_config) # Explicitly ensure we're returning a PoeBot if not isinstance(bot, PoeBot): raise TypeError(f\u0026quot;Custom bot class must return a PoeBot instance, got {type(bot)}\u0026quot;) return bot # Determine bot type based on configuration if hasattr(bot_config, 'enable_video_generation') and bot_config.enable_video_generation: # Video generation bot if 'luma' in bot_config.bot_name: from core.refactored_luma_bot import LumaVideoBot return LumaVideoBot(bot_config) else: from core.refactored_nova_reel_bot import NovaReelVideoBot return NovaReelVideoBot(bot_config) elif hasattr(bot_config, 'enable_image_generation') and bot_config.enable_image_generation: # Image generation bot if hasattr(bot_config, 'model_id') and \u0026quot;stability\u0026quot; in bot_config.model_id.lower(): # Stability AI image generation bot from core.refactored_image_stability_ai import AmazonBedrockImageStabilityAIBot return AmazonBedrockImageStabilityAIBot(bot_config) else: # Other image generation bot (Titan, Canvas, etc.) from core.refactored_image_bot_amazon import RefactoredAmazonImageGenerationBot return RefactoredAmazonImageGenerationBot(bot_config) else: # Check if this is a Claude 3.7 model if hasattr(bot_config, 'model_id') and \u0026quot;claude-3-7\u0026quot; in bot_config.model_id.lower(): return ClaudePlusBot(bot_config) else: # Default to standard chat bot return RefactoredAmazonBedrockPoeBot(bot_config) Service manager: Điều phối các dịch vụ cần thiết để xử lý yêu cầu một cách hiệu quả. Nó phối hợp giữa các dịch vụ chuyên biệt, bao gồm: Token services – Quản lý giới hạn token và theo dõi số lượng token sử dụng. Streaming services – Xử lý phản hồi thời gian thực. Error services – Chuẩn hóa và xử lý lỗi. AWS service integration – Quản lý các cuộc gọi API đến Amazon Bedrock. AWS services component – Chuyển đổi phản hồi từ định dạng của Amazon Bedrock sang định dạng mà Poe mong đợi và ngược lại; xử lý các gói dữ liệu dạng streaming, hình ảnh và video. Amazon Bedrock layer – Lớp dịch vụ mô hình nền tảng (FM) của Amazon, cung cấp khả năng xử lý AI thực tế và lưu trữ mô hình, bao gồm: Model diversity – Cung cấp quyền truy cập hơn 30 mô hình văn bản (như Amazon Titan, Amazon Nova, Claude của Anthropic, Llama của Meta, Mistral, v.v.), cũng như các mô hình hình ảnh và video. API structure – Hỗ trợ cả API riêng của từng mô hình và API hợp nhất Converse. Authentication – Yêu cầu xác thực AWS SigV4 để đảm bảo truy cập an toàn đến các điểm cuối của mô hình. Response management – Trả về kết quả mô hình kèm theo siêu dữ liệu và thống kê mức sử dụng được chuẩn hóa. Luồng xử lý yêu cầu (Request processing flow) trong API hợp nhất này minh họa quá trình điều phối phức tạp khi kết nối giao thức ServerSentEvents (hướng sự kiện) của Poe với API REST của Amazon Bedrock, cho thấy nhiều dịch vụ chuyên biệt phối hợp nhịp nhàng để mang lại trải nghiệm người dùng liền mạch.\nQuy trình bắt đầu khi client gửi yêu cầu thông qua giao diện Poe, sau đó yêu cầu được chuyển đến thành phần Bot Factory. Mẫu thiết kế factory pattern này tạo động (dynamically) trình xử lý mô hình phù hợp dựa trên loại mô hình được yêu cầu — có thể là chat, image, hoặc video generation. Tiếp đó, Service Manager sẽ điều phối các dịch vụ chuyên biệt cần thiết để xử lý yêu cầu một cách hiệu quả, bao gồm quản lý token, xử lý streaming và quản lý lỗi.\nSơ đồ tuần tự dưới đây thể hiện toàn bộ luồng xử lý yêu cầu\nMẫu cấu hình cho triển khai nhanh nhiều bot Điểm mạnh nhất của wrapper API nằm ở hệ thống mẫu cấu hình hợp nhất (unified configuration template system), cho phép triển khai và quản lý nhiều bot nhanh chóng với rất ít thay đổi trong mã nguồn. Cách tiếp cận này là trọng tâm trong thành công của giải pháp khi giúp rút ngắn đáng kể thời gian triển khai.\nHệ thống này sử dụng phương pháp cấu hình dựa trên mẫu (template-based configuration approach), trong đó kết hợp giữa các giá trị mặc định dùng chung (shared defaults) và các giá trị ghi đè riêng cho từng mô hình (model-specific overrides).\n# Bot configurations using the template pattern CHAT_BOTS = { 'poe-nova-micro': BotConfig( # Identity bot_name='poe-nova-micro', model_id='amazon.nova-micro-v1:0', aws_region=aws_config['region'], poe_access_key='XXXXXXXXXXXXXXXXXXXXXX', # Model-specific parameters supports_system_messages=True, enable_image_comprehension=True, expand_text_attachments=True, streaming=True, max_tokens=1300, temperature=0.7, top_p=0.9, # Model-specific pricing enable_monetization=True, pricing_type=\u0026quot;variable\u0026quot;, input_token_cost_milli_cents=2, output_token_cost_milli_cents=4, image_analysis_cost_milli_cents=25, # Generate rate card with model-specific values custom_rate_card=create_rate_card(2, 4, 25), # Include common parameters **DEFAULT_CHAT_CONFIG ), 'poe-mistral-pixtral': BotConfig( # Identity bot_name='poe-mistral-pixtral', model_id='us.mistral.pixtral-large-2502-v1:0', aws_region=aws_config['region'], poe_access_key='XXXXXXXXXXXXXXXXXXXXXX', # Model-specific parameters supports_system_messages=False, enable_image_comprehension=False, # ... # Include common parameters **DEFAULT_CHAT_CONFIG ) } Kiến trúc dựa trên cấu hình này mang lại nhiều lợi ích đáng kể, bao gồm:\nTriển khai nhanh – Việc thêm mô hình mới chỉ cần tạo một mục cấu hình mới thay vì phải viết lại mã tích hợp. Đây là yếu tố then chốt giúp cải thiện đáng kể thời gian triển khai. Quản lý tham số nhất quán – Các tham số dùng chung được định nghĩa một lần trong DEFAULT_CHAT_CONFIG và kế thừa tự động bởi các bot, đảm bảo tính nhất quán và giảm trùng lặp cấu hình. Tùy chỉnh theo mô hình – Mỗi mô hình có thể có thiết lập riêng biệt, nhưng vẫn hưởng lợi từ hạ tầng cấu hình chung. Linh hoạt trong vận hành – Các tham số có thể được điều chỉnh mà không cần thay đổi mã nguồn, giúp thử nghiệm và tối ưu hóa nhanh chóng. Quản lý thông tin xác thực tập trung – Thông tin xác thực AWS được quản lý tập trung tại một nơi duy nhất, giúp tăng cường bảo mật và đơn giản hóa việc cập nhật. Triển khai theo vùng – Các mô hình có thể được triển khai linh hoạt đến nhiều vùng AWS khác nhau, với các thiết lập vùng (Region settings) được kiểm soát trực tiếp tại cấp cấu hình. Lớp BotConfig cung cấp một cách có cấu trúc (structured way) để định nghĩa cấu hình cho các bot, đồng thời hỗ trợ xác thực kiểu dữ liệu (type validation) trong quá trình triển khai:\n# From config/bot_config.py - Actual implementation (partial) class BotConfig(BaseModel): # Core Bot Identity bot_name: str = Field(..., description=\u0026quot;Name of the bot\u0026quot;) model_id: str = Field(..., description=\u0026quot;Identifier for the AI model\u0026quot;) # AWS Configuration aws_region: Optional[str] = Field(default=\u0026quot;us-east-1\u0026quot;, description=\u0026quot;AWS region for deployment\u0026quot;) aws_access_key: Optional[str] = Field(default=None, description=\u0026quot;AWS access key\u0026quot;) aws_secret_key: Optional[str] = Field(default=None, description=\u0026quot;AWS secret key\u0026quot;) aws_security_token: Optional[str] = None # Poe Configuration poe_access_key: str = Field(..., description=\u0026quot;Poe access key\u0026quot;) modal_app_name: str = Field(..., description=\u0026quot;Modal app name\u0026quot;) # Capability Flags allow_attachments: bool = Field(default=True, description=\u0026quot;Whether to allow file attachments in Poe\u0026quot;) supports_system_messages: bool = Field(default=False) enable_image_comprehension: bool = Field(default=False) expand_text_attachments: bool = Field(default=False) streaming: bool = Field(default=False) enable_image_generation: bool = Field(default=False) enable_video_generation: bool = Field(default=False) # Inference Configuration max_tokens: Optional[int] = Field(default=None, description=\u0026quot;Maximum number of tokens to generate\u0026quot;) temperature: Optional[float] = Field(default=None, description=\u0026quot;Temperature for sampling\u0026quot;) top_p: Optional[float] = Field(default=None, description=\u0026quot;Top-p sampling parameter\u0026quot;) optimize_latency: bool = Field(default=False, description=\u0026quot;Enable latency optimization with performanceConfig\u0026quot;) # Reasoning Configuration (Claude 3.7+) enable_reasoning: bool = Field(default=False, description=\u0026quot;Enable Claude's reasoning capability\u0026quot;) reasoning_budget: Optional[int] = Field(default=1024, description=\u0026quot;Token budget for reasoning (1024-4000 recommended)\u0026quot;) # Monetization Configuration enable_monetization: bool = Field(default=False, description=\u0026quot;Enable variable pricing monetization\u0026quot;) custom_rate_card: Optional[str] = Field( default=None, description=\u0026quot;Custom rate card for variable pricing in markdown format\u0026quot; ) input_token_cost_milli_cents: Optional[int] = Field( default=None, description=\u0026quot;Cost per input token in thousandths of a cent\u0026quot; ) output_token_cost_milli_cents: Optional[int] = Field( default=None, description=\u0026quot;Cost per output token in thousandths of a cent\u0026quot; ) image_analysis_cost_milli_cents: Optional[int] = Field( default=None, description=\u0026quot;Cost per image analysis in thousandths of a cent\u0026quot; ) Khả năng đa phương thức nâng cao Một trong những điểm mạnh nhất của framework này là cách nó xử lý khả năng đa phương thức (multimodal) thông qua các cờ cấu hình đơn giản (simple configuration flags):\nenable_image_comprehension – Khi được đặt thành True đối với các mô hình chỉ xử lý văn bản (text-only) như Amazon Nova Micro, Poe tự sử dụng khả năng thị giác (vision capabilities) của mình để phân tích hình ảnh và chuyển đổi chúng thành mô tả văn bản, sau đó gửi các mô tả này đến mô hình của Amazon Bedrock.\nCơ chế này giúp ngay cả các mô hình chỉ-văn-bản cũng có thể phân loại hình ảnh mà không cần khả năng nhìn tích hợp sẵn. expand_text_attachments – Khi được bật (True), Poe sẽ phân tích các tệp văn bản được tải lên và đưa nội dung của chúng vào hội thoại, cho phép mô hình làm việc trực tiếp với nội dung tài liệu mà không cần cơ chế xử lý tệp đặc biệt. supports_system_messages – Tham số này kiểm soát việc mô hình có thể chấp nhận các thông điệp hệ thống (system prompts) hay không, giúp duy trì hành vi thống nhất giữa các mô hình có khả năng khác nhau. Các cờ cấu hình này tạo nên một lớp trừu tượng mạnh mẽ (powerful abstraction layer), mang lại những lợi ích nổi bật sau:\nExtends model capabilities – Các mô hình chỉ-văn-bản có thể mô phỏng khả năng đa phương thức (pseudo-multimodal) nhờ bước xử lý trước (preprocessing) của Poe. Optimizes built-in features – Các mô hình đa phương thức thực sự có thể tận dụng toàn bộ khả năng tích hợp sẵn để đạt hiệu quả tối ưu nhất. Simplifies integration – Quá trình tích hợp trở nên đơn giản, chỉ cần bật hoặc tắt các tùy chọn cấu hình, không cần thay đổi mã nguồn. Maintains consistency – Đảm bảo trải nghiệm người dùng nhất quán, bất kể khả năng gốc của mô hình là gì. Tiếp theo, chúng ta sẽ đi sâu vào triển khai kỹ thuật của giải pháp (technical implementation) để hiểu chi tiết hơn về cách thức hoạt động.\nLớp dịch giao thức Khía cạnh thách thức kỹ thuật lớn nhất của giải pháp này nằm ở việc kết nối giữa các giao thức API của Poe và các giao diện mô hình đa dạng của Amazon Bedrock. Nhóm phát triển đã giải quyết vấn đề này bằng cách xây dựng một lớp dịch giao thức tinh vi (sophisticated protocol translation layer), cho phép các hệ thống hoạt động hài hòa dù được thiết kế theo những triết lý hoàn toàn khác nhau:\n# From services/streaming_service.py - Actual implementation def _extract_content_from_event(self, event: Dict[str, Any]) -\u0026gt; Optional[str]: \u0026quot;\u0026quot;\u0026quot;Extract content from a streaming event based on model provider.\u0026quot;\u0026quot;\u0026quot; try: # Handle Anthropic Claude models if \u0026quot;message\u0026quot; in event: message = event.get(\u0026quot;message\u0026quot;, {}) if \u0026quot;content\u0026quot; in message and isinstance(message[\u0026quot;content\u0026quot;], list): for content_item in message[\u0026quot;content\u0026quot;]: if content_item.get(\u0026quot;type\u0026quot;) == \u0026quot;text\u0026quot;: return content_item.get(\u0026quot;text\u0026quot;, \u0026quot;\u0026quot;) elif \u0026quot;content\u0026quot; in message: return str(message.get(\u0026quot;content\u0026quot;, \u0026quot;\u0026quot;)) # Handle Amazon Titan models if \u0026quot;delta\u0026quot; in event: delta = event.get(\u0026quot;delta\u0026quot;, {}) if \u0026quot;text\u0026quot; in delta: return delta.get(\u0026quot;text\u0026quot;, \u0026quot;\u0026quot;) # Handle other model formats if \u0026quot;chunk\u0026quot; in event: chunk_data = event.get(\u0026quot;chunk\u0026quot;, {}) if \u0026quot;bytes\u0026quot; in chunk_data: # Process binary data if present try: text = chunk_data[\u0026quot;bytes\u0026quot;].decode(\u0026quot;utf-8\u0026quot;) return json.loads(text).get(\u0026quot;completion\u0026quot;, \u0026quot;\u0026quot;) except Exception: self.logger.warning(\u0026quot;Failed to decode bytes in chunk\u0026quot;) # No matching format found return None Lớp dịch giao thức này (translation layer) xử lý những khác biệt tinh vi giữa các mô hình, đảm bảo rằng bất kể mô hình Amazon Bedrock nào được sử dụng, phản hồi gửi về cho Poe luôn thống nhất và tuân theo định dạng mà Poe mong đợi.\nXử lý và chuẩn hóa lỗi Một khía cạnh then chốt của việc triển khai là xử lý lỗi và chuẩn hóa lỗi toàn diện (comprehensive error handling and normalization). Thành phần ErrorService chịu trách nhiệm đảm bảo quá trình xử lý lỗi diễn ra nhất quán trên tất cả các mô hình khác nhau, giúp hệ thống duy trì tính ổn định và dễ bảo trì trong môi trường đa mô hình:\n# Simplified example of error handling (not actual code) class ErrorService: def normalize_Amazon_Bedrock_error(self, error: Exception) -\u0026gt; str: \u0026quot;\u0026quot;\u0026quot;Normalize Amazon Bedrock errors into a consistent format.\u0026quot;\u0026quot;\u0026quot; if isinstance(error, ClientError): if \u0026quot;ThrottlingException\u0026quot; in str(error): return \u0026quot;The model is currently experiencing high demand. Please try again in a moment.\u0026quot; elif \u0026quot;ValidationException\u0026quot; in str(error): return \u0026quot;There was an issue with the request parameters. Please try again with different settings.\u0026quot; elif \u0026quot;AccessDeniedException\u0026quot; in str(error): return \u0026quot;Access to this model is restricted. Please check your permissions.\u0026quot; else: return f\u0026quot;An error occurred while communicating with the model: {str(error)}\u0026quot; elif isinstance(error, ConnectionError): return \u0026quot;Connection error. Please check your network and try again.\u0026quot; else: return f\u0026quot;An unexpected error occurred: {str(error)}\u0026quot; Cách tiếp cận này đảm bảo rằng người dùng luôn nhận được các thông báo lỗi có ý nghĩa (meaningful error messages), bất kể mô hình nền tảng hay tình huống lỗi cụ thể đang xảy ra. Đếm và tối ưu hóa token\nHệ thống triển khai cơ chế đếm và tối ưu hóa token tiên tiến (sophisticated token counting and optimization) nhằm tối đa hóa hiệu quả sử dụng các mô hình AI:\n# From services/streaming_service.py - Actual implementation (partial) # Calculate approximate JSON overhead user_message_tokens = 0 for msg in conversation['messages']: for content_block in msg.get('content', []): if 'text' in content_block: # Simple word-based estimation of actual text content user_message_tokens += len(content_block['text'].split()) # Estimate JSON structure overhead (difference between total and content) json_overhead = int((input_tokens - system_tokens) - user_message_tokens) # Ensure we're working with integers for calculations input_tokens_for_pct = int(input_tokens) system_tokens_for_pct = int(system_tokens) json_overhead_for_pct = int(json_overhead) # Calculate percentage with float arithmetic and proper integer division json_overhead_percent = (float(json_overhead_for_pct) / max(1, input_tokens_for_pct - system_tokens_for_pct)) * 100 ... Việc theo dõi chi tiết token này cho phép ước tính chi phí và tối ưu hóa chính xác, giúp sử dụng tài nguyên mô hình hiệu quả hơn.\nXác thực và bảo mật AWS Thành phần AwsClientService chịu trách nhiệm xác thực và bảo mật cho các lệnh gọi API của Amazon Bedrock. Triển khai này đảm bảo xác thực an toàn với các dịch vụ AWS, đồng thời xử lý lỗi và quản lý kết nối một cách đúng chuẩn và nhất quán.\nPhân tích so sánh Việc triển khai wrapper API đã cải thiện đáng kể hiệu suất và khả năng triển khai các mô hình Amazon Bedrock trên Poe, như được thể hiện trong bảng sau:\nFeature Before (Direct API) After (Wrapper API) Deployment Time Days per model Minutes per model Developer Focus Configuration and plumbing Innovation and features Model Diversity Limited by integration capacity Extensive (across Amazon Bedrock models) Maintenance Overhead High (separate code for each model) Low (configuration-based) Error Handling Custom per model Standardized across models Cost Tracking Complex (multiple integrations) Simplified (centralized) Multimodal Support Fragmented Unified Security Varied implementations Consistent best practices Bảng so sánh này làm nổi bật những cải tiến đáng kể đạt được thông qua cách tiếp cận wrapper API, minh chứng cho giá trị của việc đầu tư vào một lớp trừu tượng mạnh mẽ (robust abstraction layer).\nHiệu suất và tác động kinh doanh Framework wrapper API đã mang lại tác động kinh doanh rõ rệt và có thể đo lường được trên nhiều khía cạnh, bao gồm tăng tính đa dạng mô hình, nâng cao hiệu quả triển khai, và cải thiện năng suất của nhà phát triển. Poe hiện có thể mở rộng nhanh chóng danh mục mô hình của mình, tích hợp hàng chục mô hình Amazon Bedrock trên các loại dữ liệu văn bản, hình ảnh và video. Việc mở rộng này diễn ra trong vài tuần thay vì vài tháng như trước đây.\nBảng dưới đây tóm tắt các chỉ số hiệu quả triển khai (deployment efficiency metrics):\nChỉ số Trước Sau Cải thiện Triển khai mô hình mới 2–3 ngày 15 phút Nhanh hơn 96 lần Số dòng mã cần thay đổi Hơn 500 dòng 20–30 dòng Giảm 95% Thời gian thử nghiệm 8–12 giờ 30–60 phút Giảm 87% Các bước triển khai 10–15 bước 3–5 bước Giảm 75% Các chỉ số này được đo lường thông qua so sánh trực tiếp số giờ kỹ sư thực hiện trước và sau khi triển khai, theo dõi các lần triển khai thực tế của các mô hình mới.\nNhóm kỹ sư cũng ghi nhận sự thay đổi rõ rệt trong phân bổ thời gian công việc, chuyển trọng tâm từ tích hợp API sang phát triển tính năng, như thể hiện trong bảng dưới đây:\nHoạt động Trước (% thời gian) Sau (% thời gian) Thay đổi Tích hợp API 65% 15% -50% Phát triển tính năng 20% 60% +40% Thử nghiệm 10% 15% +5% Tài liệu 5% 10% +5% Cân nhắc về khả năng mở rộng và hiệu năng Wrapper API được thiết kế để xử lý các khối lượng công việc lớn trong môi trường sản xuất (high-volume production workloads) với khả năng mở rộng mạnh mẽ (robust scaling capabilities). Connection pooling\nĐể xử lý hiệu quả nhiều yêu cầu đồng thời (multiple concurrent requests), hệ thống wrapper triển khai cơ chế gom kết nối (connection pooling) bằng cách sử dụng thư viện aiobotocore. Cơ chế này cho phép hệ thống duy trì một nhóm (pool) các kết nối đến Amazon Bedrock, giúp giảm chi phí xử lý khi phải thiết lập kết nối mới cho từng yêu cầu riêng lẻ:\n# From services/aws_service.py - Connection management async def setup_client(self) -\u0026gt; None: \u0026quot;\u0026quot;\u0026quot;Initialize AWS client with proper configuration.\u0026quot;\u0026quot;\u0026quot; async with self._client_lock: try: # Always clean up existing clients first to avoid stale connections if self.Amazon_Bedrock_client: await self.cleanup() # Increase timeout for image generation config = Config( read_timeout=300, # 5 minutes timeout retries={'max_attempts': 3, 'mode': 'adaptive'}, connect_timeout=30 # 30 second connection timeout ) # Create the Amazon Bedrock client with proper error handling self.Amazon_Bedrock_client = await self.session.create_client( service_name=\u0026quot;Amazon_Bedrock-runtime\u0026quot;, region_name=self.bot_config.aws_region, aws_access_key_id=self.bot_config.aws_access_key, aws_secret_access_key=self.bot_config.aws_secret_key, aws_session_token=self.bot_config.aws_security_token, config=config ).__aenter__() except Exception as e: self.Amazon_Bedrock_client = None raise Xử lý bất đồng bộ Toàn bộ framework được thiết kế theo cơ chế xử lý bất đồng bộ (asynchronous processing) nhằm xử lý hiệu quả nhiều yêu cầu đồng thời (concurrent requests):\n# From core/refactored_chat_bot.py - Asynchronous request handling async def get_response(self, query: QueryRequest) -\u0026gt; AsyncIterable[PartialResponse]: try: # Ensure AWS client is set up await aws_service.setup_client() # Validate and format the conversation conversation = await conversation_service.validate_conversation(query) # Process the request with streaming if self.bot_config.streaming: async for chunk in streaming_service.stream_Amazon_Bedrock_response(conversation, request_id): yield chunk else: # Non-streaming mode response_text, input_tokens, output_tokens = await streaming_service.non_stream_Amazon_Bedrock_response(conversation, request_id) if response_text: yield PartialResponse(text=response_text) else: yield PartialResponse(text=self.bot_config.fallback_response) # Send done event for non-streaming mode yield self.done_event() except Exception as e: # Error handling error_message = error_service.log_error(e, request_id, \u0026quot;Error during request processing\u0026quot;) yield PartialResponse(text=error_message) yield self.done_event() Khôi phục lỗi và logic thử lại Hệ thống triển khai cơ chế khôi phục lỗi (error recovery) và logic thử lại thông minh (retry logic) nhằm xử lý các sự cố tạm thời (transient issues) một cách hiệu quả và tự động: # From services/streaming_service.py - Retry logic max_retries = 3 base_delay = 1 # Start with 1 second delay for attempt in range(max_retries): try: if not self.aws_service.Amazon_Bedrock_client: yield PartialResponse(text=\u0026quot;Error: Amazon Bedrock client is not initialized\u0026quot;) break response = await self.aws_service.Amazon_Bedrock_client.converse_stream(**stream_config) # Process response... break # Success, exit retry loop except ClientError as e: if \u0026quot;ThrottlingException\u0026quot; in str(e): if attempt \u0026lt; max_retries - 1: delay = base_delay * (2 ** attempt) # Exponential backoff await asyncio.sleep(delay) continue error_message = f\u0026quot;Amazon Bedrock API Error: {str(e)}\u0026quot; yield PartialResponse(text=f\u0026quot;Error: {error_message}\u0026quot;) break Chỉ số hiệu năng Hệ thống thu thập các chỉ số hiệu năng chi tiết (detailed performance metrics) nhằm xác định các điểm nghẽn (bottlenecks) và tối ưu hóa hiệu suất hoạt động tổng thể (optimize performance): # From services/streaming_service.py - Performance metrics # Log token usage and latency latency = time.perf_counter() - start_time self.logger.info( f\u0026quot;[{request_id}] Streaming Response Metrics:\\n\u0026quot; f\u0026quot; Time to First Token: {first_token_time:.4f} seconds\\n\u0026quot; f\u0026quot; Input Tokens: {input_tokens} (includes system prompt)\\n\u0026quot; f\u0026quot; Input Tokens for Billing: {input_tokens - system_tokens} (excludes system prompt)\\n\u0026quot; f\u0026quot; Output Tokens: {output_tokens}\\n\u0026quot; f\u0026quot; Total Tokens: {total_tokens}\\n\u0026quot; f\u0026quot; Amazon Bedrock Latency: {latency:.4f} seconds\\n\u0026quot; f\u0026quot; Latency Optimization: {'enabled' if hasattr(self.bot_config, 'optimize_latency') and self.bot_config.optimize_latency else 'disabled'}\u0026quot; ) Các yếu tố bảo mật Bảo mật là một khía cạnh then chốt trong việc triển khai wrapper API, với nhiều tính năng quan trọng được thiết kế để đảm bảo hoạt động an toàn của hệ thống. Xác thực JWT kết hợp chữ ký AWS SigV4 Hệ thống tích hợp xác thực JWT cho các yêu cầu từ Poe, đồng thời sử dụng AWS SigV4 signing để bảo mật các lệnh gọi Amazon Bedrock API, bao gồm:\nJWT validation – Đảm bảo rằng chỉ những yêu cầu được ủy quyền từ Poe mới có thể truy cập wrapper API. SigV4 signing – Đảm bảo wrapper API có thể xác thực an toàn với Amazon Bedrock. Credential management – Thông tin xác thực AWS được quản lý an toàn và không bao giờ lộ ra phía client. Quản lý bí mật Hệ thống được tích hợp với AWS Secrets Manager để lưu trữ và truy xuất an toàn các thông tin nhạy cảm (sensitive credentials):\n# From services/aws_service.py - Secrets management @staticmethod def get_secret(secret_name: str, region_name: str = \u0026quot;us-east-1\u0026quot;) -\u0026gt; Dict[str, Any]: \u0026quot;\u0026quot;\u0026quot; Retrieve a secret from AWS Secrets Manager. Args: secret_name: Name of the secret to retrieve region_name: AWS region where the secret is stored Returns: Dict[str, Any]: The secret value as a dictionary \u0026quot;\u0026quot;\u0026quot; # Create a Secrets Manager client session = boto3.session.Session() client = session.client( service_name='secretsmanager', region_name=region_name ) try: get_secret_value_response = client.get_secret_value( SecretId=secret_name ) except Exception as e: logging.error(f\u0026quot;Error retrieving secret {secret_name}: {str(e)}\u0026quot;) raise # Depending on whether the secret is a string or binary, one of these fields will be populated. if 'SecretString' in get_secret_value_response: import json try: # Explicitly annotate the return type for mypy result: Dict[str, Any] = json.loads(get_secret_value_response['SecretString']) return result except json.JSONDecodeError: # If not a JSON, return as a single-key dictionary return {\u0026quot;SecretString\u0026quot;: get_secret_value_response['SecretString']} else: import base64 decoded_binary_secret = base64.b64decode(get_secret_value_response['SecretBinary']) return {\u0026quot;SecretBinary\u0026quot;: decoded_binary_secret} Quản lý kết nối an toàn Hệ thống triển khai cơ chế quản lý kết nối an toàn (secure connection management) nhằm ngăn chặn rò rỉ thông tin xác thực (credential leakage) và đảm bảo quy trình dọn dẹp kết nối (proper cleanup) được thực hiện đúng cách sau mỗi phiên làm việc:\n# From services/aws_service.py - Secure connection cleanup async def cleanup(self) -\u0026gt; None: \u0026quot;\u0026quot;\u0026quot;Clean up AWS client resources.\u0026quot;\u0026quot;\u0026quot; try: if self.Amazon_Bedrock_client: try: await self.Amazon_Bedrock_client.__aexit__(None, None, None) except Exception as e: self.logger.error(f\u0026quot;Error closing Amazon Bedrock client: {str(e)}\u0026quot;) finally: self.Amazon_Bedrock_client = None self.logger.info(\u0026quot;Successfully cleaned up AWS client resources\u0026quot;) except Exception as e: # Even if cleanup fails, reset the references to avoid stale connections self.Amazon_Bedrock_client = None Khắc phục sự cố và gỡ lỗi Wrapper API được trang bị khả năng ghi log và gỡ lỗi toàn diện (comprehensive logging and debugging) nhằm hỗ trợ phát hiện và xử lý sự cố một cách nhanh chóng và chính xác. Hệ thống triển khai ghi log chi tiết (detailed logging) xuyên suốt quy trình xử lý yêu cầu (request processing flow). Mỗi yêu cầu đều được gán một mã định danh duy nhất (unique ID) — mã này được sử dụng trong toàn bộ quá trình xử lý để hỗ trợ việc truy vết và phân tích (tracing) khi cần gỡ lỗi hoặc kiểm tra hiệu năng.\n# From core/refactored_chat_bot.py - Request tracing request_id = str(id(query)) start_time = time.perf_counter() # Used in all log messages self.logger.info(f\u0026quot;[{request_id}] Incoming request received\u0026quot;) Bài học kinh nghiệm và thực tiễn tốt nhất Thông qua quá trình hợp tác này, nhiều bài học kỹ thuật quan trọng đã được rút ra — có thể mang lại lợi ích cho những nhóm đang thực hiện các dự án tương tự:\nConfiguration-driven architecture – Việc sử dụng tệp cấu hình thay vì mã hóa trực tiếp hành vi riêng cho từng mô hình mang lại lợi ích to lớn trong bảo trì và mở rộng. Cách tiếp cận này cho phép thêm mô hình mới mà không cần chỉnh sửa mã nguồn, đồng thời giảm đáng kể nguy cơ phát sinh lỗi. Protocol translation challenges – Thách thức phức tạp nhất là xử lý các khác biệt tinh tế trong giao thức truyền dữ liệu (streaming) giữa các mô hình khác nhau. Việc xây dựng một lớp trừu tượng ổn định (robust abstraction layer) đòi hỏi xem xét cẩn thận các trường hợp biên (edge cases) và xử lý lỗi toàn diện. Error normalization – Để đảm bảo trải nghiệm xử lý lỗi thống nhất giữa các mô hình, nhóm đã xây dựng cơ chế chuẩn hóa lỗi nâng cao, có thể chuyển đổi lỗi đặc thù của từng mô hình thành thông báo thân thiện và dễ hiểu cho người dùng. Cách tiếp cận này cải thiện đáng kể trải nghiệm cho cả nhà phát triển và người dùng cuối. Type safety – Việc sử dụng chặt chẽ gợi ý kiểu (type hints) của Python là yếu tố then chốt trong duy trì chất lượng mã nguồn của một codebase phức tạp có nhiều người đóng góp. Cách làm này giảm thiểu lỗi và tăng khả năng bảo trì mã. Security first – Tích hợp Secrets Manager ngay từ đầu giúp đảm bảo toàn bộ thông tin xác thực được quản lý an toàn trong suốt vòng đời hệ thống, ngăn ngừa các lỗ hổng bảo mật tiềm ẩn. Kết luận Sự hợp tác giữa AWS Generative AI Innovation Center và Quora minh chứng rằng một thiết kế kiến trúc được cân nhắc kỹ lưỡng có thể đẩy nhanh đáng kể tốc độ triển khai và đổi mới AI. Bằng việc xây dựng một wrapper API hợp nhất cho các mô hình Amazon Bedrock, hai nhóm đã rút ngắn thời gian triển khai từ vài ngày xuống chỉ còn vài phút, đồng thời mở rộng danh mục mô hình và cải thiện trải nghiệm người dùng.\nCách tiếp cận này — tập trung vào trừu tượng hóa (abstraction), phát triển dựa trên cấu hình (configuration-driven development), và xử lý lỗi mạnh mẽ (robust error handling) — mang lại những bài học quý giá cho các tổ chức đang tìm cách tích hợp nhiều mô hình AI một cách hiệu quả. Các mẫu thiết kế và kỹ thuật được trình bày trong giải pháp này có thể áp dụng cho nhiều tình huống tích hợp AI khác nhau trong thực tế.\nĐối với các lãnh đạo công nghệ và nhà phát triển đang làm việc với các thách thức tương tự, nghiên cứu tình huống này nhấn mạnh giá trị của việc đầu tư vào các framework tích hợp linh hoạt (flexible integration frameworks) thay vì các kết nối điểm-đến-điểm truyền thống. Khoản đầu tư ban đầu vào việc xây dựng một lớp trừu tượng mạnh mẽ sẽ mang lại lợi ích dài hạn trong bảo trì hệ thống và mở rộng năng lực.\nĐể tìm hiểu thêm về việc triển khai các giải pháp tương tự, bạn có thể tham khảo: AWS Well-Architected Framework – Hướng dẫn thực hành tốt nhất trong việc xây dựng hạ tầng an toàn, hiệu năng cao, linh hoạt và đáng tin cậy.\nAmazon Bedrock Developer Guide – Thông tin chi tiết về cách làm việc với các mô hình nền tảng (FMs). AWS Generative AI Innovation Center – Nguồn hỗ trợ cho các dự án AI sáng tạo. AWS Prescriptive Guidance for LLM Deployment – Thực tiễn tốt nhất khi triển khai các mô hình ngôn ngữ lớn (LLMs). AWS Generative AI Innovation Center và Quora sẽ tiếp tục hợp tác mở rộng framework này, nhằm đảm bảo người dùng Poe luôn được truy cập vào các mô hình AI mới nhất và mạnh mẽ nhất, với thời gian triển khai tối thiểu.\nVề các tác giả\nDr. Gilbert V. Lepadatu là Kiến trúc sư Học sâu cao cấp (Senior Deep Learning Architect) tại AWS Generative AI Innovation Center, nơi ông hỗ trợ các doanh nghiệp thiết kế và triển khai các giải pháp GenAI quy mô lớn và tiên tiến. Với bằng Tiến sĩ Triết học (PhD in Philosophy) và hai bằng Thạc sĩ, ông mang đến một cách tiếp cận toàn diện và liên ngành (holistic and interdisciplinary) trong khoa học dữ liệu và trí tuệ nhân tạo. Nick Huber là Trưởng nhóm Hệ sinh thái AI (AI Ecosystem Lead) cho Poe (thuộc Quora), chịu trách nhiệm đảm bảo việc tích hợp các mô hình AI hàng đầu lên nền tảng Poe diễn ra đúng hạn và đạt chất lượng cao nhất. "
},
{
	"uri": "//localhost:1313/vi/1-worklog/",
	"title": "Nhật ký công việc",
	"tags": [],
	"description": "",
	"content": "Tuần 1: Làm quen với AWS và các dịch vụ cơ bản trong AWS\nTuần 2: Tìm hiểu IAM, S3 và triển khai thử nghiệm website tĩnh\nTuần 3: Thiết kế VPC, subnet, security group và khởi tạo EC2 cơ bản\nTuần 4: Làm việc với RDS, cấu hình kết nối và sao lưu dữ liệu\nTuần 5: Thiết lập CloudWatch, log, alarm và dashboard giám sát hệ thống\nTuần 6: Nghiên cứu Auto Scaling, Load Balancer và kiến trúc high availability\nTuần 7: Thực hành workshop truy cập S3 từ VPC qua Gateway Endpoint\nTuần 8: Mô phỏng on-premises và truy cập S3 qua Interface Endpoint\nTuần 9: Thiết kế và áp dụng VPC Endpoint Policies cho truy cập S3 an toàn\nTuần 10: Thực hiện cleanup tài nguyên, rà soát và tối ưu chi phí AWS\nTuần 11: Tổng hợp kết quả, hoàn thiện proposal và tài liệu báo cáo thực tập\nTuần 12: Hoàn thiện portfolio, tự đánh giá, tiếp nhận góp ý và chuẩn bị trình bày\n"
},
{
	"uri": "//localhost:1313/vi/5-workshop/5.3-s3-vpc/5.3.1-create-gwe/",
	"title": "Tạo một Gateway Endpoint",
	"tags": [],
	"description": "",
	"content": " Mở Amazon VPC console Trong thanh điều hướng, chọn Endpoints, click Create Endpoint: Bạn sẽ thấy 6 điểm cuối VPC hiện có hỗ trợ AWS Systems Manager (SSM). Các điểm cuối này được Mẫu CloudFormation triển khai tự động cho workshop này.\nTrong Create endpoint console: Đặt tên cho endpoint: s3-gwe Trong service category, chọn aws services Trong Services, gõ \u0026ldquo;s3\u0026rdquo; trong hộp tìm kiếm và chọn dịch vụ với loại gateway Đối với VPC, chọn VPC Cloud từ drop-down menu. Đối với Route tables, chọn bảng định tuyến mà đã liên kết với 2 subnets (lưu ý: đây không phải là bảng định tuyến chính cho VPC mà là bảng định tuyến thứ hai do CloudFormation tạo). Đối với Policy, để tùy chọn mặc định là Full access để cho phép toàn quyền truy cập vào dịch vụ. Bạn sẽ triển khai VPC endpoint policy trong phần sau để chứng minh việc hạn chế quyền truy cập vào S3 bucket dựa trên các policies. Không thêm tag vào VPC endpoint. Click Create endpoint, click x sau khi nhận được thông báo tạo thành công. "
},
{
	"uri": "//localhost:1313/vi/4-eventparticipated/4.1-event1/",
	"title": "Vietnam Cloud Day 2025",
	"tags": [],
	"description": "",
	"content": "Vietnam Cloud Day 2025 Ho Chi Minh City Connect Edition for Builders - GenAI and Data Track Địa điểm: AWS Event Hall, L26 Bitexco Tower, HCMC\nThời gian: 1PM Thứ Năm, ngày 18 tháng 09 năm 2025\nMục Đích Của Sự Kiện Giới thiệu tổng quan về xu hướng Agentic AI và tầm nhìn của AWS. Khám phá chiến lược xây dựng nền tảng dữ liệu thống nhất phục vụ AI \u0026amp; Analytics trên AWS. Phân tích lộ trình GenAI, các kiến trúc AI Agent và thách thức khi đưa vào production. Tìm hiểu mô hình AI-Driven Development Lifecycle (AI-DLC). Nắm bắt các nguyên tắc bảo mật, quản trị rủi ro và Responsible AI trong Generative AI. Giới thiệu các dịch vụ AWS mới hỗ trợ AI Agents và nâng cao năng suất doanh nghiệp. Danh Sách Diễn Giả Jun Kai Loke – AI/ML Specialist Solutions Architect, AWS Kien Nguyen – Solutions Architect, AWS Tamelly Lim – Storage Specialist Solutions Architect, AWS Binh Tran – Senior Solutions Architect, AWS Taiki Dang – Solutions Architect, AWS Christal Poon – Specialist Solutions Architect, AWS Nội Dung Nổi Bật Opening – Agentic AI Overview – Jun Kai Loke Agentic AI và xu hướng phát triển Agentic AI là xu hướng chiến lược hàng đầu, hướng đến hệ thống tự vận hành, giảm giám sát của con người, và tự động hóa sâu. Các ví dụ thành công: Katalon, Apero, Techcom Securities. Amazon Bedrock – Nền tảng phát triển AI Triển khai bảo mật ở quy mô lớn Kết hợp tools và memory Giám sát toàn diện end-to-end Building a Unified Data Foundation on AWS – Kien Nguyen Thách thức hiện tại 89% CDOs đang triển khai GenAI nhưng chỉ 52% đánh giá nền tảng dữ liệu đã sẵn sàng (Harvard Business Review). Nguyên nhân: data silos, people silos, business silos. Chiến lược dữ liệu End-to-End: 3 thành phần chính:\nProducers Foundations Consumers Các thành phần dữ liệu trọng yếu từ AWS Amazon Bedrock Cơ sở dữ liệu – RDS, database chuyên dụng hỗ trợ vector search Analytics \u0026amp; ML – SageMaker, Unified Studio Data \u0026amp; AI Governance Lake House Architecture – S3, Redshift Managed Storage, Iceberg Open API Amazon DataZone GenAI Roadmap \u0026amp; AI Agents Architecture – Jun Kai Loke \u0026amp; Tamelly Lim Blueprint xây dựng AI Agents: Model \u0026amp; application capabilities, tool framework.\nAmazon Bedrock\nAmazon Nova – phát triển và tùy chỉnh mới\nStrands Agents – mô hình Agents thế hệ mới\nKhó khăn khi đưa Agents vào production\n→ AWS giới thiệu Amazon Bedrock AgentCore để giải quyết.\nAgentCore gồm các thành phần Agent Core Runtime Agent Core Gateway Memory Agent Browser Code Interpreter → Tăng cường bảo mật và khả năng mở rộng.\nAI-Driven Development Lifecycle (AI-DLC) – Binh Tran Hai mô hình phát triển phần mềm hiện tại AI Managed Pattern – ít giám sát nhưng kém tin cậy\nAI Assisted Pattern – AI hỗ trợ tác vụ nhỏ, vẫn còn hạn chế\nAI-DLC – Chu trình phát triển phần mềm mới Gồm 3 giai đoạn:\n1. Inception Xây dựng context Phác thảo user stories Lập kế hoạch bằng work units 2. Construction Code + test Bổ sung kiến trúc Triển khai IaC + kiểm thử 3. Operation Deploy production bằng IaC Quản lý sự cố Securing Generative AI Applications – Taiki Dang Các yếu tố bảo mật trọng yếu Compliance \u0026amp; Governance Legal \u0026amp; Privacy Controls Risk Management Resilience Scoping matrix Consumer App Enterprise App Pre-trained models Fine-tuned models Self-trained models Frameworks \u0026amp; Standards AWS Well-Architected MITRE ATLAS OWASP Top 10 for LLM Apps NIST AI 600-1 ISO 42001 EU AI Act Rủi ro theo từng lớp Consumer: IP, Legal, Hallucination, Safety Tuner: managed/hosted, data retention Provider: training data, model construction Giảm thiểu rủi ro Prompt engineering Fine-tuning RAG Parameter tuning Bedrock Guardrails Bảo mật prompt Beyond Automation: AI Agents as Productivity Multipliers – Christal Poon Các dạng dịch vụ AI Agents Specialized Agents Fully-managed Agents DIY Agents Dịch vụ hỗ trợ năng suất doanh nghiệp Amazon QuickSight\nAmazon Q:\nDashboards Reports Executive summaries AI Agent Scenarios Sắp ra mắt tại Việt Nam QuickSuite:\nQuick Researcher Quick Automate Humans in the Loop Những Gì Học Được Hiểu rõ hệ sinh thái Agentic AI \u0026amp; Roadmap của AWS: Agentic AI là thế hệ tiếp theo của automation, hướng tới self-directed systems. Kiến trúc dữ liệu vững chắc là nền tảng GenAI: S3, Iceberg, Redshift, Bedrock, SageMaker giữ vai trò trung tâm. AI-DLC tạo ra phương pháp phát triển phần mềm hiện đại: Tự động hóa từ planning → coding → testing → deployment. Bảo mật là yếu tố xuyên suốt mọi lớp AI stack: Cần tuân thủ chuẩn, bảo vệ dữ liệu, đánh giá rủi ro. AWS đang mở rộng mạnh hệ sinh thái AI Agents \u0026amp; Enterprise AI. Ứng Dụng Vào Công Việc Tích hợp AI Agents vào các tác vụ nghiệp vụ. Dùng Amazon Bedrock, Amazon Q, Guardrails để kiểm soát chất lượng. Xây dựng nền tảng dữ liệu thống nhất trước GenAI. Ứng dụng mô hình AI-DLC vào phát triển nội bộ. Xây dashboard, insight với QuickSight \u0026amp; Amazon Q. Trải Nghiệm Tại Sự Kiện Workshop mang lại góc nhìn rõ ràng về chuyển đổi từ automation truyền thống sang Agentic AI.\nCác diễn giả chia sẻ sâu sắc, thực tế và định hướng rõ ràng cho hành trình GenAI tại Việt Nam.\nSự kết hợp của AgentCore, Bedrock, AI-DLC và Amazon Q tạo nên bức tranh toàn diện về thế hệ AI dành cho doanh nghiệp.\nMột số hình ảnh tại sự kiện (Bạn thêm hình tại đây)\n"
},
{
	"uri": "//localhost:1313/vi/1-worklog/1.1-week1/",
	"title": "Worklog Tuần 1",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 1: Kết nối, làm quen với các thành viên trong First Cloud Journey, tạo nhóm học tập với các thành viên mới. Tìm hiểu các dịch vụ AWS cơ bản, cách dùng console và tùy chỉnh các dịch vụ cơ bản của AWS. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và ghi chú các quy định, nội quy của đơn vị thực tập 08/09/2025 08/09/2025 https://policies.fcjuni.com/ 3 - Tìm hiểu về AWS và các loại dịch vụ của nó + Tính toán (Compute) + Lưu trữ (Storage) + Mạng (Networking) + Cơ sở dữ liệu (Database) + Machine Learning và Trí tuệ nhân tạo + v.v. 08/09/2025 09/09/2025 https://docs.aws.amazon.com/whitepapers/latest/aws-overview/amazon-web-services-cloud-platform.html 4 - Tạo tài khoản AWS Free Tier - Quản lý truy cập với AWS Identity and Access Management (AWS IAM) - Quản lý chi phí sử dụng trên AWS bằng AWS Budgets - Thực hành: + Tạo tài khoản AWS + Tạo Nhóm người dùng (User Group) + Tạo người dùng mới + Thêm thiết bị MFA + Tạo ngân sách từ Template + Tạo Cost Budget + Tạo Usage Budget + Tạo RI Budget + Tạo Savings Plans Budget + Dọn dẹp Tài nguyên 09/09/2025 10/09/2025 https://000001.awsstudygroup.com/vi/ https://000002.awsstudygroup.com/vi/ https://000007.awsstudygroup.com/vi/ 5 - Tìm hiểu về bảo mật và tính năng của Amazon Virtual Private Cloud (Amazon VPC): + Các khả năng chính + Network Access Control List (NACL)\n+ VPC Flow Logs + VPC Peering + Transit Gateway - Tìm hiểu về VPN + VPN Site to Site + AWS Direct Connect - Tìm hiểu về Elastic Load Balancing + Application Load Balancer + Network Load Balancer + Classic Load Balancer + Gateway Load Balancer - Thực hành + Tạo một VPC + Cấu hình Site to Site VPN 10/09/2025 11/09/2025 https://000003.awsstudygroup.com/vi/ 6 - Thực hành: + Tạo EC2 instance + Tạo Virtual Private Gateway + Tạo Customer Gateway + Tạo kết nối VPN emsp; + Cấu hình Customer Gateway + Tùy chỉnh AWS VPN Tunnel + Cấu hình VPN nâng cao 12/09/2025 12/09/2025 https://000003.awsstudygroup.com/vi/ Kết quả đạt được tuần 1: Tạo nhóm học tập với các thành viên mới.\nHiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database Machine Learning và Artificial Intelligence vv. Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ cơ bản từ giao diện web.\nLàm quen với AWS IAM để quản trị quyền truy cập\nLàm quen và bắt đầu triển khai hạ tầng mạng với Amazon Virtual Private Cloud AWS VPC\n"
},
{
	"uri": "//localhost:1313/vi/1-worklog/1.2-week2/",
	"title": "Worklog Tuần 2",
	"tags": [],
	"description": "",
	"content": "Tuần 2 – Mục tiêu: Tiếp tục tìm hiểu các dịch vụ AWS cơ bản, cách sử dụng giao diện console và tùy chỉnh các dịch vụ AWS ở mức nền tảng.\nCác nhiệm vụ cần thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Khởi tạo và triển khai một ứng dụng trên Amazon Compute Cloud (Amazon EC2) 09/15/2025 09/15/2025 https://000004.awsstudygroup.com/vi/ 3 - Cấp quyền để ứng dụng có thể truy cập các dịch vụ AWS thông qua IAM Role (AWS IAM) 09/16/2025 09/16/2025 https://000048.awsstudygroup.com/vi/ 4 - Sử dụng Cloud IDE trên trình duyệt với AWS Cloud9 09/17/2025 09/17/2025 https://000049.awsstudygroup.com/vi/ 5 - Triển khai website tĩnh bằng Amazon S3 09/18/2025 09/18/2025 https://000057.awsstudygroup.com/vi/ 6 - Thực hành: + Tạo và thiết lập một EC2 instance + Tạo người dùng và nhóm người dùng trong AWS IAM + Tạo S3 Bucket và triển khai website tĩnh 09/19/2025 09/19/2025 https://000004.awsstudygroup.com/vi/ https://000048.awsstudygroup.com/vi https://000057.awsstudygroup.com/vi/ Kết quả đạt được trong tuần 2: Khởi tạo và triển khai thành công một ứng dụng trên Amazon EC2, bao gồm cấu hình cơ bản của instance và kiểm tra kết nối.\nThiết lập đúng quyền truy cập cho ứng dụng vào các dịch vụ AWS cần thiết thông qua việc tạo và gán IAM Role, củng cố kiến thức về kiểm soát truy cập dựa trên vai trò.\nLàm quen với AWS Cloud9 như một môi trường IDE trên đám mây, bao gồm chỉnh sửa mã nguồn, sử dụng terminal, và tích hợp cơ bản với các dịch vụ AWS khác.\nThiết lập và triển khai website tĩnh bằng Amazon S3, bao gồm cấu hình bucket, thiết lập chế độ static website hosting và cấu hình truy cập công khai cho nội dung website.\nCủng cố kỹ năng thực hành thông qua việc:\nTạo và cấu hình một EC2 instance. Tạo người dùng và nhóm người dùng trong IAM, đồng thời phân quyền phù hợp. Tạo S3 bucket và triển khai website tĩnh hoàn chỉnh từ đầu đến cuối. "
},
{
	"uri": "//localhost:1313/vi/1-worklog/1.3-week3/",
	"title": "Worklog Tuần 3",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 3: Tiếp tục học cách sử dụng các dịch vụ AWS cơ bản. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu về Amazon Relational Database Service (Amazon RDS) 09/22/2025 09/22/2025 https://000005.awsstudygroup.com/vi/ 3 - Tối ưu chi phí tính toán với Amazon Lightsail (Amazon Lightsail) 09/23/2025 09/23/2025 https://000045.awsstudygroup.com/vi/ 4 - Tìm hiểu về cơ chế của Amazon EC2 Autoscaling 09/24/2025 09/24/2025 https://000006.awsstudygroup.com/vi/ 5 - Tạo bảng theo dõi hệ thống với Amazon Cloudwatch 09/24/2025 09/25/2025 https://000008.awsstudygroup.com/vi/ 6 - Thực hành: + Tạo một database với Amazon RDS + Tạo một EC2 instance có chế độ Autoscaling + Thiết lập Amazon Cloudwatch để theo dõi EC2 Instance đã khởi tạo 09/25/2025 09/26/2025 https://000005.awsstudygroup.com/vi/ https://000006.awsstudygroup.com/vi/ https://000008.awsstudygroup.com/vi/ Kết quả đạt được trong tuần 3: Nắm được khái niệm, vai trò và các trường hợp sử dụng chính của Amazon RDS, bao gồm ưu điểm so với việc tự quản lý database trên EC2.\nHiểu được cách tối ưu chi phí tính toán với Amazon Lightsail, bao gồm đặc điểm gói chi phí cố định và sự khác biệt giữa Lightsail và EC2 trong các kịch bản triển khai đơn giản.\nNắm được cơ chế hoạt động cơ bản của Amazon EC2 Auto Scaling, bao gồm:\nKhái niệm Auto Scaling Group. Cách tự động tăng/giảm số lượng EC2 instance theo tải hệ thống. Biết cách tạo bảng theo dõi và giám sát hệ thống với Amazon CloudWatch, bao gồm thiết lập metric, biểu đồ giám sát và theo dõi tình trạng EC2 instance.\nHoàn thành các bài thực hành:\nTạo một database trên Amazon RDS và cấu hình các tham số cơ bản. Tạo một EC2 instance nằm trong nhóm Auto Scaling với cấu hình mở rộng/thu hẹp tự động. Thiết lập Amazon CloudWatch để giám sát EC2 instance đã khởi tạo, hỗ trợ theo dõi hiệu năng và tình trạng hoạt động. "
},
{
	"uri": "//localhost:1313/vi/1-worklog/1.4-week4/",
	"title": "Worklog Tuần 4",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 4: Học cách chuyển dịch lên AWS liền mạch và tối ưu hệ thống trên AWS Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu về dịch vụ AWS VM Import/Export 09/29/2025 09/29/2025 https://000014.awsstudygroup.com/vi/ 3 - Tìm hiểu về dịch vụ AWS Database Migration Service (DMS) và AWS Schema Conversion Tool (SCT) 09/30/2025 09/30/2025 https://000043.awsstudygroup.com/vi/ 4 - Làm quen với AWS Lambda, bật tắt máy chủ tự động va nhắn tin qua Slack 10/01/2025 10/01/2025 https://000022.awsstudygroup.com/vi/ 5 - Tạo bảng theo dõi hệ thống với Amazon Cloudwatch và Grafana 10/02/2025 10/02/2025 https://000029.awsstudygroup.com/vi/ 6 - Quản lý tài nguyên theo nhóm bằng Tag và Resource Groups - Quản lý truy cập dịch vụ EC2 bằng Tag thông qua IAM - Quản lý dịch vụ và tự động hóa tác vụ sử dụng AWS System Manager 10/02/2025 10/03/2025 https://000027.awsstudygroup.com/vi/ https://000028.awsstudygroup.com/vi/ https://000031.awsstudygroup.com/vi/ Kết quả đạt được trong tuần 4: Hiểu được mục đích, kiến trúc tổng quan và kịch bản sử dụng của AWS VM Import/Export trong việc chuyển đổi máy ảo on-premise hoặc từ môi trường khác lên AWS một cách liền mạch.\nNắm được quy trình và vai trò của:\nAWS Database Migration Service (DMS) trong việc migrate dữ liệu giữa các hệ quản trị CSDL khác nhau, hạn chế downtime. AWS Schema Conversion Tool (SCT) trong việc chuyển đổi schema khi migrate cơ sở dữ liệu không đồng nhất (heterogeneous migration). Làm quen với AWS Lambda và cơ chế serverless, đồng thời:\nThiết lập logic bật/tắt máy chủ tự động (EC2) thông qua Lambda. Tìm hiểu cách tích hợp gửi thông báo qua Slack khi thực hiện các tác vụ tự động. Biết cách tạo bảng, dashboard theo dõi hệ thống với:\nAmazon CloudWatch để thu thập metric, log, và tạo alarm. Grafana để trực quan hóa dữ liệu giám sát từ CloudWatch một cách rõ ràng, dễ theo dõi. Nắm được cách quản lý tài nguyên theo nhóm bằng Tag và Resource Groups, bao gồm:\nGán thẻ (tag) có cấu trúc cho tài nguyên để tiện lọc, quản lý và tính chi phí. Tạo và sử dụng Resource Groups để làm việc theo nhóm tài nguyên có chung đặc điểm. Hiểu cơ chế quản lý truy cập dịch vụ EC2 bằng Tag thông qua IAM, từ đó:\nXây dựng được chính sách IAM dựa trên điều kiện Tag (tag-based access control). Hạn chế hoặc cấp quyền chi tiết hơn đến từng nhóm tài nguyên. Làm quen với AWS Systems Manager và vai trò của nó trong:\nQuản lý cấu hình và trạng thái tài nguyên. Tự động hóa một số tác vụ vận hành (operations) trên hệ thống chạy trên EC2 và môi trường hybrid. "
},
{
	"uri": "//localhost:1313/vi/1-worklog/1.5-week5/",
	"title": "Worklog Tuần 5",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 5: Tiếp tục học cách tối ưu hóa hệ thống AWS Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Triển khai kế hoạch sao lưu hệ thống với AWS Backup 10/06/2025 10/06/2025 https://000013.awsstudygroup.com/vi/ 3 - Triển khai ứng dụng với Docker - Triển khai ứng dụng lên Amazon Elastic Container Service (Amazon ECS) 10/07/2025 10/07/2025 https://000015.awsstudygroup.com/vi/ https://000016.awsstudygroup.com/vi/ 4 - Triển khai ứng dụng với AWS CodePipeline - Tự động hóa triển khai ứng dụng với AWS CodePipeline 10/08/2025 10/08/2025 https://000017.awsstudygroup.com/vi/ https://000023.awsstudygroup.com/vi/ 5 - Tìm hiểu về cách thiết lập Single Sign-On (Amazon SSO) 10/09/2025 10/09/2025 https://000012.awsstudygroup.com/vi/ 6 - Tìm hiểu về IAM Permission Boudary 10/10/2025 10/10/2025 https://000030.awsstudygroup.com/vi/ Kết quả đạt được trong tuần 5: Hiểu được vai trò và kiến trúc tổng quan của AWS Backup, bao gồm cách định nghĩa backup plan, cấu hình backup vault và thiết lập lịch sao lưu tự động cho tài nguyên.\nNắm được quy trình đóng gói ứng dụng với Docker cơ bản\nLàm quen với Amazon ECS trong việc triển khai container:\nHiểu khái niệm Task Definition, Service, Cluster. Triển khai ứng dụng container hóa lên ECS theo tài liệu hướng dẫn. Nắm được quy trình triển khai ứng dụng với AWS CodePipeline, bao gồm:\nHiểu các stage chính: Source – Build – Deploy. Thiết lập pipeline tự động hoá quy trình triển khai (CI/CD) để khi cập nhật mã nguồn thì ứng dụng được build và deploy tự động. Tìm hiểu cơ chế và lợi ích của AWS Single Sign-On (SSO):\nNắm được mục tiêu tập trung quản lý đăng nhập cho nhiều tài khoản và ứng dụng. Hiểu luồng đăng nhập và phân quyền người dùng/nhóm. Hiểu khái niệm IAM Permission Boundary:\nPhân biệt giữa Permission Boundary và Policy thông thường. Nắm được cách sử dụng Permission Boundary để giới hạn quyền tối đa mà user/role có thể được cấp, hỗ trợ kiểm soát truy cập chặt chẽ hơn. "
},
{
	"uri": "//localhost:1313/vi/1-worklog/1.6-week6/",
	"title": "Worklog Tuần 6",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 6: Tìm hiểu về cách hiện đại hóa ứng dụng, làm quen với cách xây dựng ứng dụng Serverless và trải nghiệm các dịch vụ AI trên AWS Trao đổi với các thành viên trong nhóm, lên ý tưởng sơ bộ, triển khai các dịch vụ cơ bản phục vụ cho dự án và học thêm các kiến thức liên quan Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Serverless: Lambda tương tác với S3 và DynamoDB 10/13/2025 10/13/2025 https://000078.awsstudygroup.com/vi/ 3 - Gọi API thông qua API Gateway 10/14/2025 10/14/2025 https://000079.awsstudygroup.com/vi/ 4 - Tìm hiểu về Amazon Cognito 10/15/2025 10/15/2025 https://000081.awsstudygroup.com/vi/ 5 - Tìm hiểu cách triển khai ứng dụng trên AWS Serverless Application Model (SAM) 10/16/2025 10/16/2025 https://000080.awsstudygroup.com/vi/ 6 - Thực hành: + Triển khai Frontend + Triển khai Lambda Function + Cấu hình API Gateway + Kiểm tra API với Postman và Frontend 10/17/2025 10/17/2025 https://000078.awsstudygroup.com/vi/ https://000079.awsstudygroup.com/vi/ https://000080.awsstudygroup.com/vi/ Kết quả đạt được tuần 6: Hiểu được mô hình Serverless trên AWS thông qua bài lab Lambda tương tác với S3 và DynamoDB, bao gồm:\nCách Lambda đọc/ghi dữ liệu từ S3. Cách Lambda thao tác dữ liệu trong DynamoDB ở mức cơ bản. Nắm được vai trò của Amazon API Gateway trong kiến trúc serverless:\nHiểu luồng request từ client → API Gateway → Lambda. Biết cách cấu hình endpoint để chuyển tiếp request đến Lambda function. Tìm hiểu tổng quan về Amazon Cognito:\nNắm được khái niệm User Pool, Identity Pool. Hiểu mục đích sử dụng Cognito trong việc xác thực và quản lý người dùng cho ứng dụng web/mobile. Làm quen với cách triển khai ứng dụng bằng AWS Serverless Application Model (AWS SAM):\nHiểu ý nghĩa file template (hạ tầng dưới dạng mã – IaC). Nắm được luồng build, deploy và update ứng dụng serverless qua SAM. Hoàn thành bài thực hành triển khai ứng dụng đầu cuối, bao gồm:\nTriển khai Frontend kết nối với backend serverless. Triển khai Lambda Function xử lý logic phía server. Cấu hình API Gateway để kết nối frontend với Lambda. Kiểm tra hoạt động của API thông qua Postman và kiểm thử từ giao diện frontend. Trao đổi với các thành viên trong nhóm để:\nThống nhất ý tưởng sơ bộ cho dự án sử dụng kiến trúc serverless. Xác định và triển khai các dịch vụ AWS cơ bản cần thiết, đồng thời bổ sung thêm kiến thức liên quan phục vụ cho giai đoạn phát triển tiếp theo. "
},
{
	"uri": "//localhost:1313/vi/1-worklog/1.7-week7/",
	"title": "Worklog Tuần 7",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 7: Tìm hiểu về kiến trúc và các khái niệm cơ bản của Kubernetes. Học cách triển khai và quản lý ứng dụng trên Amazon EKS. Xây dựng một pipeline CI/CD hoàn chỉnh để tự động hóa việc triển khai lên EKS. Công việc đã thực hiện trong tuần: Day Task Start Date Completion Date Reference Material 2 Chỉnh sửa chi tiết kiến trúc.\nĐọc lab 126:\n- Cách khởi tạo cluster, worker node \u0026amp; kiến trúc quản lý. - Hiểu các khái niệm cơ bản: Pod, Deployment, DaemonSet, … — cách thức Kubernetes tổ chức container. - Cách deploy micro-services lên EKS. 20/10/2025 21/10/2025 https://000126.awsstudygroup.com/vi/ 4 Họp team dự án:\n- Thống nhất nguồn dữ liệu và định dạng dữ liệu.\n- Kiểm tra tính năng, sửa lỗi.\n- Lên luồng user. 22/10/2025 22/10/2025 5 Hoàn thành lab 62:\n- Thiết lập Amazon EKS — khởi tạo cluster Kubernetes.\n- Dùng AWS CodePipeline + AWS CodeBuild + GitHub để tạo pipeline CI/CD: mỗi khi có commit mới, pipeline tự build container, push image, deploy lên EKS.\n- Cấu hình RBAC để CodeBuild/CodePipeline có quyền deploy lên cluster. 23/10/2025 23/10/2025 https://000062.awsstudygroup.com/vi/ 6 Meeting team báo cáo hằng tuần. 24/10/2025 24/10/2025 7 Chuẩn bị tài liệu ôn tập giữa kì. 24/10/2025 25/10/2025 Kết quả đạt được trong tuần 7: Kiến thức chuyên sâu về Kubernetes: Đã nắm vững các khái niệm cốt lõi của Kubernetes và kiến trúc của Amazon EKS thông qua việc nghiên cứu lý thuyết (Lab 126). Kỹ năng triển khai CI/CD trên EKS: Xây dựng thành công một pipeline CI/CD hoàn chỉnh, tự động hóa toàn bộ quy trình từ build, push image đến deploy ứng dụng lên EKS, tích hợp với GitHub, CodePipeline và CodeBuild (Lab 62). Dự án: Đã thống nhất được các chi tiết quan trọng về dữ liệu và luồng người dùng, đồng thời tiến hành kiểm thử và sửa lỗi cho các tính năng đã phát triển. Chuẩn bị cho Ôn tập: Bắt đầu hệ thống hóa kiến thức và chuẩn bị tài liệu cho kỳ ôn tập giữa kỳ. "
},
{
	"uri": "//localhost:1313/vi/1-worklog/1.8-week8/",
	"title": "Worklog Tuần 8",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 8: Các kỹ thuật kiểm soát truy cập và phân quyền nâng cao trong IAM. Học cách tự động hóa hạ tầng bằng AWS CloudFormation. Ôn tập và hoàn thành bài thi giữa kỳ. Xác định và giải quyết các vấn đề còn tồn đọng trong dự án. Công việc đã thực hiện trong tuần: Day Task Start Date Completion Date Reference Material 2 Hoàn thành lab 28:\n- Dùng tag + IAM để kiểm soát quyền thao tác EC2.\n- Tạo IAM policy có điều kiện theo tag để đảm bảo “least privilege”.\n- Chỉ user có tag phù hợp mới thao tác được EC2.\nHoàn thành lab 37: - Tạo IAM User/Role để dùng CloudFormation.\n- Deploy template, tạo stack tự động.\nChuẩn bị tiếp tài liệu ôn tập. 27/10/2025 28/10/2025 https://000028.awsstudygroup.com/\nhttps://000037.awsstudygroup.com/ 3 Ôn tập giữa kì. 29/10/2025 30/10/2025 6 Thi giữa kì. 31/10/2025 31/10/2025 CN Họp team dự án: Xác định lỗi tool và các vấn đề về dữ liệu, thống nhất cách giải quyết. 02/11/2025 02/11/2025 Kết quả đạt được trong tuần 8: Bảo mật \u0026amp; Phân quyền nâng cao: Nắm cách sử dụng tag để kiểm soát quyền truy cập chi tiết tới tài nguyên, đảm bảo nguyên tắc “least privilege” (Lab 28). Hạ tầng dưới dạng mã (IaC): Có khả năng tự động hóa việc tạo và quản lý hạ tầng bằng cách sử dụng AWS CloudFormation (Lab 37). Hoàn thành mục tiêu Giữa kỳ: Đã ôn tập kỹ lưỡng và hoàn thành bài thi giữa kỳ. Giải quyết vấn đề Dự án: Chủ động xác định các lỗi và vấn đề liên quan đến dữ liệu trong dự án và đưa ra phương án giải quyết thống nhất. "
},
{
	"uri": "//localhost:1313/vi/1-worklog/1.9-week9/",
	"title": "Worklog Tuần 9",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 9: Tinh chỉnh Proposal và chốt các yêu cầu các tính năng sử dụng Lambda Khảo sát và thống nhất bộ nhận diện thương hiệu. Tìm kiếm các phương pháp để tối ưu hóa chi phí cho kiến trúc đã đề xuất. Tiếp tục xử lý và chuẩn bị dữ liệu cho dự án. Công việc đã thực hiện trong tuần: Day Task Start Date Completion Date Reference Material 2 Chỉnh sửa Proposal dựa theo kiến trúc. 03/11/2025 05/11/2025 5 Lên danh sách các tính năng sử dụng Lambda. Lập trình hàm Lambda 06/11/2025 06/11/2025 6 Họp team dự án:\n- Kiểm tra hoạt động tool dữ liệu.\n- Thống nhất với các thành viên về các tính năng chính của trang web, các dịch vụ AWS sẽ sử dụng.\nMeeting team báo cáo tiến độ. 07/11/2025 07/11/2025 7 Tiếp tục đào dữ liệu.\nTìm phương pháp giảm chi phí.\nChỉnh sửa sơ đồ kiến trúc để cải thiện chi phí. 08/11/2025 09/11/2025 Kết quả đạt được trong tuần 9: Hoàn thiện Proposal \u0026amp; Yêu cầu chức năng AI: Đã tinh chỉnh lại Proposal dựa trên kiến trúc mới và xây dựng được hàm Lambda để test các bước đầu tiên Thống nhất tính năng, dịch vụ sử dụng: Thống nhất được các tính năng chính cũng như dịch vụ sẽ sử dụng. Nghiên cứu Tối ưu Chi phí: Chủ động tìm kiếm các giải pháp và chỉnh sửa sơ đồ kiến trúc nhằm giảm thiểu chi phí vận hành. Xử lý Dữ liệu: Tiếp tục quá trình xử lý và chuẩn bị dữ liệu, đảm bảo nguồn đầu vào cho các tính năng của dự án. "
},
{
	"uri": "//localhost:1313/vi/4-eventparticipated/4.2-event2/",
	"title": "AI-Driven Development Life Cycle",
	"tags": [],
	"description": "",
	"content": "Reimagining Software Engineering Địa điểm: AWS Event Hall, L26 Bitexco Tower, HCMC\nThời gian: 2PM – 4:30PM Thứ Sáu, ngày 03 tháng 10 năm 2025\nMục Đích Của Sự Kiện Khám phá sự chuyển đổi của Software Development Lifecycle (SDLC) trong kỷ nguyên GenAI. Giới thiệu mô hình AI-Driven Development Lifecycle (AI-DLC) và cách áp dụng trong các dự án thực tế. Trình diễn công cụ Amazon Q Developer và KIRO – AI IDE hỗ trợ từ prototype đến production. Chia sẻ best practices để developers và doanh nghiệp kiểm soát chất lượng khi ứng dụng AI vào toàn bộ quy trình phát triển phần mềm. Danh Sách Diễn Giả Toan Huynh – Senior Specialist Solutions Architect, AWS My Nguyen – Senior Prototyping Architect, AWS Nội Dung Nổi Bật 1. AI-Driven Development Life Cycle \u0026amp; Amazon Q Developer - Toan Huynh Sự phát triển của AI và tác động đến SDLC Tiến hóa của AI: auto-complete → assistant → agents. Mỗi giai đoạn đều thay đổi cách developers học, viết code, test, triển khai và vận hành phần mềm. Dù AI hỗ trợ sâu, developer vẫn phải là owner của sản phẩm: quyết định, phê duyệt chất lượng, chịu trách nhiệm chuyên môn. Hai phương pháp developers sử dụng AI AI-assisted: dùng AI cho các tác vụ hẹp → vẫn hạn chế, không đủ bao quát cả quy trình. AI-managed: AI tham gia toàn bộ quá trình, phối hợp nhiều agents đảm nhiệm nhiều vai trò khác nhau → mô hình tương lai. 7 vấn đề khi dùng AI → sự ra đời của AI-DLC AI-DLC nằm giữa AI-Assisted và AI-Managed. Trong AI-DLC, AI hỗ trợ nhiều task hơn: Planning Architecture suggestions Clarifying requirements Generating scaffolding Refactoring Testing flows Nhưng: developers vẫn phải đảm bảo:\nExpertise Decisions Judgment Validation Core Concepts of AI-DLC Mob development: Mob Elaboration Mob Construction Spec-driven development: hiệu quả nhưng khó tùy biến khi bài toán phức tạp. Mỗi stage cần rõ ràng về context – input – output. Khi làm việc với AI cần yêu cầu ghi log quá trình (không chỉ output cuối). Cần mô tả rõ ràng cho AI: Nêu rõ bạn cần gì Cung cấp tài liệu liên quan Không nên prompt kiểu “đừng làm ABC” AI hoạt động tốt trong các tác vụ cần tính chuẩn chỉnh, cấu trúc rõ → nên tận dụng vào những phần này. Ghi chú quan trọng từ diễn giả Luôn yêu cầu AI tạo plan, sau đó review–refine–repeat liên tục. Chia nhỏ yêu cầu trước khi giao cho AI. Tạo nhiều session tách biệt cho từng task để tránh nhiễu context. 2. KIRO – AI IDE for Prototype to Production - My Nguyen Giới thiệu KIRO AI IDE được thiết kế cho luồng spec → prototype → production. Hỗ trợ spec-driven development tích hợp ngay trong IDE. UI trực quan, dễ quan sát toàn bộ workflow của dự án. Tính năng nổi bật Agent hooks Advanced context management Tracking workflow Tối ưu cho dự án nhỏ (ít tài liệu hơn so với AI-DLC truyền thống) Tích hợp AI-DLC trong KIRO Có thể áp dụng methodology AI-DLC bằng cách: Tạo thư mục steering Đặt workflow AI-DLC (file .md) hoặc rules của công ty Tương thích VSCode, Claude models và nhiều công nghệ mới. Điểm chung của hai phương pháp Cả AI-DLC và KIRO đều dựa trên domain-driven design (DDD) để đảm bảo rõ ràng về boundary, context và logic nghiệp vụ.\nNhững Gì Học Được Tư duy thiết kế AI-driven AI có thể tự động hóa phần lớn tác vụ SDLC, nhưng con người chịu trách nhiệm cuối cùng. Cần thiết kế quy trình rõ ràng: context → inputs → outputs → validation. Quy trình kỹ thuật AI-DLC giúp tự động hóa từ planning đến testing. Mob development + spec-driven giúp củng cố sự minh bạch và kiểm soát chất lượng. Nên lưu lại toàn bộ quá trình AI reasoning để tiện kiểm chứng. Cách làm việc hiệu quả với AI Yêu cầu AI lập kế hoạch chi tiết trước khi làm. Chia nhỏ vấn đề. Tránh nhồi nhét quá nhiều vào một phiên làm việc. Tận dụng thế mạnh AI ở các phần có cấu trúc, yêu cầu tính nhất quán. Công cụ Amazon Q Developer hỗ trợ automation xuyên suốt SDLC. KIRO phù hợp cho các sản phẩm nhỏ và yêu cầu nhanh về prototype–to–production. Ứng Dụng Vào Công Việc Áp dụng AI-DLC vào quy trình hiện tại để giảm thời gian lập kế hoạch, thiết kế và review. Sử dụng Amazon Q Developer để tăng tốc coding, kiến trúc và test. Dùng KIRO cho các dự án yêu cầu xây nhanh prototype hoặc tính trực quan cao. Thiết lập workflow rõ ràng + ghi lại reasoning để đảm bảo kiểm soát chất lượng khi AI tham gia sâu vào SDLC. Trải Nghiệm Trong Sự Kiện Buổi học đem lại góc nhìn rõ ràng về cách GenAI đang thay đổi software engineering.\nCác diễn giả cung cấp phương pháp thực tế, công cụ hiện đại, và hướng triển khai phù hợp cho mọi quy mô dự án.\nViệc kết hợp Amazon Q Developer và KIRO tạo nên bức tranh trọn vẹn về AI-driven development – từ enterprise workflows đến prototype builds.\nMột số hình ảnh khi tham gia sự kiện "
},
{
	"uri": "//localhost:1313/vi/2-proposal/",
	"title": "Bản đề xuất",
	"tags": [],
	"description": "",
	"content": "Nền tảng Smart Contract Assistant - AGREEME Giải pháp AWS Serverless cho việc rà soát hợp đồng cá nhân TEEJ - AGREEME 1. Tóm tắt (Executive Summary) Nền tảng Smart Contract Assistant - AGREEME là một dịch vụ web dành cho cá nhân và các nhóm người dùng nhỏ (freelancer, chủ doanh nghiệp nhỏ, nhân viên văn phòng) làm việc với hợp đồng hằng ngày nhưng không có chuyên môn pháp lý sâu. Giải pháp sử dụng Amazon Bedrock và kiến trúc AWS serverless hoàn toàn để phân tích hợp đồng, làm nổi bật rủi ro, gợi ý chỉnh sửa điều khoản, và tạo tóm tắt cũng như mẫu hợp đồng mới.\nĐược xây dựng trên AWS Amplify, Lambda, API Gateway, DynamoDB, S3, Cognito, EventBridge và CloudWatch, nền tảng cung cấp khả năng rà soát hợp đồng bằng AI với độ trễ thấp, chi phí thấp và bảo mật cao, được tối ưu cho người dùng đơn lẻ hoặc các nhóm nhỏ mà không cần tính năng phức tạp như hệ thống doanh nghiệp.\n2. Vấn đề và giải pháp (Problem Statement) Vấn đề Hợp đồng thường dài, phức tạp và khó hiểu đối với người không có chuyên môn về luật pháp. Việc thuê tư vấn pháp lý cho mỗi hợp đồng tốn kém và không phù hợp để mở rộng cho các cá nhân. Hiện tại vẫn chưa có công cụ tự phục vụ, đơn giản, tập trung vào việc rà soát hợp đồng nhanh và chính xác cho mục đích cá nhân hoặc các doanh nghiệp nhỏ. Người dùng cá nhân hoặc các doanh nghiệp nhỏ không có nhu cầu sử dụng các hệ thống phức tạp hay nền tảng quản lý tài liệu nặng nề; họ chỉ cần kiểm tra rủi ro nhanh với các chỉ dẫn rõ ràng. Giải pháp Nền tảng AGREEME cung cấp một web app sử dụng mô hình AI, nơi người dùng có thể upload file hợp đồng (PDF/DOCX) và nhận được:\nGiải thích về các điều khoản phức tạp bằng ngôn ngữ đơn giản, dễ hiểu. Ngữ cảnh pháp lý với việc đánh dấu các điều khoản có lợi/không có lợi. Phát hiện rủi ro và cảnh báo (điều khoản mất cân bằng, nghĩa vụ ẩn, vấn đề pháp lý tiềm ẩn). Gợi ý chỉnh sửa và câu chữ thay thế ở cấp độ điều khoản để phục vụ đàm phán. Bản tóm tắt điều hành (executive summary) tự động cho người dùng bận rộn. Khả năng tạo hợp đồng đơn giản từ mẫu (thuê nhà, mua bán, dịch vụ, v.v.) với các điều chỉnh dựa trên tình huống thực tế được AI hỗ trợ. Tất cả được vận hành trên kiến trúc AWS Serverless:\nFrontend trên AWS Amplify với Hosting, CDN và WAF tích hợp. APIs \u0026amp; compute thông qua Amazon API Gateway và AWS Lambda. AI sử dụng Amazon Bedrock (GenAI/LLM + embeddings/RAG). Lưu trữ \u0026amp; metadata bằng Amazon S3 và DynamoDB, được mã hóa bởi KMS. Định danh \u0026amp; bảo mật với Amazon Cognito, AWS WAF, IAM và KMS. Giám sát \u0026amp; sự kiện thông qua Amazon CloudWatch và EventBridge. Lợi ích và hoàn vốn đầu tư (Benefits and Return on Investment) Tác động kinh doanh\nGiảm thời gian đọc/hiểu hợp đồng ít nhất ≥ 70%. Giảm chi phí tư vấn pháp lý ít nhất ≥ 50% bằng cách thay thế bước rà soát ban đầu bằng AI. Tăng sự tự tin của người dùng khi ký kết và đàm phán hợp đồng. Hiệu năng kỹ thuật\nĐộ chính xác phân tích hợp đồng ≥ 85% (theo kiểm thử nội bộ và phản hồi người dùng). Thời gian phản hồi ≤ 8 giây sau khi upload. Tỷ lệ uptime hệ thống ≥ 99.9% cho người dùng cá nhân. Hiệu quả chi phí\nChi phí hạ tầng AWS ước tính: $27.90/tháng → $334.80/12 tháng. Nỗ lực triển khai: tổng 592 giờ, ≈ $637.12 cho chi phí nhân sự (Solution Architect + Software Engineer + AI Engineer). 3. Kiến trúc giải pháp (Solution Architecture) Nền tảng được triển khai dưới dạng kiến trúc serverless hoàn toàn, bảo mật và có khả năng mở rộng, được tối ưu cho xử lý tài liệu bằng GenAI và phân tích hợp đồng dựa trên RAG. Kiến trúc tổng thể (High-Level Architecture) Lớp Entry \u0026amp; Web\nAmazon Route 53 cho DNS và tên miền thân thiện. AWS Amplify Hosting cho frontend React/Amplify với CDN và WAF tích hợp. Định danh \u0026amp; Truy cập (Identity \u0026amp; Access)\nAmazon Cognito cho user pool và xác thực (JWT). API Gateway xác thực token Cognito trước khi gọi Lambda. IAM roles đảm bảo nguyên tắc phân quyền tối thiểu cho S3, DynamoDB, Bedrock, KMS và EventBridge. Tầng Backend Compute (Lambda Microservices)\nCore API Lambda để điều phối các yêu cầu từ API Gateway. Các Lambda chuyên biệt cho: Tạo hợp đồng (ContractGen). Gọi LLM tổng quát (tóm tắt, phân loại, chuyển đổi). Tìm kiếm RAG (truy xuất dựa trên embedding và tra cứu tri thức). Cập nhật metadata (DynamoDB). Quản lý template. Tầng AI \u0026amp; LLM\nAmazon Bedrock dùng cho: Phân tích hợp đồng (tóm tắt, rủi ro, phân loại điều khoản). Embeddings và RAG trên kho văn bản pháp luật và các template. Tạo hợp đồng và gợi ý viết lại điều khoản. Dữ liệu \u0026amp; Lưu trữ (Data \u0026amp; Storage)\nAmazon S3 lưu hợp đồng người dùng upload, tài liệu sinh ra và các mẫu hợp đồng, văn bản pháp luật thô. Amazon DynamoDB lưu metadata, template, và chỉ mục RAG. AWS KMS mã hóa dữ liệu lưu trữ cho S3, DynamoDB và secrets. Sự kiện \u0026amp; Tự động hóa (Events \u0026amp; Automation)\nAmazon EventBridge cho các workflow bất đồng bộ (xử lý nền, cập nhật metadata, đồng bộ template). Giám sát \u0026amp; Vận hành (Monitoring \u0026amp; Operations)\nAmazon CloudWatch cho logs, metrics và cảnh báo trên Lambda, API Gateway, Amplify và tương tác với Bedrock. Dịch vụ AWS sử dụng (AWS Services Used) Application Stack\nAWS Amplify (hosting frontend, CI/CD, tích hợp WAF). React / Amplify Framework (UI). Amazon API Gateway (quản lý API). AWS Lambda (backend microservices). Amazon Bedrock (suy luận LLM, embeddings, RAG). Amazon DynamoDB (metadata và kho tri thức). Amazon S3 (lưu trữ tài liệu). AWS KMS (mã hóa). Amazon EventBridge (định tuyến sự kiện). Monitoring \u0026amp; DevOps\nAmazon CloudWatch (quan sát hệ thống, cảnh báo). GitLab + Amplify CI/CD (quản lý mã nguồn và triển khai tự động). Security\nAWS WAF (thông qua Amplify). AWS IAM (kiểm soát truy cập). Amazon Cognito (xác thực). Thiết kế thành phần (Component Design) Web Interface: Ứng dụng React host trên Amplify để upload, xem kết quả phân tích, lịch sử và tạo hợp đồng. API Layer: API Gateway + Lambda để xử lý upload, điều phối Bedrock và trả kết quả. AI Logic: Luồng xử lý sử dụng Bedrock để phân tích điều khoản, chấm điểm rủi ro, tóm tắt và tạo hợp đồng dựa trên template. Data Layer: S3 lưu hợp đồng thô/đã sinh; DynamoDB lưu metadata, template và chỉ mục RAG. Security \u0026amp; Compliance: Xác thực dựa trên Cognito, mã hóa KMS, bảo vệ WAF và chính sách IAM chặt chẽ. 4. Triển khai kỹ thuật (Technical Implementation) Các giai đoạn triển khai (Implementation Phases) Phase 1 – Assessment (Tuần 1–2)\nThu thập yêu cầu kinh doanh và yêu cầu người dùng. Xác định các use case AI (phân tích, phát hiện rủi ro, gợi ý). Thiết kế kiến trúc tổng thể và baseline bảo mật. Phase 2 – Setup Base Infrastructure (Tuần 3–4)\nCấu hình dự án Amplify, IAM roles, S3, DynamoDB, KMS. Bật logging và monitoring bằng CloudWatch. Phase 3 – Frontend \u0026amp; Authentication (Tuần 5–6)\nTriển khai frontend qua Amplify. Tích hợp Cognito và WAF do Amplify quản lý. Xây dựng chức năng upload hợp đồng và giao diện dashboard cơ bản. Phase 4 – Backend Core \u0026amp; AI Integration (Tuần 7–8)\nXây dựng Lambda APIs và tích hợp Bedrock. Parse hợp đồng, lưu kết quả vào DynamoDB và trả lại phân tích cho UI. Phase 5 – Advanced AI Logic \u0026amp; Optimization (Tuần 9–10)\nXây dựng logic phát hiện rủi ro, gợi ý đàm phán và tìm kiếm RAG. Cải thiện UX, tối ưu độ trễ và chi phí. Phase 6 – Testing, Go-Live \u0026amp; Handover (Tuần 11–12)\nViết unit/integration test, kiểm thử bảo mật và hiệu năng. Triển khai production và chuyển giao kiến thức. Yêu cầu kỹ thuật (Technical Requirements) Thành thạo AWS Amplify, Lambda, API Gateway, Cognito, S3, DynamoDB, EventBridge, CloudWatch. Có quyền truy cập Amazon Bedrock (Claude, Cohere, v.v.) để phân tích văn bản pháp lý. Thư viện xử lý file để trích xuất nội dung PDF/DOCX. Chính sách xử lý dữ liệu và quyền riêng tư rõ ràng cho tài liệu hợp đồng nhạy cảm. 5. Timeline \u0026amp; Milestones Tổng thời gian: 12 tuần (6 sprint, mỗi sprint 2 tuần).\nCác sprint:\nSprint 1–2: Assessment \u0026amp; hạ tầng nền tảng. Sprint 3–4: Frontend + authentication. Sprint 5–6: Backend core, tích hợp AI, logic AI nâng cao và tối ưu. Áp dụng Agile liên tục với planning, review và retrospective mỗi sprint.\nChuyển giao kiến thức ở các sprint cuối (kiến trúc, vận hành, CloudWatch, best practices về prompt).\n6. Ước tính ngân sách (Budget Estimation) Chi phí hạ tầng (theo tháng) – Infrastructure Costs (per month) Infrastructure Costs Service Monthly Cost (USD) 12-Month Cost (USD) Amazon S3 $1.80 $21.60 Amazon API Gateway $0.05 $0.60 Amazon DynamoDB $4.02 $48.24 AWS Secrets Manager $1.08 $12.96 Amazon Route 53 $2.04 $24.48 Amazon Cognito $1.00 $12.00 AWS Amplify $16.25 $195.00 Amazon CloudWatch $0.53 $6.36 Amazon Bedrock $1.13 $13.56 Total $27.90/month $334.80/12 months Implementation Team Cost Role Hourly Rate (USD) Solution Architect $2.30/hour Software Engineer $0.70/hour AI Engineer $0.70/hour Total estimated project effort: 592 hours → ≈ $637.12 USD.\n7. Đánh giá rủi ro (Risk Assessment) Rủi ro chính (Key Risks) AI accuracy risk: Mô hình có thể diễn giải sai một số điều khoản pháp lý. File quality risk: File scan chất lượng thấp hoặc PDF phức tạp có thể làm hỏng OCR/parsing. Sensitive data risk: Người dùng có thể upload hợp đồng có mức độ bí mật rất cao. Cloud dependency risk: Sự cố trên Bedrock hoặc Amplify sẽ ảnh hưởng tới khả dụng hệ thống. Usage \u0026amp; cost risk: Khối lượng gọi AI lớn sẽ làm tăng chi phí vận hành. Chiến lược giảm thiểu (Mitigation Strategies) Kiểm thử nội bộ kỹ lưỡng và cung cấp cảnh báo rõ ràng về giới hạn của AI. Xây dựng pipeline xử lý file vững chắc với bước kiểm tra và hướng dẫn người dùng. Mã hóa mạnh (KMS), giới hạn thời gian lưu trữ và kiểm soát truy cập chặt chẽ. Giám sát và cảnh báo qua CloudWatch, kèm theo runbook xử lý sự cố. Tối ưu prompt, giới hạn request và thiết lập budget alert để kiểm soát chi phí AI. 8. Kết quả kỳ vọng (Expected Outcomes) Kết quả kỹ thuật (Technical Outcomes) Trợ lý AI dạng serverless, sẵn sàng production cho cá nhân/nhóm nhỏ. Hiệu năng ổn định với thời gian phân tích ≤ 8 giây và uptime ≥ 99.9%. Xử lý tài liệu nhạy cảm một cách an toàn với mã hóa và phân quyền tối thiểu. Kết quả kinh doanh (Business Outcomes) Tăng tốc độ hiểu hợp đồng và giảm rủi ro pháp lý cho người không chuyên. Giảm đáng kể chi phí tư vấn pháp lý và thời gian rà soát thủ công. Nền tảng SaaS có khả năng mở rộng, có thể phát triển thêm tính năng hoặc nhóm người dùng mới trong các giai đoạn sau. "
},
{
	"uri": "//localhost:1313/vi/5-workshop/5.2-prerequiste/",
	"title": "Các bước chuẩn bị",
	"tags": [],
	"description": "",
	"content": "IAM permissions Gắn IAM permission policy sau vào tài khoản aws user của bạn để triển khai và dọn dẹp tài nguyên trong workshop này.\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;VisualEditor0\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;cloudformation:*\u0026#34;, \u0026#34;cloudwatch:*\u0026#34;, \u0026#34;ec2:AcceptTransitGatewayPeeringAttachment\u0026#34;, \u0026#34;ec2:AcceptTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:AllocateAddress\u0026#34;, \u0026#34;ec2:AssociateAddress\u0026#34;, \u0026#34;ec2:AssociateIamInstanceProfile\u0026#34;, \u0026#34;ec2:AssociateRouteTable\u0026#34;, \u0026#34;ec2:AssociateSubnetCidrBlock\u0026#34;, \u0026#34;ec2:AssociateTransitGatewayRouteTable\u0026#34;, \u0026#34;ec2:AssociateVpcCidrBlock\u0026#34;, \u0026#34;ec2:AttachInternetGateway\u0026#34;, \u0026#34;ec2:AttachNetworkInterface\u0026#34;, \u0026#34;ec2:AttachVolume\u0026#34;, \u0026#34;ec2:AttachVpnGateway\u0026#34;, \u0026#34;ec2:AuthorizeSecurityGroupEgress\u0026#34;, \u0026#34;ec2:AuthorizeSecurityGroupIngress\u0026#34;, \u0026#34;ec2:CreateClientVpnEndpoint\u0026#34;, \u0026#34;ec2:CreateClientVpnRoute\u0026#34;, \u0026#34;ec2:CreateCustomerGateway\u0026#34;, \u0026#34;ec2:CreateDhcpOptions\u0026#34;, \u0026#34;ec2:CreateFlowLogs\u0026#34;, \u0026#34;ec2:CreateInternetGateway\u0026#34;, \u0026#34;ec2:CreateLaunchTemplate\u0026#34;, \u0026#34;ec2:CreateNetworkAcl\u0026#34;, \u0026#34;ec2:CreateNetworkInterface\u0026#34;, \u0026#34;ec2:CreateNetworkInterfacePermission\u0026#34;, \u0026#34;ec2:CreateRoute\u0026#34;, \u0026#34;ec2:CreateRouteTable\u0026#34;, \u0026#34;ec2:CreateSecurityGroup\u0026#34;, \u0026#34;ec2:CreateSubnet\u0026#34;, \u0026#34;ec2:CreateSubnetCidrReservation\u0026#34;, \u0026#34;ec2:CreateTags\u0026#34;, \u0026#34;ec2:CreateTransitGateway\u0026#34;, \u0026#34;ec2:CreateTransitGatewayPeeringAttachment\u0026#34;, \u0026#34;ec2:CreateTransitGatewayPrefixListReference\u0026#34;, \u0026#34;ec2:CreateTransitGatewayRoute\u0026#34;, \u0026#34;ec2:CreateTransitGatewayRouteTable\u0026#34;, \u0026#34;ec2:CreateTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:CreateVpc\u0026#34;, \u0026#34;ec2:CreateVpcEndpoint\u0026#34;, \u0026#34;ec2:CreateVpcEndpointConnectionNotification\u0026#34;, \u0026#34;ec2:CreateVpcEndpointServiceConfiguration\u0026#34;, \u0026#34;ec2:CreateVpnConnection\u0026#34;, \u0026#34;ec2:CreateVpnConnectionRoute\u0026#34;, \u0026#34;ec2:CreateVpnGateway\u0026#34;, \u0026#34;ec2:DeleteCustomerGateway\u0026#34;, \u0026#34;ec2:DeleteFlowLogs\u0026#34;, \u0026#34;ec2:DeleteInternetGateway\u0026#34;, \u0026#34;ec2:DeleteNetworkInterface\u0026#34;, \u0026#34;ec2:DeleteNetworkInterfacePermission\u0026#34;, \u0026#34;ec2:DeleteRoute\u0026#34;, \u0026#34;ec2:DeleteRouteTable\u0026#34;, \u0026#34;ec2:DeleteSecurityGroup\u0026#34;, \u0026#34;ec2:DeleteSubnet\u0026#34;, \u0026#34;ec2:DeleteSubnetCidrReservation\u0026#34;, \u0026#34;ec2:DeleteTags\u0026#34;, \u0026#34;ec2:DeleteTransitGateway\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayPeeringAttachment\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayPrefixListReference\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayRoute\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayRouteTable\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:DeleteVpc\u0026#34;, \u0026#34;ec2:DeleteVpcEndpoints\u0026#34;, \u0026#34;ec2:DeleteVpcEndpointServiceConfigurations\u0026#34;, \u0026#34;ec2:DeleteVpnConnection\u0026#34;, \u0026#34;ec2:DeleteVpnConnectionRoute\u0026#34;, \u0026#34;ec2:Describe*\u0026#34;, \u0026#34;ec2:DetachInternetGateway\u0026#34;, \u0026#34;ec2:DisassociateAddress\u0026#34;, \u0026#34;ec2:DisassociateRouteTable\u0026#34;, \u0026#34;ec2:GetLaunchTemplateData\u0026#34;, \u0026#34;ec2:GetTransitGatewayAttachmentPropagations\u0026#34;, \u0026#34;ec2:ModifyInstanceAttribute\u0026#34;, \u0026#34;ec2:ModifySecurityGroupRules\u0026#34;, \u0026#34;ec2:ModifyTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:ModifyVpcAttribute\u0026#34;, \u0026#34;ec2:ModifyVpcEndpoint\u0026#34;, \u0026#34;ec2:ReleaseAddress\u0026#34;, \u0026#34;ec2:ReplaceRoute\u0026#34;, \u0026#34;ec2:RevokeSecurityGroupEgress\u0026#34;, \u0026#34;ec2:RevokeSecurityGroupIngress\u0026#34;, \u0026#34;ec2:RunInstances\u0026#34;, \u0026#34;ec2:StartInstances\u0026#34;, \u0026#34;ec2:StopInstances\u0026#34;, \u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsEgress\u0026#34;, \u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsIngress\u0026#34;, \u0026#34;iam:AddRoleToInstanceProfile\u0026#34;, \u0026#34;iam:AttachRolePolicy\u0026#34;, \u0026#34;iam:CreateInstanceProfile\u0026#34;, \u0026#34;iam:CreatePolicy\u0026#34;, \u0026#34;iam:CreateRole\u0026#34;, \u0026#34;iam:DeleteInstanceProfile\u0026#34;, \u0026#34;iam:DeletePolicy\u0026#34;, \u0026#34;iam:DeleteRole\u0026#34;, \u0026#34;iam:DeleteRolePolicy\u0026#34;, \u0026#34;iam:DetachRolePolicy\u0026#34;, \u0026#34;iam:GetInstanceProfile\u0026#34;, \u0026#34;iam:GetPolicy\u0026#34;, \u0026#34;iam:GetRole\u0026#34;, \u0026#34;iam:GetRolePolicy\u0026#34;, \u0026#34;iam:ListPolicyVersions\u0026#34;, \u0026#34;iam:ListRoles\u0026#34;, \u0026#34;iam:PassRole\u0026#34;, \u0026#34;iam:PutRolePolicy\u0026#34;, \u0026#34;iam:RemoveRoleFromInstanceProfile\u0026#34;, \u0026#34;lambda:CreateFunction\u0026#34;, \u0026#34;lambda:DeleteFunction\u0026#34;, \u0026#34;lambda:DeleteLayerVersion\u0026#34;, \u0026#34;lambda:GetFunction\u0026#34;, \u0026#34;lambda:GetLayerVersion\u0026#34;, \u0026#34;lambda:InvokeFunction\u0026#34;, \u0026#34;lambda:PublishLayerVersion\u0026#34;, \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:DeleteLogGroup\u0026#34;, \u0026#34;logs:DescribeLogGroups\u0026#34;, \u0026#34;logs:PutRetentionPolicy\u0026#34;, \u0026#34;route53:ChangeTagsForResource\u0026#34;, \u0026#34;route53:CreateHealthCheck\u0026#34;, \u0026#34;route53:CreateHostedZone\u0026#34;, \u0026#34;route53:CreateTrafficPolicy\u0026#34;, \u0026#34;route53:DeleteHostedZone\u0026#34;, \u0026#34;route53:DisassociateVPCFromHostedZone\u0026#34;, \u0026#34;route53:GetHostedZone\u0026#34;, \u0026#34;route53:ListHostedZones\u0026#34;, \u0026#34;route53domains:ListDomains\u0026#34;, \u0026#34;route53domains:ListOperations\u0026#34;, \u0026#34;route53domains:ListTagsForDomain\u0026#34;, \u0026#34;route53resolver:AssociateResolverEndpointIpAddress\u0026#34;, \u0026#34;route53resolver:AssociateResolverRule\u0026#34;, \u0026#34;route53resolver:CreateResolverEndpoint\u0026#34;, \u0026#34;route53resolver:CreateResolverRule\u0026#34;, \u0026#34;route53resolver:DeleteResolverEndpoint\u0026#34;, \u0026#34;route53resolver:DeleteResolverRule\u0026#34;, \u0026#34;route53resolver:DisassociateResolverEndpointIpAddress\u0026#34;, \u0026#34;route53resolver:DisassociateResolverRule\u0026#34;, \u0026#34;route53resolver:GetResolverEndpoint\u0026#34;, \u0026#34;route53resolver:GetResolverRule\u0026#34;, \u0026#34;route53resolver:ListResolverEndpointIpAddresses\u0026#34;, \u0026#34;route53resolver:ListResolverEndpoints\u0026#34;, \u0026#34;route53resolver:ListResolverRuleAssociations\u0026#34;, \u0026#34;route53resolver:ListResolverRules\u0026#34;, \u0026#34;route53resolver:ListTagsForResource\u0026#34;, \u0026#34;route53resolver:UpdateResolverEndpoint\u0026#34;, \u0026#34;route53resolver:UpdateResolverRule\u0026#34;, \u0026#34;s3:AbortMultipartUpload\u0026#34;, \u0026#34;s3:CreateBucket\u0026#34;, \u0026#34;s3:DeleteBucket\u0026#34;, \u0026#34;s3:DeleteObject\u0026#34;, \u0026#34;s3:GetAccountPublicAccessBlock\u0026#34;, \u0026#34;s3:GetBucketAcl\u0026#34;, \u0026#34;s3:GetBucketOwnershipControls\u0026#34;, \u0026#34;s3:GetBucketPolicy\u0026#34;, \u0026#34;s3:GetBucketPolicyStatus\u0026#34;, \u0026#34;s3:GetBucketPublicAccessBlock\u0026#34;, \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:GetObjectVersion\u0026#34;, \u0026#34;s3:GetBucketVersioning\u0026#34;, \u0026#34;s3:ListAccessPoints\u0026#34;, \u0026#34;s3:ListAccessPointsForObjectLambda\u0026#34;, \u0026#34;s3:ListAllMyBuckets\u0026#34;, \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:ListBucketMultipartUploads\u0026#34;, \u0026#34;s3:ListBucketVersions\u0026#34;, \u0026#34;s3:ListJobs\u0026#34;, \u0026#34;s3:ListMultipartUploadParts\u0026#34;, \u0026#34;s3:ListMultiRegionAccessPoints\u0026#34;, \u0026#34;s3:ListStorageLensConfigurations\u0026#34;, \u0026#34;s3:PutAccountPublicAccessBlock\u0026#34;, \u0026#34;s3:PutBucketAcl\u0026#34;, \u0026#34;s3:PutBucketPolicy\u0026#34;, \u0026#34;s3:PutBucketPublicAccessBlock\u0026#34;, \u0026#34;s3:PutObject\u0026#34;, \u0026#34;secretsmanager:CreateSecret\u0026#34;, \u0026#34;secretsmanager:DeleteSecret\u0026#34;, \u0026#34;secretsmanager:DescribeSecret\u0026#34;, \u0026#34;secretsmanager:GetSecretValue\u0026#34;, \u0026#34;secretsmanager:ListSecrets\u0026#34;, \u0026#34;secretsmanager:ListSecretVersionIds\u0026#34;, \u0026#34;secretsmanager:PutResourcePolicy\u0026#34;, \u0026#34;secretsmanager:TagResource\u0026#34;, \u0026#34;secretsmanager:UpdateSecret\u0026#34;, \u0026#34;sns:ListTopics\u0026#34;, \u0026#34;ssm:DescribeInstanceProperties\u0026#34;, \u0026#34;ssm:DescribeSessions\u0026#34;, \u0026#34;ssm:GetConnectionStatus\u0026#34;, \u0026#34;ssm:GetParameters\u0026#34;, \u0026#34;ssm:ListAssociations\u0026#34;, \u0026#34;ssm:ResumeSession\u0026#34;, \u0026#34;ssm:StartSession\u0026#34;, \u0026#34;ssm:TerminateSession\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Khởi tạo tài nguyên bằng CloudFormation Trong lab này, chúng ta sẽ dùng N.Virginia region (us-east-1).\nĐể chuẩn bị cho môi trường làm workshop, chúng ta deploy CloudFormation template sau (click link): PrivateLinkWorkshop . Để nguyên các lựa chọn mặc định.\nLựa chọn 2 mục acknowledgement Chọn Create stack Quá trình triển khai CloudFormation cần khoảng 15 phút để hoàn thành.\n2 VPCs đã được tạo 3 EC2s đã được tạo "
},
{
	"uri": "//localhost:1313/vi/5-workshop/5.3-s3-vpc/5.3.2-test-gwe/",
	"title": "Kiểm tra Gateway Endpoint",
	"tags": [],
	"description": "",
	"content": "Tạo S3 bucket Đi đến S3 management console Trong Bucket console, chọn Create bucket Trong Create bucket console Đặt tên bucket: chọn 1 tên mà không bị trùng trong phạm vi toàn cầu (gợi ý: lab\u0026lt;số-lab\u0026gt;\u0026lt;tên-bạn\u0026gt;) Giữ nguyên giá trị của các fields khác (default) Kéo chuột xuống và chọn Create bucket Tạo thành công S3 bucket Kết nối với EC2 bằng session manager Trong workshop này, bạn sẽ dùng AWS Session Manager để kết nối đến các EC2 instances. Session Manager là 1 tính năng trong dịch vụ Systems Manager được quản lý hoàn toàn bởi AWS. System manager cho phép bạn quản lý Amazon EC2 instances và các máy ảo on-premises (VMs)thông qua 1 browser-based shell. Session Manager cung cấp khả năng quản lý phiên bản an toàn và có thể kiểm tra mà không cần mở cổng vào, duy trì máy chủ bastion host hoặc quản lý khóa SSH.\nFirst cloud journey Lab để hiểu sâu hơn về Session manager.\nTrong AWS Management Console, gõ Systems Manager trong ô tìm kiếm và nhấn Enter: Từ Systems Manager menu, tìm Node Management ở thanh bên trái và chọn Session Manager: Click Start Session, và chọn EC2 instance tên Test-Gateway-Endpoint. Phiên bản EC2 này đã chạy trong \u0026ldquo;VPC cloud\u0026rdquo; và sẽ được dùng để kiểm tra khả năng kết nối với Amazon S3 thông qua điểm cuối Cổng mà bạn vừa tạo (s3-gwe).\nSession Manager sẽ mở browser tab mới với shell prompt: sh-4.2 $\nBạn đã bắt đầu phiên kết nối đến EC2 trong VPC Cloud thành công. Trong bước tiếp theo, chúng ta sẽ tạo một S3 bucket và một tệp trong đó.\nCreate a file and upload to s3 bucket Đổi về ssm-user\u0026rsquo;s thư mục bằng lệnh \u0026ldquo;cd ~\u0026rdquo; Tạo 1 file để kiểm tra bằng lệnh \u0026ldquo;fallocate -l 1G testfile.xyz\u0026rdquo;, 1 file tên \u0026ldquo;testfile.xyz\u0026rdquo; có kích thước 1GB sẽ được tạo. Tải file mình vừa tạo lên S3 với lệnh \u0026ldquo;aws s3 cp testfile.xyz s3://your-bucket-name\u0026rdquo;. Thay your-bucket-name bằng tên S3 bạn đã tạo. Bạn đã tải thành công tệp lên bộ chứa S3 của mình. Bây giờ bạn có thể kết thúc session.\nKiểm tra object trong S3 bucket Đi đến S3 console. Click tên s3 bucket của bạn Trong Bucket console, bạn sẽ thấy tệp bạn đã tải lên S3 bucket của mình Tóm tắt Chúc mừng bạn đã hoàn thành truy cập S3 từ VPC. Trong phần này, bạn đã tạo gateway endpoint cho Amazon S3 và sử dụng AWS CLI để tải file lên. Quá trình tải lên hoạt động vì gateway endpoint cho phép giao tiếp với S3 mà không cần Internet gateway gắn vào \u0026ldquo;VPC Cloud\u0026rdquo;. Điều này thể hiện chức năng của gateway endpoint như một đường dẫn an toàn đến S3 mà không cần đi qua pub lic Internet.\n"
},
{
	"uri": "//localhost:1313/vi/5-workshop/5.4-s3-onprem/5.4.2-create-interface-enpoint/",
	"title": "Tạo một S3 Interface endpoint",
	"tags": [],
	"description": "",
	"content": "Trong phần này, bạn sẽ tạo và kiểm tra Interface Endpoint S3 bằng cách sử dụng môi trường truyền thống mô phỏng.\nQuay lại Amazon VPC menu. Trong thanh điều hướng bên trái, chọn Endpoints, sau đó click Create Endpoint.\nTrong Create endpoint console:\nĐặt tên interface endpoint Trong Service category, chọn aws services Trong Search box, gõ S3 và nhấn Enter. Chọn endpoint có tên com.amazonaws.us-east-1.s3. Đảm bảo rằng cột Type có giá trị Interface. Đối với VPC, chọn VPC Cloud từ drop-down. Đảm bảo rằng bạn chọn \u0026ldquo;VPC Cloud\u0026rdquo; và không phải \u0026ldquo;VPC On-prem\u0026rdquo;\nMở rộng Additional settings và đảm bảo rằng Enable DNS name không được chọn (sẽ sử dụng điều này trong phần tiếp theo của workshop) Chọn 2 subnets trong AZs sau: us-east-1a and us-east-1b Đối với Security group, chọn SGforS3Endpoint: Giữ default policy - full access và click Create endpoint Chúc mừng bạn đã tạo thành công S3 interface endpoint. Ở bước tiếp theo, chúng ta sẽ kiểm tra interface endpoint.\n"
},
{
	"uri": "//localhost:1313/vi/3-blogstranslated/3.2-blog2/",
	"title": "Tối ưu hóa việc truy cập thay đổi nội dung xếp hạng ISO với Verisk Rating Insights và Amazon Bedrock",
	"tags": [],
	"description": "",
	"content": "Bởi Samit Verma, Eusha Rizvi, Manmeet Singh, Troy Smith, Corey Finley, Arun Pradeep Selvaraj, và Ryan Doty – đăng ngày 16 tháng 9 năm 2025| Chủ đề: Amazon Bedrock, Amazon ElastiCache, Amazon OpenSearch Service, Artificial Intelligence, Customer Solutions, Generative AI\nBài viết này được đồng tác giả bởi Samit Verma, Eusha Rizvi, Manmeet Singh, Troy Smith, và Corey Finley từ Verisk.\nVerisk Rating Insights, là một tính năng thuộc ISO Electronic Rating Content (ERC) — một công cụ mạnh mẽ được thiết kế để cung cấp tóm tắt về các thay đổi trong ISO Rating giữa hai phiên bản phát hành.\nTrước đây, việc trích xuất thông tin cụ thể từ hồ sơ hoặc xác định sự khác biệt giữa nhiều phiên bản đòi hỏi người dùng phải tải xuống thủ công toàn bộ gói dữ liệu, một quy trình mất thời gian và dễ xảy ra sai sót.\nThách thức này, kết hợp với nhu cầu về độ chính xác cao và hỗ trợ khách hàng kịp thời, đã thúc đẩy Verisk tìm kiếm các phương pháp đổi mới nhằm nâng cao khả năng truy cập và tự động hóa các quy trình lặp lại.\nBằng việc sử dụng trí tuệ nhân tạo sinh (Generative AI) và các dịch vụ từ Amazon Web Services (AWS), Verisk đã đạt được những bước tiến đáng kể trong việc xây dựng giao diện hội thoại thông minh, giúp người dùng truy xuất thông tin nhanh chóng, xác định khác biệt nội dung, và nâng cao hiệu suất vận hành tổng thể.\nTrong bài viết này, chúng ta sẽ tìm hiểu cách Verisk Rating Insights, được hỗ trợ bởi Amazon Bedrock, mô hình ngôn ngữ lớn (LLM), và Retrieval Augmented Generation (RAG), đang thay đổi cách khách hàng tương tác và truy cập các thay đổi trong nội dung ISO ERC.\nThách thức\nRating Insights cung cấp nội dung có giá trị, nhưng có những thách thức đáng kể về khả năng tiếp cận của người dùng và thời gian cần thiết để trích xuất thông tin chi tiết có thể hành động:\nTải xuống thủ công – Khách hàng phải tải xuống toàn bộ gói để có được một phần nhỏ thông tin liên quan. Điều này không hiệu quả, đặc biệt khi chỉ cần xem xét một phần của hồ sơ. Truy xuất dữ liệu không hiệu quả – Người dùng không thể nhanh chóng xác định sự khác biệt giữa hai gói nội dung mà không cần tải xuống và so sánh thủ công, có thể mất hàng giờ và đôi khi là nhiều ngày phân tích. Hỗ trợ khách hàng tốn thời gian – Nhóm hỗ trợ khách hàng ERC của Verisk đã dành 15% thời gian hàng tuần để giải quyết các truy vấn từ những khách hàng bị ảnh hưởng bởi những sự thiếu hiệu quả này. Hơn nữa, việc giới thiệu khách hàng mới yêu cầu nửa ngày đào tạo lặp đi lặp lại để đảm bảo họ hiểu cách truy cập và diễn giải dữ liệu. Thời gian phân tích thủ công – Khách hàng thường dành 3–4 giờ cho mỗi trường hợp thử nghiệm để phân tích sự khác biệt giữa các hồ sơ. Với nhiều trường hợp thử nghiệm cần giải quyết, điều này dẫn đến sự chậm trễ đáng kể trong việc ra quyết định quan trọng. Tổng quan giải pháp\nĐể giải quyết những thách thức này, Verisk đã bắt tay vào hành trình nâng cao Rating Insights bằng các công nghệ AI tạo sinh. Bằng cách tích hợp Anthropic’s Claude, có sẵn trong Amazon Bedrock và Amazon OpenSearch Service, Verisk đã tạo ra một nền tảng hội thoại tinh vi nơi người dùng có thể dễ dàng truy cập và phân tích các thay đổi nội dung xếp hạng.\nSơ đồ sau minh họa kiến trúc cấp cao của giải pháp, với các phần riêng biệt hiển thị quy trình nhập dữ liệu và vòng lặp suy luận. Kiến trúc sử dụng nhiều dịch vụ AWS để thêm khả năng AI tạo sinh vào hệ thống Ratings Insight. Các thành phần của hệ thống này hoạt động cùng nhau một cách liền mạch, điều phối nhiều lệnh gọi LLM để tạo phản hồi cho người dùng.\nSơ đồ sau cho thấy các thành phần kiến trúc và các bước cấp cao liên quan đến quy trình nhập dữ liệu.\nCác bước trong quy trình nhập dữ liệu diễn ra như sau:\nQuá trình này được kích hoạt khi một tệp mới được thả vào. Nó chịu trách nhiệm phân đoạn tài liệu bằng cách sử dụng chiến lược phân đoạn tùy chỉnh. Chiến lược này kiểm tra đệ quy từng phần và giữ chúng nguyên vẹn mà không chồng chéo. Sau đó, quá trình nhúng các đoạn và lưu trữ chúng trong OpenSearch Service dưới dạng nhúng vectơ. Mô hình nhúng được sử dụng trong Amazon Bedrock là amazon titan-embed-g1-text-02. Amazon OpenSearch Serverless được sử dụng làm kho lưu trữ nhúng vectơ với khả năng lọc siêu dữ liệu. Sơ đồ sau cho thấy các thành phần kiến trúc và các bước cấp cao liên quan đến vòng lặp suy luận để tạo phản hồi cho người dùng.\nCác bước trong vòng lặp suy luận diễn ra như sau:\nThành phần này chịu trách nhiệm thực hiện nhiều tác vụ: nó bổ sung các câu hỏi của người dùng bằng lịch sử trò chuyện gần đây, nhúng các câu hỏi, truy xuất các đoạn liên quan từ cơ sở dữ liệu vectơ và cuối cùng gọi mô hình tạo sinh để tổng hợp phản hồi. Amazon ElastiCache được sử dụng để lưu trữ lịch sử trò chuyện gần đây. Mô hình nhúng được sử dụng trong Amazon Bedrock là amazon titan-embed-g1-text-02. OpenSearch Serverless được triển khai cho RAG (Retrieval-Augmented Generation). Để tạo phản hồi cho các truy vấn của người dùng, hệ thống sử dụng Anthropic’s Claude Sonnet 3.5 (ID mô hình: anthropic.claude-3-5-sonnet-20240620-v1:0), có sẵn thông qua Amazon Bedrock. Các công nghệ và khung công tác chính được sử dụng\nChúng tôi đã sử dụng Anthropic’s Claude Sonnet 3.5 (ID mô hình: anthropic.claude-3-5-sonnet-20240620-v1:0) để hiểu đầu vào của người dùng và cung cấp các phản hồi chi tiết, có liên quan theo ngữ cảnh. Anthropic’s Claude Sonnet 3.5 nâng cao khả năng của nền tảng để diễn giải các truy vấn của người dùng và cung cấp thông tin chi tiết chính xác từ các thay đổi nội dung phức tạp. LlamaIndex, một khung công tác mã nguồn mở, đóng vai trò là khung chuỗi để kết nối và quản lý hiệu quả các nguồn dữ liệu khác nhau nhằm cho phép truy xuất nội dung và thông tin chi tiết một cách linh hoạt.\nChúng tôi đã triển khai RAG, cho phép mô hình kéo dữ liệu cụ thể, có liên quan từ cơ sở dữ liệu vectơ OpenSearch Serverless. Điều này có nghĩa là hệ thống tạo ra các phản hồi chính xác, cập nhật dựa trên truy vấn của người dùng mà không cần phải sàng lọc các bản tải xuống nội dung khổng lồ. Cơ sở dữ liệu vectơ cho phép tìm kiếm và truy xuất thông minh, tổ chức các thay đổi nội dung theo cách giúp chúng có thể truy cập nhanh chóng và dễ dàng. Điều này loại bỏ nhu cầu tìm kiếm thủ công hoặc tải xuống toàn bộ gói nội dung. Verisk đã áp dụng các biện pháp bảo vệ trong Amazon Bedrock Guardrails cùng với các biện pháp bảo vệ tùy chỉnh xung quanh mô hình tạo sinh để đầu ra tuân thủ các tiêu chuẩn chất lượng và tuân thủ cụ thể, bảo vệ tính toàn vẹn của các phản hồi.\nGiải pháp AI tạo sinh của Verisk là một dịch vụ toàn diện, an toàn và linh hoạt để xây dựng các ứng dụng và tác nhân AI tạo sinh. Amazon Bedrock kết nối bạn với các FM hàng đầu, các dịch vụ để triển khai và vận hành tác nhân, và các công cụ để tinh chỉnh, bảo vệ và tối ưu hóa các mô hình cùng với các cơ sở kiến thức để kết nối các ứng dụng với dữ liệu mới nhất của bạn để bạn có mọi thứ bạn cần để nhanh chóng chuyển từ thử nghiệm sang triển khai thực tế.\nVới sự mới lạ của AI tạo sinh, Verisk đã thành lập một hội đồng quản trị để giám sát các giải pháp của mình, đảm bảo chúng đáp ứng các tiêu chuẩn bảo mật, tuân thủ và sử dụng dữ liệu. Verisk đã triển khai các biện pháp kiểm soát chặt chẽ trong đường ống RAG để đảm bảo dữ liệu chỉ có thể truy cập được đối với những người dùng được ủy quyền. Điều này giúp duy trì tính toàn vẹn và quyền riêng tư của thông tin nhạy cảm. Các đánh giá pháp lý đảm bảo bảo vệ IP và tuân thủ hợp đồng.\nCách hoạt động\nViệc tích hợp các công nghệ tiên tiến này cho phép trải nghiệm liền mạch, thân thiện với người dùng. Đây là cách Verisk Rating Insights hiện hoạt động đối với khách hàng:\nGiao diện người dùng hội thoại – Người dùng có thể tương tác với nền tảng bằng cách sử dụng giao diện hội thoại. Thay vì xem xét thủ công các gói nội dung, người dùng nhập một truy vấn ngôn ngữ tự nhiên (ví dụ: “Những thay đổi về phạm vi bảo hiểm giữa hai hồ sơ gần đây là gì?”). Hệ thống sử dụng Anthropic’s Claude Sonnet 3.5 để hiểu ý định và cung cấp tóm tắt tức thì về các thay đổi liên quan. Truy xuất nội dung động – Nhờ RAG và OpenSearch Service, nền tảng không yêu cầu tải xuống toàn bộ tệp. Thay vào đó, nó tự động truy xuất và trình bày các thay đổi cụ thể mà người dùng đang tìm kiếm, cho phép phân tích và ra quyết định nhanh hơn. Phân tích sự khác biệt tự động – Hệ thống có thể tự động so sánh hai gói nội dung, làm nổi bật sự khác biệt mà không cần can thiệp thủ công. Người dùng có thể truy vấn để so sánh chính xác (ví dụ: “Cho tôi xem sự khác biệt về tiêu chí xếp hạng giữa Bản phát hành 1 và Bản phát hành 2”). Thông tin chi tiết tùy chỉnh – Các biện pháp bảo vệ được áp dụng có nghĩa là các phản hồi chính xác, tuân thủ và có thể hành động. Ngoài ra, nếu cần, hệ thống có thể giúp người dùng hiểu tác động của các thay đổi và hỗ trợ họ điều hướng sự phức tạp của các hồ sơ, cung cấp thông tin chi tiết rõ ràng, súc tích. Sơ đồ sau cho thấy các thành phần kiến trúc và các bước cấp cao liên quan đến vòng lặp đánh giá để tạo ra các phản hồi có liên quan và có cơ sở.\nCác bước trong vòng lặp đánh giá diễn ra như sau:\nThành phần này chịu trách nhiệm gọi mô hình Anthropic’s Claude Sonnet 3.5 và sau đó gọi các API đánh giá tùy chỉnh để đảm bảo độ chính xác của phản hồi. Mô hình tạo sinh được sử dụng là Anthropic’s Claude Sonnet 3.5, xử lý việc tạo ra các phản hồi. API đánh giá đảm bảo rằng các phản hồi vẫn phù hợp với các truy vấn của người dùng và vẫn nằm trong ngữ cảnh được cung cấp. Sơ đồ sau cho thấy quá trình ghi lại lịch sử trò chuyện làm bộ nhớ ngữ cảnh và lưu trữ để phân tích.\nCác tiêu chuẩn chất lượng\nNhóm Verisk Rating Insights đã triển khai một khung đánh giá toàn diện và cơ chế vòng lặp phản hồi tương ứng, được hiển thị trong các hình trên, để hỗ trợ cải tiến liên tục và giải quyết các vấn đề có thể phát sinh.\nĐảm bảo độ chính xác và nhất quán cao trong các phản hồi là điều cần thiết đối với các giải pháp AI tạo sinh của Verisk. Tuy nhiên, LLM đôi khi có thể tạo ra ảo giác hoặc cung cấp các chi tiết không liên quan, ảnh hưởng đến độ tin cậy. Để giải quyết vấn đề này, Verisk đã triển khai:\nKhung đánh giá – Được tích hợp vào đường ống truy vấn, nó xác thực các phản hồi về độ chính xác và mức độ liên quan trước khi phân phối. Kiểm tra rộng rãi – Các chuyên gia về chủ đề sản phẩm (SME) và chuyên gia chất lượng đã kiểm tra nghiêm ngặt giải pháp để đảm bảo độ chính xác và độ tin cậy. Verisk đã hợp tác với các chuyên gia về lĩnh vực bảo hiểm nội bộ để phát triển các số liệu đánh giá SME về độ chính xác và tính nhất quán. Nhiều vòng đánh giá SME đã được thực hiện, trong đó các chuyên gia chấm điểm các số liệu này trên thang điểm từ 1–10. Độ trễ cũng được theo dõi để đánh giá tốc độ. Phản hồi từ mỗi vòng được đưa vào các thử nghiệm tiếp theo để thúc đẩy cải tiến. Cải tiến mô hình liên tục – Sử dụng phản hồi của khách hàng đóng vai trò là một thành phần quan trọng trong việc thúc đẩy sự phát triển và tinh chỉnh liên tục của các mô hình tạo sinh, cải thiện cả độ chính xác và mức độ liên quan. Bằng cách tích hợp liền mạch các tương tác và phản hồi của người dùng với lịch sử trò chuyện, một đường ống dữ liệu mạnh mẽ được tạo ra để truyền các tương tác của người dùng đến một Amazon Simple Storage Service (Amazon S3) bucket, hoạt động như một trung tâm dữ liệu. Các tương tác sau đó đi vào Snowflake, là một nền tảng dữ liệu dựa trên đám mây và kho dữ liệu dưới dạng dịch vụ cung cấp các khả năng như kho dữ liệu, hồ dữ liệu, chia sẻ dữ liệu và trao đổi dữ liệu. Thông qua việc tích hợp này, chúng tôi đã xây dựng các bảng điều khiển phân tích toàn diện cung cấp thông tin chi tiết có giá trị về các mẫu trải nghiệm người dùng và các điểm khó khăn. Mặc dù kết quả ban đầu đầy hứa hẹn, nhưng chúng không đạt được mức độ chính xác và nhất quán mong muốn. Quá trình phát triển bao gồm một số cải tiến lặp đi lặp lại, chẳng hạn như thiết kế lại hệ thống và thực hiện nhiều lệnh gọi đến LLM. Số liệu chính để thành công là một hệ thống chấm điểm thủ công, nơi các chuyên gia kinh doanh so sánh kết quả và cung cấp phản hồi liên tục để cải thiện các tiêu chuẩn tổng thể.\nTác động và cơ hội kinh doanh\nBằng cách tích hợp AI tạo sinh vào Verisk Rating Insights, doanh nghiệp đã chứng kiến một sự chuyển đổi đáng kể. Khách hàng đã tiết kiệm đáng kể thời gian. Bằng cách loại bỏ nhu cầu tải xuống toàn bộ gói và tìm kiếm sự khác biệt theo cách thủ công, thời gian dành cho phân tích đã giảm đáng kể. Khách hàng không còn mất 3–4 giờ cho mỗi trường hợp thử nghiệm. Những gì trước đây mất nhiều ngày giờ đây chỉ mất vài phút.\nViệc tiết kiệm thời gian này mang lại năng suất tăng lên. Với một giải pháp tự động cung cấp thông tin chi tiết liên quan ngay lập tức, khách hàng có thể tập trung nhiều hơn vào việc ra quyết định thay vì dành thời gian truy xuất dữ liệu thủ công. Và bằng cách tự động hóa phân tích sự khác biệt và cung cấp một nền tảng tập trung, dễ dàng, khách hàng có thể tự tin hơn vào độ chính xác của kết quả và tránh bỏ lỡ những thay đổi quan trọng.\nĐối với Verisk, lợi ích là giảm gánh nặng hỗ trợ khách hàng vì nhóm hỗ trợ khách hàng ERC hiện dành ít thời gian hơn để giải quyết các truy vấn. Với giao diện hội thoại được hỗ trợ bởi AI, người dùng có thể tự phục vụ và nhận câu trả lời trong thời gian thực, giải phóng tài nguyên hỗ trợ cho các yêu cầu phức tạp hơn.\nViệc tự động hóa các tác vụ đào tạo lặp đi lặp lại có nghĩa là giới thiệu khách hàng nhanh hơn và hiệu quả hơn. Điều này làm giảm nhu cầu về các buổi đào tạo dài dòng, và khách hàng mới nhanh chóng trở nên thành thạo hơn. Việc tích hợp AI tạo sinh đã giảm các quy trình làm việc dư thừa và nhu cầu can thiệp thủ công. Điều này hợp lý hóa các hoạt động trên nhiều phòng ban, dẫn đến một doanh nghiệp linh hoạt và phản ứng nhanh hơn.\nKết luận\nTrong tương lai, Verisk có kế hoạch tiếp tục nâng cao nền tảng Rating Insights theo hai hướng. Thứ nhất, chúng tôi sẽ mở rộng phạm vi truy vấn, cho phép các truy vấn phức tạp hơn liên quan đến các loại hồ sơ khác nhau và các lĩnh vực bảo hiểm tinh tế hơn. Thứ hai, chúng tôi sẽ mở rộng quy mô nền tảng. Với Amazon Bedrock cung cấp cơ sở hạ tầng, Verisk đặt mục tiêu mở rộng giải pháp này hơn nữa để hỗ trợ nhiều người dùng và các bộ nội dung bổ sung trên các dòng sản phẩm khác nhau.\nVerisk Rating Insights, hiện được hỗ trợ bởi AI tạo sinh và các công nghệ AWS, đã thay đổi cách khách hàng tương tác và truy cập các thay đổi nội dung xếp hạng. Thông qua giao diện người dùng hội thoại, RAG và cơ sở dữ liệu vectơ, Verisk có ý định loại bỏ sự thiếu hiệu quả và tiết kiệm thời gian và tài nguyên quý giá cho khách hàng đồng thời nâng cao khả năng tiếp cận tổng thể. Đối với Verisk, giải pháp này đã cải thiện hiệu quả hoạt động và cung cấp một nền tảng vững chắc cho sự đổi mới liên tục.\nVới Amazon Bedrock và sự tập trung vào tự động hóa, Verisk đang thúc đẩy tương lai của hỗ trợ khách hàng thông minh và quản lý nội dung, trao quyền cho cả khách hàng và đội ngũ nội bộ của họ để đưa ra các quyết định thông minh hơn, nhanh hơn.\nĐể biết thêm thông tin, hãy tham khảo các tài nguyên sau:\nKhám phá AI tạo sinh trên AWS Tìm hiểu về khai thác giá trị kinh doanh của AI tạo sinh Tìm hiểu thêm về các mô hình Claude 3 của Anthropic trên Amazon Bedrock Tìm hiểu về Amazon Bedrock và cách xây dựng và mở rộng các ứng dụng AI tạo sinh với FM Khám phá các bằng chứng khái niệm khởi động nhanh AI tạo sinh Về các tác giả\nSamit Verma là Giám đốc Kỹ thuật Phần mềm tại Verisk, giám sát các nhóm phát triển Xếp hạng và Bảo hiểm. Trong vai trò này, ông đóng vai trò quan trọng trong thiết kế kiến trúc và cung cấp định hướng chiến lược cho nhiều nhóm phát triển, nâng cao hiệu quả và đảm bảo khả năng duy trì giải pháp lâu dài. Ông có bằng thạc sĩ về công nghệ thông tin. Eusha Rizvi là Giám đốc Phát triển Phần mềm tại Verisk, lãnh đạo một số nhóm công nghệ trong bộ phận Sản phẩm Xếp hạng. Với chuyên môn vững chắc về thiết kế, kiến trúc và kỹ thuật hệ thống, Eusha cung cấp hướng dẫn thiết yếu để thúc đẩy sự phát triển của các giải pháp đổi mới. Ông có bằng cử nhân về hệ thống thông tin từ Đại học Stony Brook. Manmeet Singh là Trưởng nhóm Kỹ thuật Phần mềm tại Verisk và là Chuyên gia AI tạo sinh được chứng nhận AWS. Ông lãnh đạo việc phát triển một hệ thống AI tạo sinh dựa trên RAG trên Amazon Bedrock, với chuyên môn về điều phối LLM, kỹ thuật nhắc nhở, cơ sở dữ liệu vectơ, vi dịch vụ và kiến trúc có độ khả dụng cao. Manmeet đam mê áp dụng các công nghệ AI và điện toán đám mây tiên tiến để cung cấp các hệ thống linh hoạt, có khả năng mở rộng và quan trọng đối với doanh nghiệp. Troy Smith là Phó Chủ tịch Giải pháp Xếp hạng tại Verisk. Troy là một nhà lãnh đạo công nghệ bảo hiểm dày dạn kinh nghiệm với hơn 25 năm kinh nghiệm trong chiến lược xếp hạng, định giá và sản phẩm. Tại Verisk, ông lãnh đạo nhóm đứng sau ISO Electronic Rating Content, một tài nguyên được sử dụng rộng rãi trong ngành bảo hiểm. Troy đã giữ các vai trò lãnh đạo tại Earnix và Capgemini và là người đồng sáng lập và tạo ra công cụ Oracle Insbridge Rating Engine ban đầu. Corey Finley là Giám đốc Sản phẩm tại Verisk. Corey có hơn 22 năm kinh nghiệm trong lĩnh vực bảo hiểm cá nhân và thương mại. Ông đã làm việc trong cả vai trò triển khai và hỗ trợ sản phẩm và đã dẫn dắt các nỗ lực cho các hãng vận tải lớn bao gồm Allianz, CNA, Citizens và những hãng khác. Tại Verisk, ông giữ chức Giám đốc Sản phẩm cho VRI, RaaS và ERC. Arun Pradeep Selvaraj là Kiến trúc sư Giải pháp cấp cao tại Amazon Web Services (AWS). Arun đam mê làm việc với khách hàng và các bên liên quan của mình về chuyển đổi kỹ thuật số và đổi mới trên đám mây trong khi tiếp tục học hỏi, xây dựng và đổi mới. Ông là người sáng tạo, năng động, tận tâm với khách hàng và sử dụng quy trình làm việc ngược để xây dựng các kiến trúc hiện đại nhằm giúp khách hàng giải quyết những thách thức độc đáo của họ. Kết nối với ông trên LinkedIn. Ryan Doty là Giám đốc Kiến trúc sư Giải pháp tại Amazon Web Services (AWS), có trụ sở tại New York. Ông giúp khách hàng dịch vụ tài chính đẩy nhanh việc áp dụng AWS Cloud bằng cách cung cấp các hướng dẫn kiến trúc để thiết kế các giải pháp sáng tạo và có khả năng mở rộng. Đến từ nền tảng phát triển phần mềm và kỹ thuật bán hàng, những khả năng mà đám mây có thể mang lại cho thế giới khiến ông rất hào hứng. "
},
{
	"uri": "//localhost:1313/vi/1-worklog/1.10-week10/",
	"title": "Worklog Tuần 10",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 10: Hoàn thiện Proposal. Tiếp tục lập trình các hàm Lambda, hoàn thiện các tính năng đã đề ra. Hoàn thiện quy trình chuẩn hóa dữ liệu, kỹ thuật sử dụng RAG, quá trình chunking, tạo các quy trình tự động hóa. Tham gia sự kiện của AWS để cập nhật kiến thức về AI/ML/GenAI. Công việc đã thực hiện trong tuần: Day Task Start Date Completion Date Reference Material 2 Hoàn thiện Proposal và kiến trúc dựa trên feedback. 10/11/2025 11/11/2025 3 Meeting team báo cáo hằng tuần. 11/11/2025 11/11/2025 4 - 6 Thu thập và chuẩn hóa dữ liệu, viết code thử nghiệm embedding và RAG Lập trình hàm Lambda 12/11/2025 14/11/2025 7 Event - AWS Cloud Mastery Series #1: AI/ML/GenAI on AWS\nFigma: Review \u0026amp; Analysis pages 15/11/2025 15/11/2025 CN Figma: Review \u0026amp; Analysis pages (tiếp tục) 16/11/2025 16/11/2025 Kết quả đạt được trong tuần 10: Chốt Proposal và Kiến trúc: Đã hoàn thiện tài liệu Proposal và sơ đồ kiến trúc cuối cùng sau khi tiếp thu các phản hồi. Cập nhật Kiến thức Chuyên sâu: Tham gia sự kiện AWS Cloud Mastery Series, tiếp thu được nhiều kiến thức mới và giá trị về các công nghệ AI/ML và GenAI trên nền tảng AWS. "
},
{
	"uri": "//localhost:1313/vi/1-worklog/1.11-week11/",
	"title": "Worklog Tuần 11",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Tuần 11: Tham gia các sự kiện của AWS để nâng cao kiến thức về DevOps. Tiếp tục phát triển các hàm Lambda, kiểm thử và gỡ lỗi. Thường xuyên thu thập phản hồi để tinh chỉnh và hoàn thiện các tính năng AI. Các công việc đã hoàn thành trong tuần: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 Sự kiện – AWS Cloud Mastery Series #2: DevOps on AWS 17/11/2025 17/11/2025 3–6 Hoàn thành các hàm Lambda cho RAG retrieval, gọi LLM và các tính năng hỗ trợ khác; thực hiện gỡ lỗi và tạo test case. 18/11/2025 21/11/2025 7 Cập nhật thiết kế giao diện UI/UX dựa trên phản hồi. 22/11/2025 23/11/2025 Thành tựu Tuần 11: Nâng cao kiến thức DevOps: Tham gia sự kiện AWS và thu nhận thêm nhiều góc nhìn, thực tiễn tốt về DevOps. Hoàn thành các hàm Lambda sớm hơn kế hoạch: Phát triển gần như toàn bộ các hàm Lambda cần thiết… "
},
{
	"uri": "//localhost:1313/vi/1-worklog/1.12-week12/",
	"title": "Worklog Tuần 12",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 12: Hoàn thiện và tinh chỉnh các trang chức năng quan trọng như Analysis, Contract Editor, và Upload. Tham gia sự kiện AWS để học hỏi về Security Pillar trong AWS Well-Architected Framework. Sửa lỗi và cải thiện tốc độ phản hồi của hệ thống. Công việc đã thực hiện trong tuần: Day Task Start Date Completion Date Reference Material 2 Sửa tiếp các lỗi còn tồn đọng Hoàn thiện và kiểm tra các tính năng lần cuối Phối hợp triển khai toàn bộ lên AWS 24/11/2025 28/11/2025 7 Event - AWS Cloud Mastery Series #3: ​Theo AWS Well-Architected Security Pillar 29/11/2025 29/11/2025 CN Sửa các lỗi còn tồn đọng 30/11/2025 30/11/2025 Kết quả đạt được trong tuần 12: Nắm vững Nguyên tắc Bảo mật của AWS: Tham gia sự kiện và tiếp thu kiến thức về AWS Well-Architected Security Pillar, giúp xây dựng một nền tảng an toàn và đáng tin cậy. Cải thiện Điều hướng và Sửa lỗi: Hệ thống điều hướng đã được cải thiện đáng kể, các lỗi giao diện đã được khắc phục, đảm bảo ứng dụng hoạt động mượt mà hơn. "
},
{
	"uri": "//localhost:1313/vi/4-eventparticipated/4.3-event3/",
	"title": "AWS Cloud Mastery Series #1",
	"tags": [],
	"description": "",
	"content": "AI/ML/GenAI on AWS Thứ Bảy, 15/11/2025 – AWS Vietnam Office I. Thông tin chung về sự kiện Tên sự kiện: AI/ML/GenAI on AWS\nThời gian: 8:30 – 12:00, ngày 15/11/2025\nĐịa điểm: AWS Vietnam Office\nMục tiêu:\nGiới thiệu tổng quan về AI/ML và GenAI trên nền tảng AWS. Làm rõ khái niệm foundation models và các cách ứng dụng trong thực tế. Trình bày hệ sinh thái dịch vụ AI/ML trên AWS, từ dịch vụ “ready-made” đến nền tảng xây dựng mô hình tùy chỉnh. Minh họa cách xây dựng ứng dụng GenAI sử dụng Amazon Bedrock, RAG và AgentCore. II. Nội dung chính theo dòng thời gian 1. Phần mở đầu – Giới thiệu GenAI và Foundation Models (8:30 – 9:00) Người trình bày Lâm Tuấn Kiệt tập trung vào việc đặt nền tảng về Generative AI (GenAI):\nGenAI là gì:\nKhác với các mô hình ML truyền thống chủ yếu “phân loại” hoặc “dự đoán”, GenAI có khả năng tạo mới nội dung: văn bản, hình ảnh, âm thanh, mã nguồn,… GenAI được xây dựng dựa trên các foundation models có quy mô rất lớn (nhiều tỷ tham số), được huấn luyện trên tập dữ liệu đa dạng, sau đó tinh chỉnh hoặc hướng dẫn để phù hợp với từng bài toán thực tế. Foundation Models \u0026amp; Amazon Bedrock:\nAmazon Bedrock được giới thiệu là nền tảng quản lý và truy cập nhiều foundation models từ các nhà cung cấp khác nhau (như Claude, Llama, Titan,…), giúp người dùng không phải tự quản lý hạ tầng, scaling hay bảo mật mô hình. Điểm nhấn: cùng một API, có thể thử nghiệm nhiều mô hình, so sánh chất lượng và chi phí, lựa chọn mô hình phù hợp với từng kịch bản (chatbot, tóm tắt, phân loại văn bản, RAG,…). Prompt Engineering:\nĐược nhấn mạnh như kỹ năng cốt lõi khi làm việc với GenAI:\nPrompt engineering = quá trình thiết kế, thử nghiệm và tinh chỉnh prompt để mô hình hiểu đúng bối cảnh và cho ra kết quả phù hợp. Các kỹ thuật chính được nêu:\nZero-shot prompting: không cung cấp ví dụ, chỉ mô tả yêu cầu. Few-shot prompting: đưa thêm một vài ví dụ mẫu để mô hình học “cách trả lời” đúng phong cách. Chain-of-Thought (CoT): hướng dẫn mô hình diễn giải từng bước suy luận, giúp kết quả có tính logic, đặc biệt cho bài toán tính toán, lập luận nhiều bước. RAG (Retrieval-Augmented Generation):\nĐược giới thiệu như kiến trúc kết hợp truy xuất tri thức với GenAI: mô hình chỉ “giỏi ngôn ngữ”, còn kiến thức cụ thể thì lấy từ kho dữ liệu riêng của doanh nghiệp (document, knowledge base,…).\nGhi chú của tôi nhấn mạnh: “RAG: retrieving relevant info from a data source” – mô hình sẽ truy xuất đoạn văn bản liên quan, sau đó dùng foundation model để tổng hợp và trả lời dựa trên dữ liệu đó, giúp:\nGiảm rủi ro “hallucination”. Dễ cập nhật kiến thức (chỉ cần cập nhật kho dữ liệu, không cần retrain model). 2. Phiên “AWS AI/ML Services Overview” \u0026amp; Embeddings/RAG in Action (9:00 – 10:30) Phần này tập trung vào bức tranh hệ sinh thái dịch vụ AI trên AWS và cách tận dụng cho GenAI/RAG.\n2.1. Embeddings và Titan Embeddings Trong phần slide “What are embeddings?” giảng viên giải thích:\nEmbedding là cách biểu diễn văn bản/hình ảnh thành vector số để mô hình có thể đo được mức độ tương đồng, tìm kiếm, phân cụm,… Embeddings là “nền móng” của các hệ thống RAG, semantic search, recommendation,… AWS giới thiệu Titan Embeddings – một lựa chọn embedding do chính AWS cung cấp, tối ưu cho:\nTìm kiếm ngữ nghĩa (semantic search). RAG trên tài liệu doanh nghiệp. Khả năng tích hợp chặt với Amazon Bedrock và các dịch vụ khác. Ghi chú: “Embeddings. Một vài options AWS hỗ trợ. RAG in action.” – tôi hiểu đây là phần demo mô tả pipeline: dữ liệu → chia nhỏ → sinh embedding → lưu vào vector store → truy vấn và kết hợp với LLM để trả lời.\n2.2. Các dịch vụ AI “ready-made” trên AWS Anh Hoàng Anh giới thiệu chi tiết các dịch vụ AI managed, trong đó tôi có ghi lại cả use case lẫn chi phí tham khảo:\nAmazon Rekognition – Computer Vision:\nNhận diện đối tượng, khuôn mặt, text trong ảnh/video. Ghi chú: “0.0013 USD/ảnh (dưới 1 triệu ảnh)” → phù hợp các bài toán nhận diện ảnh ở quy mô vừa, như giám sát camera, lọc nội dung. Amazon Translate – Neural Machine Translation:\nDịch tự động đa ngôn ngữ. Ghi chú: “15 USD / 1 triệu ký tự” → có thể áp dụng cho hệ thống dịch tự động tài liệu, email, nội dung web. Amazon Textract – OCR \u0026amp; trích xuất cấu trúc tài liệu:\nKhông chỉ nhận dạng text, mà còn giữ bố cục bảng, form, field. Ghi chú: “0.05 USD/trang (dưới 1 triệu trang)”, rất phù hợp cho bài toán trích xuất hợp đồng, hóa đơn. Amazon Transcribe – Speech-to-Text:\nChuyển giọng nói thành văn bản, hỗ trợ caption, transcript cuộc họp. Ghi chú: “0.024 USD/phút (dưới 250k phút)”. Amazon Polly – Text-to-Speech:\nTạo giọng nói tự nhiên từ văn bản. Ghi chú: “4 USD / 1 triệu ký tự” → dùng cho voicebot, audio guide, video training. Amazon Comprehend – NLP service:\nPhân tích sentiment, key phrase, entity, relationship,… từ văn bản. Ghi chú: “0.0001 USD / 100 ký tự hoặc 3 USD/giờ” → thích hợp gắn với hệ thống phân tích ý kiến khách hàng, phân loại ticket. Amazon Kendra – Intelligent Search / RAG Support:\nTìm kiếm ngữ nghĩa, FAQ, semantic search. Ghi chú: “30 USD/index/tháng + 0.35 USD/giờ” → đóng vai “search engine” nội bộ cho tài liệu doanh nghiệp, kết hợp tốt với RAG. Amazon Personalize – Recommendation:\nGợi ý cá nhân hóa: sản phẩm, nội dung, phân đoạn người dùng,… Ghi chú: “0.24 USD/giờ training + 0.05 USD/GB + 0.15 USD/1000 recommendation”. Việc nêu cụ thể use case kèm chi phí giúp tôi hình dung tốt hơn cách thiết kế giải pháp vừa “đúng bài toán”, vừa cân bằng được ngân sách.\n3. Phiên “Generative AI with Amazon Bedrock” – AgentCore \u0026amp; Pipecat (10:45 – 12:00) Sau phần overview, chương trình đi sâu vào xây dựng hệ GenAI thực chiến.\n3.1. Pipecat – Framework cho voice/multimodal AI agents Pipecat được giới thiệu là pipeline framework tối ưu cho real-time voice/multimodal agents:\nHỗ trợ ghép nhiều khối: speech-to-text, LLM, text-to-speech, các công cụ bên ngoài… thành một pipeline thống nhất. Tối ưu cho độ trễ thấp, phù hợp các ứng dụng trợ lý giọng nói, callbot. Điểm quan trọng tôi rút ra: thay vì “tự ráp” từng dịch vụ, có thể dùng framework như Pipecat để chuẩn hóa luồng xử lý, dễ mở rộng và maintain.\n3.2. Amazon Bedrock AgentCore và hệ sinh thái Agentic AI Diễn giả Hiếu Nghị trình bày về Bedrock AgentCore và bức tranh agentic AI systems:\nTừ LLM tới Agentic Systems:\nLLM đơn thuần chỉ “trả lời câu hỏi”. Agentic system có thêm: mục tiêu, kế hoạch, khả năng gọi công cụ (tools), truy cập dữ liệu, ra quyết định nhiều bước. Bedrock AgentCore được giới thiệu như lớp điều phối để xây dựng các agent kiểu này trên hạ tầng AWS. Các framework build agents được nhắc đến:\ncrew.ai, Google ADK, LlamaIndex, OpenAI Agents SDK, LangChain, LangGraph, Strands Agents SDK,… Ý chính: hệ sinh thái rất phong phú, nhưng nếu chạy trên AWS thì AgentCore giúp tối ưu việc tích hợp với dịch vụ AWS, bảo mật, logging, monitoring,… Các khả năng chính của Bedrock AgentCore (dựa trên slide và ghi chú):\nKết nối với nhiều foundation model trên Bedrock. Quản lý workflow nhiều bước, gọi tools (Lambda, API nội bộ, truy vấn dữ liệu…). Hỗ trợ RAG, tích hợp với Kendra/Knowledge Base. Xây dựng guardrails (chính sách nội dung, giới hạn miền trả lời). Quan sát \u0026amp; giám sát hành vi agent khi đưa vào production. Thách thức khi đưa agents vào production:\nĐộ ổn định và khả năng dự đoán hành vi của agent. Kiểm soát chi phí inference khi workflow quá phức tạp. Bảo mật dữ liệu, giới hạn quyền truy cập khi agent gọi nhiều hệ thống khác nhau. Logging/monitoring chi tiết để debug và cải tiến. Phần cuối là demo xây dựng chatbot GenAI trên Bedrock sử dụng RAG và một số guardrails cơ bản, giúp kết nối lý thuyết với cách triển khai thực tế.\nIII. Kiến thức và bài học rút ra Nhận thức rõ hơn về vai trò của GenAI trong kiến trúc hệ thống hiện đại\nGenAI không đứng một mình mà cần kết hợp với RAG, search, data pipeline, monitoring,… Việc hiểu đúng về foundation model và prompt engineering giúp tránh kỳ vọng sai lệch và thiết kế giải pháp thực tế hơn. Nắm được hệ sinh thái dịch vụ AI trên AWS dưới góc độ “build vs. buy”\nCác dịch vụ như Rekognition, Textract, Comprehend, Personalize… rất phù hợp khi bài toán đã tương đối chuẩn, không cần custom quá sâu. Khi cần đặc thù dữ liệu riêng (hợp đồng, tài liệu pháp lý, log nội bộ,…), thì kết hợp Bedrock + Embeddings + Kendra/RAG sẽ linh hoạt hơn. Quan điểm thực tế về chi phí\nCác con số cụ thể trong ghi chú giúp tôi hiểu rằng bài toán kỹ thuật luôn phải đi song song với bài toán kinh tế. Ngay từ giai đoạn thiết kế, cần ước lượng volume (số ảnh, số ký tự, số phút audio, số request) để chọn dịch vụ và mô hình phù hợp. Tư duy “agentic” thay vì chỉ “chatbot”\nKhái niệm AgentCore và agentic AI systems cho thấy bước tiến tiếp theo không chỉ là hỏi–đáp, mà là tự động hóa quy trình: đọc dữ liệu, gọi API, ra quyết định, ghi log,…\nĐiều này mở ra nhiều hướng cho các dự án cá nhân:\nAgent hỗ trợ phân tích hợp đồng pháp lý. Agent theo dõi log hạ tầng và cảnh báo bất thường. Agent hỗ trợ phân tích tài chính, gợi ý hành động dựa trên dữ liệu thời gian thực. IV. Định hướng áp dụng cá nhân Sau sự kiện này, tôi định hướng:\nThiết kế một pipeline RAG trên AWS cho bài toán mình đang làm (ví dụ: phân tích hợp đồng pháp luật, tài liệu học tập):\nDùng Textract để trích xuất nội dung tài liệu. Dùng Titan Embeddings để sinh vector và lưu vào vector store. Kết nối Kendra hoặc search engine tương đương để truy xuất. Sử dụng Bedrock (Claude/Llama/Titan) để xây dựng chatbot trả lời dựa trên tài liệu nội bộ. Thử nghiệm một Agent nhỏ với Bedrock AgentCore:\nBước đầu: agent đọc một câu hỏi → truy vấn knowledge base → tổng hợp lại → tạo báo cáo ngắn. Sau đó mở rộng: agent có thể gọi Lambda để thực hiện hành động (ví dụ tạo ticket, gửi email, cập nhật log). Rèn luyện thêm kỹ năng prompt engineering:\nLuyện tập các dạng prompt: zero-shot, few-shot, CoT trên chính các bài toán mình đang làm (AI/ML, DevOps, Security). Ghi lại các “prompt pattern” hiệu quả thành một thư viện dùng lại cho nhiều dự án. V. Một số hình ảnh trong sự kiện "
},
{
	"uri": "//localhost:1313/vi/3-blogstranslated/",
	"title": "Các bài blogs đã dịch",
	"tags": [],
	"description": "",
	"content": "Blog 1 - Getting started with healthcare data lakes: Using microservices Bài viết giới thiệu cách xây dựng một data lake hiện đại cho lĩnh vực y tế trên AWS bằng kiến trúc microservices. Nội dung tập trung vào nhu cầu hợp nhất nhiều nguồn dữ liệu khác nhau như hồ sơ sức khỏe điện tử (EHR), hệ thống xét nghiệm, chẩn đoán hình ảnh và thiết bị IoT y tế vào một nền tảng dữ liệu tập trung. Tác giả giải thích cách microservices — được triển khai qua API, container hoặc serverless — giúp tách biệt các bước ingest, xử lý, phân tích và quản trị dữ liệu, từ đó hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng mô tả các bước điển hình như đưa dữ liệu vào Amazon S3, lập catalog và chuyển đổi bằng các dịch vụ như AWS Glue, thiết lập bảo mật và quyền riêng tư (mã hóa, phân quyền chi tiết, ghi log), đồng thời đảm bảo tuân thủ các tiêu chuẩn như HIPAA.\nBlog 2 - Streamline access to ISO-rating content changes with Verisk Rating Insights and Amazon Bedrock Bài viết trình bày cách Verisk nâng cấp sản phẩm ISO Electronic Rating Content (ERC) bằng một giao diện hội thoại sử dụng AI tạo sinh trên Amazon Bedrock. Từ các điểm đau của khách hàng — phải tải cả gói nội dung để lấy một phần thông tin nhỏ, việc so sánh các bản phát hành tốn hàng giờ hoặc nhiều ngày, đội hỗ trợ ERC phải xử lý nhiều truy vấn lặp lại — Verisk đã xây dựng một hệ thống RAG (Retrieval-Augmented Generation). Tài liệu được phân đoạn, nhúng bằng mô hình Amazon Titan và lưu trữ dưới dạng vector trong Amazon OpenSearch Serverless để truy xuất theo ngữ cảnh truy vấn. Mô hình Anthropic Claude 3.5 Sonnet trên Amazon Bedrock chịu trách nhiệm tạo câu trả lời, Amazon ElastiCache lưu lịch sử trò chuyện, và LlamaIndex điều phối các nguồn dữ liệu. Bài viết cũng mô tả vòng lặp đánh giá, cơ chế guardrail với Amazon Bedrock Guardrails, các chỉ số chất lượng do SME định nghĩa, cùng pipeline phân tích sử dụng Amazon S3 và Snowflake. Kết quả kinh doanh bao gồm rút ngắn thời gian phân tích từ hàng giờ/ngày xuống còn vài phút, giảm tải cho bộ phận hỗ trợ, tăng tốc onboarding khách hàng và cung cấp thông tin chi tiết chính xác, dễ hiểu về các thay đổi nội dung xếp hạng.\nBlog 3 - How Poland’s Post Bank accelerated digital transformation while maintaining regulatory compliance on AWS Bài viết kể lại hành trình hiện đại hóa nền tảng ngân hàng số của Ngân hàng Bưu điện Ba Lan (Post Bank) trên AWS, đồng thời vẫn tuân thủ chặt chẽ các quy định tài chính. Bắt đầu từ năm 2019 với việc di chuyển thử một hệ thống không trọng yếu, ngân hàng dần xây dựng năng lực và niềm tin với đám mây, sau đó chọn ứng dụng ngân hàng điện tử và di động làm dự án di chuyển chủ lực. Sử dụng Terraform cho mô hình Infrastructure as Code, kiến trúc lai với các kết nối AWS Direct Connect dự phòng tới vùng châu Âu (Frankfurt) và vận dụng linh hoạt chiến lược 6R, Post Bank đạt được độ trễ ổn định, tính sẵn sàng cao với Amazon RDS Multi-AZ và giải pháp cache có thể tự động co giãn với Auto Scaling. Bài viết nhấn mạnh nền tảng quản trị mạnh dựa trên AWS Organizations, IAM Identity Center, SCPs, AWS Control Tower và kiến trúc mạng hub-and-spoke, phù hợp với AWS Well-Architected Framework và Security Reference Architecture. Kết quả định lượng gồm: giảm thời gian triển khai từ 2 giờ xuống 10 phút, giảm 40% mức sử dụng CPU, rút ngắn thời gian dựng môi trường từ 30 ngày xuống 30 phút và hạ tỷ lệ nghỉ việc nhân viên từ 30% xuống còn 5%. Ngân hàng tiếp tục mở rộng di chuyển lên đám mây và đã triển khai trợ lý AI nội bộ dùng Amazon Bedrock và Claude 3.5 để tra cứu kho tri thức nội bộ, thể hiện định hướng đổi mới liên tục trên nền tảng đám mây an toàn và tuân thủ.\n"
},
{
	"uri": "//localhost:1313/vi/3-blogstranslated/3.3-blog3/",
	"title": "Cách Ngân hàng Bưu điện Ba Lan tăng tốc chuyển đổi số trong khi vẫn duy trì tuân thủ quy định trên AWS",
	"tags": [],
	"description": "",
	"content": "Tác giả: Waldemar Szczepański, Bartłomiej Rafał, Piotr Boetzel, và Dariusz Matczak | Ngày đăng: 16/09/2025 | Danh mục: Cloud Adoption, Customer Solutions, Financial Services, Government, Migration, Public Sector, Regions\nTrong thị trường dịch vụ tài chính cạnh tranh của Ba Lan, Ngân hàng Bưu điện (Post Bank) đối mặt với một thách thức quan trọng: làm thế nào để tăng tốc đổi mới và cải thiện trải nghiệm khách hàng trong khi vẫn tuân thủ các yêu cầu quy định nghiêm ngặt. Giải pháp đến từ chiến lược di chuyển lên đám mây, không chỉ thay đổi hạ tầng công nghệ mà còn toàn bộ cách tiếp cận ngân hàng số của họ. Bằng cách di chuyển hệ thống ngân hàng điện tử sang Amazon Web Services (AWS), Post Bank đã rút ngắn thời gian triển khai ứng dụng từ 2 giờ xuống chỉ còn 10 phút, giảm 40% mức sử dụng CPU và cải thiện đáng kể độ tin cậy hệ thống—tất cả trong khi vẫn đảm bảo tuân thủ đầy đủ các quy định tài chính khắt khe của Ba Lan.\nCâu chuyện chuyển đổi này cho thấy cách các tổ chức tài chính có thể sử dụng công nghệ AWS Cloud để trở nên linh hoạt và hiệu quả hơn mà không làm giảm tính bảo mật hay tuân thủ. Với Post Bank, kết quả không chỉ ở các chỉ số kỹ thuật: tỷ lệ nghỉ việc của nhân viên giảm từ 30% xuống còn 5%, và ngân hàng có thể cung cấp môi trường phát triển mới trong 30 phút thay vì 30 ngày.\nXây dựng niềm tin thông qua áp dụng từng bước Hành trình lên đám mây của Post Bank bắt đầu thận trọng vào năm 2019, với việc di chuyển một hệ thống không trọng yếu.\n“Chúng tôi cần học công nghệ đám mây và xây dựng niềm tin trong toàn tổ chức,”\n— Waldemar Szczepański, Trưởng nhóm Trung tâm xuất sắc về điện toán đám mây (CCoE) tại Post Bank.\nCách tiếp cận có kiểm soát này cho phép đội ngũ CNTT phát triển kỹ năng về đám mây trong khi chứng minh giá trị thực tế với các bên liên quan.\nĐại dịch COVID-19 đã thúc đẩy mạnh mẽ quá trình chuyển đổi số của ngân hàng.\nKhả năng mở rộng nhanh chóng và triển khai tính năng mới liên tục trở thành yếu tố quyết định thành công trong kinh doanh.\nBên cạnh đó, xung đột tại Ukraine bổ sung thêm một yếu tố chiến lược quan trọng:\nban lãnh đạo cấp cao nhận thấy tầm quan trọng của tính dự phòng địa lý và việc lưu trữ hệ thống ngoài lãnh thổ Ba Lan.\nNhững yếu tố hội tụ này đã tạo ra thời điểm hoàn hảo cho sự thay đổi tổ chức.\nPost Bank thành lập đội CCoE theo AWS Cloud Adoption Framework (AWS CAF), đặt nền tảng cho chiến lược di chuyển toàn diện lên đám mây.\nChuyển đổi tổ chức Việc di chuyển một hệ thống kinh doanh quan trọng đòi hỏi nhiều hơn là chuyên môn kỹ thuật—nó cần sự đồng bộ trong tổ chức. Post Bank đã thay đổi toàn diện hoạt động CNTT: áp dụng công nghệ mới, thay đổi mô hình làm việc, quản lý chi phí đám mây và quy trình vận hành.\nNhóm CCoE phải điều phối nhiều bên liên quan nội bộ gồm: nhóm kiến trúc, bảo mật, kiểm toán và vận hành — mỗi nhóm có các yêu cầu và mối quan tâm riêng cần được giải quyết.\n“Chúng tôi không thể làm điều này một mình,”\n— Szczepański chia sẻ.\n“Các kiến trúc sư AWS và đối tác AWS đã giúp chúng tôi xây dựng bản thử nghiệm (proof of concept), và chương trình AWS Migration Acceleration Program (MAP) cung cấp cả phương pháp luận lẫn một phần tài trợ cho quá trình di chuyển.”\nCách tiếp cận hợp tác này chứng minh là yếu tố then chốt.\nCác kiến trúc sư AWS và chuyên gia từ đối tác AWS làm việc cùng với đội ngũ của Post Bank, vừa cung cấp chuyên môn, vừa chuyển giao kiến thức cho nhân sự nội bộ.\nKiến trúc cho môi trường lai Sau khi đánh giá kỹ lưỡng năng lực đội ngũ, độ phức tạp của ứng dụng và tác động đến người dùng, nhóm CCoE đã chọn ứng dụng ngân hàng điện tử và di động làm dự án di chuyển chủ lực.\nĐây là hệ thống trọng yếu, thử thách khả năng duy trì hiệu năng và độ tin cậy trong môi trường kết hợp giữa on-premises và đám mây.\nHọ sử dụng phương pháp Infrastructure as Code (IaC) với Terraform, đặt nền tảng cho việc triển khai nhanh chóng và nhất quán.\nTuy nhiên, kiến trúc lai mang lại những thách thức riêng biệt.\nKhoảng cách 750 km giữa trung tâm dữ liệu nội bộ và vùng AWS Châu Âu (Frankfurt) khiến quản lý độ trễ (latency) trở thành ưu tiên hàng đầu.\nPost Bank đã triển khai các kết nối AWS Direct Connect dự phòng trên những tuyến đường địa lý khác nhau, giúp đạt được độ trễ ổn định 30 mili-giây, đáp ứng yêu cầu vận hành của ứng dụng.\nHình minh họa 1: sơ đồ kết nối AWS Direct Connect\nNhóm dự án đã áp dụng linh hoạt chiến lược 6Rs gồm:\nrehost, replatform, repurchase, re-architect, retire, và retain.\nKhi mô hình kiểm soát truy cập mạng on-premises không thể chuyển trực tiếp lên đám mây, họ chọn chiến lược “repurchase”, sử dụng giải pháp của bên thứ ba từ AWS Marketplace.\nĐể đảm bảo tính sẵn sàng cao của cơ sở dữ liệu, họ tái nền tảng (replatform) sang Amazon Relational Database Service (Amazon RDS) Multi-AZ.\nGiải pháp bộ nhớ đệm trong bộ nhớ (in-memory cache) được di chuyển (rehost) và nâng cấp với plugin cộng đồng để hỗ trợ AWS Auto Scaling.\nChứng minh giá trị thông qua thành công có thể đo lường Bản thử nghiệm (proof of concept) của Post Bank không chỉ là một bài kiểm tra kỹ thuật, mà là một cách tiếp cận dựa trên dữ liệu nhằm thuyết phục các bên liên quan.\nNhóm dự án đã xác định 10 chỉ số hiệu suất chính (KPI), trực tiếp giải quyết các mối lo ngại của các bên về chi phí, bảo mật và hiệu năng.\n“Việc lựa chọn các chỉ số KPI là yếu tố then chốt,”\n— chia sẻ Bartłomiej Rafał, Trưởng nhóm kỹ thuật CCoE.\n“Chúng tôi cần những số liệu có thể phản biện lại các nghi ngờ bằng các con số cụ thể.”\nKết quả vượt ngoài mong đợi ở hầu hết các chỉ số, chỉ có một KPI chưa đạt mức mục tiêu đề ra, nhưng vẫn tốt hơn đáng kể so với mức hiệu suất trung bình của hệ thống on-premises trước đây.\nCách tiếp cận dựa trên bằng chứng thực nghiệm này đã biến những người hoài nghi thành người ủng hộ mạnh mẽ.Tính sẵn sàng của hệ thống (system availability) được cải thiện rõ rệt nhờ khả năng tự phục hồi tự động, có thể khắc phục sự cố trong vòng 10 giây, thay vì phải can thiệp thủ công như trước.Tốc độ phát triển (development velocity) tăng đáng kể, khi thời gian khởi tạo môi trường mới giảm từ 30 ngày xuống còn 30 phút.\nDuy trì bảo mật và tuân thủ trên đám mây Đối với một tổ chức tài chính tại Ba Lan, vấn đề bảo mật và tuân thủ quy định là không thể thương lượng. Post Bank đã xây dựng nền tảng đám mây của mình dựa trên các thực tiễn tốt nhất của AWS, tuân theo AWS Well-Architected Framework Security Pillar và AWS Security Reference Architecture.\nBằng cách sử dụng AWS Organizations kết hợp với AWS IAM Identity Center và service control policies (SCPs), ngân hàng đã thực thi các cơ chế kiểm soát tuân thủ quan trọng như: phân tách môi trường (environment isolation), phân chia nhiệm vụ (separation of duties), nguyên tắc đặc quyền tối thiểu (least privilege access) và mã hóa bắt buộc (mandatory encryption).\nAWS Control Tower giúp đơn giản hóa quản trị bảo mật, cho phép thiết lập các chính sách như giới hạn sử dụng dịch vụ trong phạm vi các vùng thuộc Khu vực Kinh tế châu Âu (EEA).\nNhóm kỹ thuật đã sử dụng Account Factory for Terraform (AFT) để tạo mới tất cả tài khoản AWS với cấu hình và cài đặt bảo mật chuẩn. Đối với quản lý danh tính, họ liên kết (federate) IAM Identity Center với hệ thống quản lý danh tính sẵn có, giúp đơn giản hóa việc chứng nhận tuân thủ bằng cách điều chỉnh quy trình hiện có thay vì tạo quy trình mới. Sơ đồ dưới đây minh họa kiến trúc này:\nHình minh họa 2: sơ đồ phân quyền và bảo mật\nĐiều quan trọng đối với ngân hàng là chỉ thay đổi tối thiểu các quy trình hiện có trong khi vẫn đơn giản hóa việc tuân thủ. Kiến trúc bảo mật mạng hub-and-spoke, được thể hiện trong sơ đồ sau, cho phép mở rộng các quy trình bảo mật hiện có sang môi trường AWS Cloud thông qua đồng bộ hóa quản lý tường lửa (firewall management synchronization).\nHình minh họa 3: sơ đồ kiến trúc mạng\nBài học cho các tổ chức tài chính Thành công của Post Bank trong quá trình di chuyển lên đám mây mang lại những bài học giá trị cho các tổ chức tài chính khác đang cân nhắc chuyển đổi:\nBắt đầu nhỏ nhưng nghĩ lớn – Bắt đầu với một hệ thống không trọng yếu giúp Post Bank xây dựng kỹ năng và sự tự tin, đồng thời giảm thiểu rủi ro.\nThiết lập quản trị mạnh mẽ từ sớm – Nhóm CCoE đóng vai trò then chốt trong việc lãnh đạo và điều phối các nhóm liên quan.\nĐầu tư vào kiến trúc – Dành thời gian thiết kế hệ thống đúng cách, xem xét các chiến lược di chuyển 6Rs, sẽ mang lại lợi ích lớn trong giai đoạn triển khai.\nSử dụng PoC một cách chiến lược – Bao gồm các chỉ số KPI trực tiếp phản ánh mối quan tâm của các bên liên quan và chứng minh rõ ràng lợi ích như cải thiện tính sẵn sàng và hiệu quả vận hành.\nTận dụng chuyên môn bên ngoài – Hợp tác với các kiến trúc sư AWS và sử dụng các chương trình như MAP (Migration Acceleration Program) để tăng tốc quá trình di chuyển đồng thời nâng cao năng lực nội bộ.\nHướng tới đổi mới liên tục “AWS Cloud khiến đội ngũ quản trị viên và kiểm thử của chúng tôi hài lòng hơn, đồng thời nâng cao sự thỏa mãn của các bên liên quan trong kinh doanh vì chúng tôi có thể triển khai thay đổi và nâng cấp nhanh hơn,” – Szczepański chia sẻ. Sự chuyển đổi này đã thay đổi căn bản cách Post Bank tiếp cận công nghệ. Giám đốc Bộ phận Hệ thống CNTT của Post Bank, Artur Szatkowski, khẳng định đầy tự tin:\n“Chúng tôi sẽ không quay lại với các giải pháp on-premises.”\nNgân hàng có kế hoạch di chuyển thêm nhiều hệ thống khác và đang khám phá các năng lực mới dựa trên đám mây.Gần đây, họ đã triển khai trợ lý AI nội bộ sử dụng Amazon Bedrock và Claude 3.5 của Anthropic. Nhờ đó, nhân viên có thể nhanh chóng tìm kiếm thông tin trong kho dữ liệu nội bộ khổng lồ của ngân hàng, bao gồm tài liệu, biểu mẫu, điều khoản dịch vụ và tài liệu quảng bá. Hành trình của Post Bank chứng minh rằng, với kế hoạch cẩn trọng, hợp tác chặt chẽ và cam kết tuân thủ các tiêu chuẩn tốt nhất, các tổ chức tài chính hoàn toàn có thể đạt được tính linh hoạt và khả năng đổi mới của điện toán đám mây trong khi vẫn duy trì bảo mật và tuân thủ nghiêm ngặt mà khách hàng và cơ quan quản lý yêu cầu.\nVề Post Bank Post Bank là một ngân hàng tiêu dùng của Ba Lan với khoảng 700.000 khách hàng, đã hoạt động trên thị trường 35 năm. Đối tác chiến lược và cổ đông chính của ngân hàng là Bưu điện Quốc gia Ba Lan. Thông qua mối quan hệ này, các sản phẩm và dịch vụ của ngân hàng được cung cấp tại mọi bưu điện trên toàn quốc, tạo nên mạng lưới khoảng 4.700 chi nhánh — lớn gấp 5 lần so với các đối thủ. Điều này giúp Post Bank phục vụ cả những người dân chưa có khả năng tiếp cận dịch vụ số, góp phần thúc đẩy tài chính toàn diện tại Ba Lan.\nWaldemar Szczepański Waldemar là Trưởng nhóm Trung tâm Xuất sắc về Điện toán Đám mây (CCoE) tại Post Bank, phụ trách việc phát triển ngân hàng trong các lĩnh vực công nghệ đám mây và trí tuệ nhân tạo (AI). Ông có hơn 20 năm kinh nghiệm trong lĩnh vực tài chính. Tại Post Bank, ông đã lãnh đạo các dự án nhằm xây dựng môi trường làm việc hiện đại và ứng dụng các công nghệ mới, bao gồm AI và ngân hàng đám mây. Bartłomiej Rafał Bartłomiej là Trưởng nhóm kỹ thuật CCoE tại Post Bank.\u000bÔng đam mê việc ứng dụng công nghệ để giải quyết các vấn đề kinh doanh và cải thiện quy trình hiện có. Là một chuyên gia công nghệ đa năng (tech generalist), ông có niềm quan tâm sâu rộng đến mọi khía cạnh của CNTT, từ hạ tầng, an ninh mạng, kiến trúc hệ thống cho đến quản lý — và luôn có nhiều ý tưởng hơn thời gian để thực hiện. Piotr Boetzel Piotr là Kiến trúc sư Giải pháp Cấp cao (Senior Solution Architect) tại AWS, làm việc với khách hàng thuộc khu vực công (Public Sector) ở Trung và Đông Âu (CEE). Ông hỗ trợ khách hàng trong các dự án hiện đại hóa và chuyển đổi hệ thống, đặc biệt tập trung vào bảo mật và tuân thủ quy định. Dariusz Matczak Dariusz là Quản lý tài khoản (Account Manager) tại AWS, phụ trách khu vực công ở Ba Lan.\u000bÔng có hơn 15 năm kinh nghiệm làm việc với khách hàng và đối tác trên nhiều ngành công nghiệp, hỗ trợ họ trong các dự án chuyển đổi số lên đám mây và triển khai nhiều dự án công nghệ khác nhau. "
},
{
	"uri": "//localhost:1313/vi/5-workshop/5.4-s3-onprem/5.4.3-test-endpoint/",
	"title": "Kiểm tra Interface Endpoint",
	"tags": [],
	"description": "",
	"content": "Lấy regional DNS name (tên DNS khu vực) của S3 interface endpoint Trong Amazon VPC menu, chọn Endpoints.\nClick tên của endpoint chúng ta mới tạo ở mục 4.2: s3-interface-endpoint. Click details và lưu lại regional DNS name của endpoint (cái đầu tiên) vào text-editor của bạn để dùng ở các bước sau.\nKết nối đến EC2 instance ở trong \u0026ldquo;VPC On-prem\u0026rdquo; (giả lập môi trường truyền thống) Đi đến Session manager bằng cách gõ \u0026ldquo;session manager\u0026rdquo; vào ô tìm kiếm\nClick Start Session, chọn EC2 instance có tên Test-Interface-Endpoint. EC2 instance này đang chạy trên \u0026ldquo;VPC On-prem\u0026rdquo; và sẽ được sử dụng để kiểm tra kết nối đến Amazon S3 thông qua Interface endpoint. Session Manager sẽ mở 1 browser tab mới với shell prompt: sh-4.2 $\nĐi đến ssm-user\u0026rsquo;s home directory với lệnh \u0026ldquo;cd ~\u0026rdquo;\nTạo 1 file tên testfile2.xyz\nfallocate -l 1G testfile2.xyz Copy file vào S3 bucket mình tạo ở section 4.2 aws s3 cp --endpoint-url https://bucket.\u0026lt;Regional-DNS-Name\u0026gt; testfile2.xyz s3://\u0026lt;your-bucket-name\u0026gt; Câu lệnh này yêu cầu thông số \u0026ndash;endpoint-url, bởi vì bạn cần sử dụng DNS name chỉ định cho endpoint để truy cập vào S3 thông qua Interface endpoint. Không lấy \u0026rsquo; * \u0026rsquo; khi copy/paste tên DNS khu vực. Cung cấp tên S3 bucket của bạn Bây giờ tệp đã được thêm vào bộ chứa S3 của bạn. Hãy kiểm tra bộ chứa S3 của bạn trong bước tiếp theo.\nKiểm tra Object trong S3 bucket Đi đến S3 console Click Buckets Click tên bucket của bạn và bạn sẽ thấy testfile2.xyz đã được thêm vào s3 bucket của bạn "
},
{
	"uri": "//localhost:1313/vi/5-workshop/5.3-s3-vpc/",
	"title": "Truy cập S3 từ VPC",
	"tags": [],
	"description": "",
	"content": "Sử dụng Gateway endpoint Trong phần này, bạn sẽ tạo một Gateway endpoint để truy cập Amazon S3 từ một EC2 instance. Gateway endpoint sẽ cho phép tải một object lên S3 bucket mà không cần sử dụng Internet Công cộng. Để tạo endpoint, bạn phải chỉ định VPC mà bạn muốn tạo endpoint và dịch vụ (trong trường hợp này là S3) mà bạn muốn thiết lập kết nối.\nNội dung Tạo gateway endpoint Test gateway endpoint "
},
{
	"uri": "//localhost:1313/vi/4-eventparticipated/4.4-event4/",
	"title": "AWS Cloud Mastery Series #2",
	"tags": [],
	"description": "",
	"content": "DevOps on AWS Thứ Hai, ngày 17/11/2025, từ 8:30 – 17:00 – AWS Vietnam Office I. Thông tin chung về sự kiện Tên sự kiện: AWS Cloud Mastery Series #2 – DevOps on AWS\nThời gian: Thứ Hai, ngày 17/11/2025, từ 8h30 đến 17h00\nĐịa điểm: Văn phòng AWS Việt Nam\nĐối tượng tham dự: Sinh viên, thực tập sinh và kỹ sư trẻ quan tâm đến DevOps, hạ tầng trên AWS và vận hành hệ thống theo hướng tự động hóa.\nMục tiêu chính của buổi học:\nHiểu đúng về DevOps mindset và vai trò của DevOps/Platform Engineer trong tổ chức. Nắm được hệ sinh thái DevOps Services trên AWS (CodeCommit, CodeBuild, CodeDeploy, CodePipeline) và cách xây dựng pipeline CI/CD hoàn chỉnh. Làm quen với tư duy Infrastructure as Code (IaC) thông qua CloudFormation và AWS CDK, hiểu vì sao “ClickOps” không còn phù hợp ở quy mô lớn. Hiểu các lựa chọn dịch vụ container trên AWS (ECR, ECS, EKS, App Runner) và các chiến lược triển khai. Nắm các khái niệm và công cụ Monitoring \u0026amp; Observability (CloudWatch, X-Ray, Grafana, Prometheus) để vận hành hệ thống một cách chủ động. II. Nội dung chi tiết chương trình trong ngày 2.1. Phiên sáng – DevOps Mindset \u0026amp; CI/CD \u0026amp; IaC 2.1.1. 8:30 – 9:00 | Welcome \u0026amp; DevOps Mindset (Quang Tịnh – Platform Engineer)\nMở đầu, diễn giả Quang Tịnh giới thiệu lại tổng quan buổi AI/ML trước đó và đặt vấn đề: DevOps xuất hiện để giải quyết khoảng cách giữa Development (Dev) và Operations (Ops) – “DevOps là cầu nối giữa Dev và Ops”, không chỉ là một vị trí, mà là một mindset và một cách làm việc.\nDiễn giả nhấn mạnh một số đặc điểm của DevOps culture:\nCollaboration: Dev và Ops làm việc như một đội, cùng chịu trách nhiệm về chất lượng và vận hành sản phẩm. Automation-first: ưu tiên tự động hóa build, test, deploy thay vì thao tác thủ công. Measurement \u0026amp; Feedback: luôn đo lường và phản hồi dựa trên dữ liệu, không dựa trên cảm tính. Về DevOps metrics, diễn giả gợi lại các nhóm chỉ số thường được dùng theo hướng DORA:\nDeployment Frequency – tần suất triển khai. Lead Time for Changes – thời gian từ lúc commit tới khi lên production. MTTR (Mean Time To Recovery) – thời gian trung bình để khôi phục sau sự cố. Change Failure Rate – tỉ lệ triển khai gây lỗi. Cuối phần này, diễn giả liên hệ vai trò Platform Engineer: xây dựng nền tảng, công cụ và quy trình chuẩn, giúp các team product có thể triển khai, giám sát và vận hành dịch vụ một cách nhất quán, ít ma sát.\n2.1.2. 9:00 – 10:30 | AWS DevOps Services – CI/CD Pipeline (Kha – CI/CD Workflow)\nPhần này tập trung vào CI/CD pipeline trên AWS, do anh Kha trình bày.\nPipeline cơ bản được mô tả với các khối chính:\nSource Control – AWS CodeCommit \u0026amp; Git strategies\nGiới thiệu CodeCommit như một dịch vụ Git managed trên AWS, tương đương GitHub/GitLab nhưng tích hợp sâu với hệ sinh thái AWS.\nNhắc đến các chiến lược Git phổ biến:\nGitFlow: phù hợp với quy trình có release lớn, nhiều nhánh feature. Trunk-based Development: commit thường xuyên lên main/trunk, tối ưu cho CI/CD và deployment nhanh. Build \u0026amp; Test – AWS CodeBuild\nSử dụng CodeBuild để build mã nguồn, chạy unit test, integration test. Buildspec file định nghĩa các bước cài dependency, build, test, xuất artifact. Deployment – AWS CodeDeploy\nGiới thiệu các chiến lược deploy:\nBlue/Green: chạy song song hai môi trường, switch traffic khi bản mới ổn định. Canary: chuyển traffic từng phần nhỏ để giảm rủi ro. Rolling update: cập nhật dần từng nhóm instance. Orchestration – AWS CodePipeline\nCodePipeline đóng vai trò “xương sống” pipeline, kết nối CodeCommit → CodeBuild → CodeDeploy và các bước approval, test tự động. Mô hình tổng thể của pipeline được trình bày trong slide và được minh họa qua demo walk-through (từ commit đến khi deploy thành công). Điểm nhấn ở phiên này là việc kết hợp DevOps mindset với toolchain AWS: mọi bước từ commit đến production đều phải được tự động hóa và theo dõi.\n2.1.3. 10:45 – 12:00 | Infrastructure as Code (IaC) – Thịnh Nguyễn \u0026amp; Hoàng Anh\nMở đầu phiên, hai diễn giả Thịnh Nguyễn và Hoàng Anh đặt câu hỏi:\n“Why ClickOps isn’t ideal?” – Tại sao không nên quản lý hạ tầng bằng việc click tay trên console?\nTừ đó, các lý do được liệt kê:\nAutomation: không thể tự động hóa khi mọi thao tác đều click tay. Scalability: khi hệ thống lớn, số lượng tài nguyên nhiều, con người không thể quản lý nổi bằng tay. Reproducibility: khó tái tạo lại môi trường giống nhau giữa dev, staging, production. Collaboration: không có “source of truth”, khó review, khó audit, dễ sai sót. AWS CloudFormation\nĐược giới thiệu như dịch vụ IaC chuẩn trên AWS, dùng template (YAML/JSON) để mô tả tài nguyên.\nCác khái niệm chính:\nTemplate: file định nghĩa tài nguyên cần tạo (VPC, EC2, S3, RDS, v.v.). Stack: một lần triển khai template. Drift detection: phát hiện sự sai khác giữa thực tế hạ tầng và template (khi ai đó “clickops” trên console). Ưu điểm: có thể version control; rollback stack khi lỗi; dễ nhân bản môi trường.\nAWS Cloud Development Kit (CDK – “CloudDevKit”)\nĐược nhắc đến như một lựa chọn IaC hiện đại, dùng ngôn ngữ lập trình (TypeScript, Python, Java, v.v.) để định nghĩa hạ tầng.\nCDK sinh ra CloudFormation template, cho phép:\nTái sử dụng constructs (thành phần hạ tầng đóng gói). Áp dụng best practices, pattern chuẩn của AWS. Phần “Choosing between IaC tools” kết luận:\nCloudFormation: phù hợp khi muốn gần “native AWS”, đơn giản, dễ kiểm soát. CDK: phù hợp khi dự án lớn, cần abstraction cao, tái sử dụng nhiều, đội dev đã quen code. 2.2. Phiên chiều – Container Services \u0026amp; Monitoring/Observability 2.2.1. 13:00 – 14:30 | Container Services on AWS (Trần Vĩ)\nDiễn giả Trần Vĩ giới thiệu từ khái niệm cơ bản:\nContainer: ứng dụng được “đóng gói” cùng mọi dependency để khi di chuyển giữa các môi trường khác nhau vẫn chạy ổn định. Phân biệt Container vs Virtual Machine (VM): container dùng chung kernel, nhẹ hơn, khởi động nhanh hơn; VM cô lập mạnh hơn nhưng nặng và tốn tài nguyên hơn (phần so sánh chi tiết đã có trong slide, không ghi lại toàn bộ). Docker \u0026amp; Docker Workflow\nContainer engine: Docker. Dockerfile: mô tả cách build image, môi trường runtime. Image: “blueprint” đóng gói code + runtime. Workflow cơ bản: viết Dockerfile → build image → push lên registry → run container. Amazon ECR (Elastic Container Registry)\nĐược giới thiệu là fully-managed container registry, mặc định private.\nCác tính năng chính theo ghi chú:\nImage scanning Immutable tags Lifecycle policies Encryption \u0026amp; IAM để kiểm soát truy cập images. Amazon ECS (Elastic Container Service)\nDịch vụ orchestration cho containers.\nChức năng: đảm bảo container tự khởi động lại khi fail, scale up/down, phân phối traffic giữa các service, quản lý containers trên nhiều server.\nHỗ trợ 2 mode:\nEC2 mode: chạy containers trên cụm EC2 – chi phí thấp cho workload chạy lâu dài nhưng phải tự quản lý server. Fargate mode: serverless, không quản lý hạ tầng, trả tiền theo tài nguyên sử dụng. Thành phần chính: ECS cluster, task definition, task, service – sơ đồ kiến trúc được minh họa trong slide.\nAmazon EKS (Elastic Kubernetes Service)\nManaged service cho Kubernetes, dùng khi cần kiến trúc linh hoạt, phức tạp. Thành phần: Control plane (master), worker node, pod, service, sơ đồ minh họa kiến trúc Kubernetes. So sánh ECS vs EKS: ECS đơn giản, gắn chặt AWS; EKS linh hoạt, phù hợp khi đã có kinh nghiệm Kubernetes hoặc cần portability cao. AWS App Runner\nĐược ghi chú là:\n“Nhanh, đơn giản, cost effective” “Directly from source code, no management required” App Runner phù hợp cho trường hợp muốn đưa code web/service chạy nhanh nhất có thể, không muốn quản lý cluster, node, v.v.\n2.2.2. 14:45 – 16:00 | Monitoring \u0026amp; Observability (Anh Nghiêm, Anh Long, Anh Quý)\nKhái niệm Monitoring \u0026amp; Observability – anh Nghiêm\nMonitoring: theo dõi các chỉ số, log, cảnh báo trong hệ thống.\nObservability: khả năng suy luận nguyên nhân sự cố dựa trên các dữ liệu thu thập được từ hệ thống (metrics, logs, traces).\nCác dịch vụ AWS liên quan:\nAmazon CloudWatch Amazon Managed Grafana AWS X-Ray Amazon Managed Service for Prometheus Amazon CloudWatch\nMonitor tài nguyên AWS real-time, cung cấp metrics và logs cho cả dịch vụ AWS và on-premises. Metrics: dữ liệu hiệu năng của hệ thống; có thể là default metrics hoặc custom metrics. Logs: thu thập log từ nhiều dịch vụ AWS, lưu trữ và cho phép query để phân tích. Alarms: thiết lập ngưỡng, tự động gửi thông báo (SNS, email, v.v.) hoặc kích hoạt action (Auto Scaling, EventBridge). Dashboards: giao diện trực quan để kết hợp metrics và logs, hỗ trợ tối ưu vận hành và chi phí. AWS X-Ray – anh Long\nTập trung vào hệ thống microservices, giúp:\nPhân tích performance bottlenecks. Thực hiện distributed tracing: theo dõi request end-to-end, hiển thị service map, gán trace IDs qua các service. Hỗ trợ root cause analysis và real user monitoring (RUM) khi kết hợp với CloudWatch. Observability Best Practices – anh Quý\nNội dung chi tiết ở slide, trong ghi chú chỉ lưu lại tiêu đề. Tập trung vào việc chuẩn hóa cách log, metric, trace, thiết lập alert hợp lý, tránh “alert noise” và gắn với DevOps/SRE workflow. 2.2.3. 16:00 – 17:00 | DevOps Best Practices, Career \u0026amp; Q\u0026amp;A\nPhần cuối ngày chủ yếu tổng kết:\nÔn lại pipeline chuẩn: từ DevOps mindset → IaC → CI/CD → Containers → Observability. Nhắc tới các DevOps best practices: deployment an toàn (feature flags, canary, blue/green), tự động hóa test, postmortem không đổ lỗi cá nhân. Thảo luận về DevOps career pathway và lộ trình AWS Certifications (Developer Associate, SysOps, DevOps Engineer Professional, v.v.). III. Kiến thức và bài học rút ra DevOps là một tư duy tổng thể, không chỉ là công cụ\nViệc nhấn mạnh DevOps là “cầu nối giữa Dev và Ops” giúp tôi nhìn rõ hơn vai trò DevOps/Platform Engineer: thiết kế nền tảng dùng chung cho các team, đảm bảo từ code tới production đi qua một đường ống chuẩn, có đo lường và tự động hóa. Tầm quan trọng của CI/CD và Git strategy rõ ràng\nSử dụng CodeCommit + CodeBuild + CodeDeploy + CodePipeline cho phép chuẩn hóa quy trình build–test–deploy. Việc chọn GitFlow hay trunk-based không chỉ là “cách đặt nhánh” mà ảnh hưởng trực tiếp đến tần suất release, cách xử lý hotfix, rollback. Infrastructure as Code giải quyết triệt để nhược điểm của ClickOps\nCác lý do “Automation – Scalability – Reproducibility – Collaboration” khiến tôi đánh giá lại thói quen click trên console. CloudFormation thích hợp khi cần kiểm soát hạ tầng sát với AWS, trong khi CDK phù hợp khi muốn tái sử dụng và tổ chức hạ tầng bằng code. Hiểu rõ hơn bức tranh container trên AWS\nTừ Docker, ECR, ECS, EKS đến App Runner, mỗi dịch vụ phù hợp với một mức độ phức tạp khác nhau:\nApp Runner cho “chạy nhanh, ít quản lý hạ tầng”. ECS (EC2/Fargate) cho microservices vừa phải, “thuần AWS”. EKS khi cần đầy đủ sức mạnh Kubernetes. Monitoring \u0026amp; Observability là bắt buộc, không phải “nice-to-have”\nCloudWatch không chỉ là nơi xem log mà là trung tâm metrics, logs, alarms, dashboards. X-Ray mở rộng khả năng quan sát sang chiều “trace”, giúp hiểu rõ hành trình của từng request trong hệ thống microservices. Nhìn chung, sự kiện ngày 17/11 đã giúp tôi khớp nối các mảnh ghép DevOps rời rạc thành một bức tranh hoàn chỉnh trên nền tảng AWS.\nIV. Định hướng áp dụng vào học tập và dự án cá nhân Chuẩn hóa workflow DevOps cho các dự án hiện tại\nÁp dụng trunk-based development cho các repo cá nhân/thực tập.\nThiết lập một pipeline mẫu với CodeCommit → CodeBuild → CodeDeploy → CodePipeline, trong đó:\nTự động chạy unit test. Tự động build image Docker và push lên ECR. Loại bỏ dần ClickOps, chuyển sang IaC\nVới các môi trường sandbox/lab hiện tại, tôi sẽ thử mô tả hạ tầng bằng CloudFormation trước (VPC, EC2, S3, IAM Role). Sau khi quen, chuyển sang AWS CDK cho những dự án lớn hơn, tái sử dụng construct cho VPC, cluster, RDS, v.v. Đưa container vào pipeline học tập và sản phẩm\nĐóng gói các ứng dụng AI/ML và các dự án web cá nhân vào Docker image. Thử triển khai một service trên ECS Fargate và một service đơn giản trên App Runner để so sánh chi phí, độ phức tạp vận hành. Thiết lập Monitoring \u0026amp; Observability tối thiểu cho mọi workload\nBật CloudWatch metrics \u0026amp; logs cho EC2, Lambda, ECS task. Tạo ít nhất một dashboard và một alarm cơ bản (CPU, lỗi 5xx). Đối với các API quan trọng, tích hợp X-Ray để tập làm quen với distributed tracing. Định hướng nghề nghiệp và chứng chỉ\nDựa trên nội dung sự kiện, tôi đánh giá DevOps/Platform Engineer là một hướng đi phù hợp nếu muốn kết hợp kiến thức hạ tầng và lập trình. Trung hạn, tôi đặt mục tiêu chuẩn bị cho AWS Certified Developer – Associate, sau đó hướng tới AWS DevOps Engineer – Professional khi đã có đủ trải nghiệm thực tế. Bài thu hoạch này là cơ sở để tôi hệ thống lại kiến thức về DevOps trên AWS, đồng thời làm guideline cụ thể cho việc thiết kế và tối ưu các hệ thống, dự án cá nhân trong giai đoạn tiếp theo.\nV. Một số hình ảnh trong sự kiện "
},
{
	"uri": "//localhost:1313/vi/5-workshop/5.4-s3-onprem/5.4.4-dns-simulation/",
	"title": "Mô phỏng On-premises DNS ",
	"tags": [],
	"description": "",
	"content": "AWS PrivateLink endpoint có một địa chỉ IP cố định trong từng AZ nơi chúng được triển khai, trong suốt thời gian tồn tại của endpoint (cho đến khi endpoint bị xóa). Các địa chỉ IP này được gắn vào Elastic network interface (ENI). AWS khuyến nghị sử dụng DNS để resolve địa chỉ IP cho endpoint để các ứng dụng downstream sử dụng địa chỉ IP mới nhất khi ENIs được thêm vào AZ mới hoặc bị xóa theo thời gian.\nTrong phần này, bạn sẽ tạo một quy tắc chuyển tiếp (forwarding rule) để gửi các yêu cầu resolve DNS từ môi trường truyền thống (mô phỏng) đến Private Hosted Zone trên Route 53. Phần này tận dụng cơ sở hạ tầng do CloudFormation triển khai trong phần Chuẩn bị môi trường.\nTạo DNS Alias Records cho Interface endpoint Click link để đi đến Route 53 management console (Hosted Zones section). Mẫu CloudFormation mà bạn triển khai trong phần Chuẩn bị môi trường đã tạo Private Hosted Zone này. Nhấp vào tên của Private Hosted Zone, s3.us-east-1.amazonaws.com: Tạo 1 record mới trong Private Hosted Zone: Giữ nguyên Record name và record type Alias Button: click để enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Chọn endpoint: Paste tên (Regional VPC Endpoint DNS) bạn đã lưu lại ở phần 4.3 Click Add another record, và add 1 cái record thứ 2 sử dụng những thông số sau: Record name: *. Record type: giữ giá trị default (type A) Alias Button: Click để enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Chọn endpoint: Paste tên (Regional VPC Endpoint DNS) bạn đã lưu lại ở phần 4.3 Click Create records Record mới xuất hiện trên giao diện Route 53.\nTạo một Resolver Forwarding Rule Route 53 Resolver Forwarding Rules cho phép bạn chuyển tiếp các DNS queries từ VPC của bạn đến các nguồn khác để resolve name. Bên ngoài môi trường workshop, bạn có thể sử dụng tính năng này để chuyển tiếp các DNS queries từ VPC của bạn đến các máy chủ DNS chạy trên on-premises. Trong phần này, bạn sẽ mô phỏng một on-premises conditional forwarder bằng cách tạo một forwarding rule để chuyển tiếp các DNS queries for Amazon S3 đến một Private Hosted Zone chạy trong \u0026ldquo;VPC Cloud\u0026rdquo; để resolve PrivateLink interface endpoint regional DNS name.\nTừ giao diện Route 53, chọn Inbound endpoints trên thanh bên trái\nTrong giao diện Inbound endpoint, Chọn ID của Inbound endpoint.\nSao chép 2 địa chỉ IP trong danh sách vào trình chỉnh sửa. Từ giao diện Route 53, chọn Resolver \u0026gt; Rules và chọn Create rule Trong giao diện Create rule Name: myS3Rule Rule type: Forward Domain name: s3.us-east-1.amazonaws.com VPC: VPC On-prem Outbound endpoint: VPCOnpremOutboundEndpoint Target IP Addresses: điền cả hai IP bạn đã lưu trữ trên trình soạn thảo (inbound endpoint addresses) và sau đó chọn Submit Bạn đã tạo thành công resolver forwarding rule.\nKiểm tra on-premises DNS mô phỏng. Kết nối đến Test-Interface-Endpoint EC2 instance với Session Manager Kiểm tra DNS resolution. Lệnh dig sẽ trả về địa chỉ IP được gán cho VPC endpoint interface đang chạy trên VPC (địa chỉ IP của bạn sẽ khác): dig +short s3.us-east-1.amazonaws.com Các địa chỉ IP được trả về là các địa chỉ IP VPC enpoint, KHÔNG phải là các địa chỉ IP Resolver mà bạn đã dán từ trình chỉnh sửa văn bản của mình. Các địa chỉ IP của Resolver endpoint và VPC endpoin trông giống nhau vì chúng đều từ khối CIDR VPC Cloud.\nTruy cập vào menu VPC (phần Endpoints), chọn S3 interface endpoint. Nhấp vào tab Subnets và xác nhận rằng các địa chỉ IP được trả về bởi lệnh Dig khớp với VPC endpoint: Hãy quay lại shell của bạn và sử dụng AWS CLI để kiểm tra danh sách các bucket S3 của bạn: aws s3 ls --endpoint-url https://s3.us-east-1.amazonaws.com Kết thúc phiên làm việc của Session Manager của bạn: Trong phần này, bạn đã tạo một Interface Endpoint cho Amazon S3. Điểm cuối này có thể được truy cập từ on-premises thông qua Site-to-Site VPN hoặc AWS Direct Connect. Các điểm cuối Route 53 Resolver outbound giả lập chuyển tiếp các yêu cầu DNS từ on-premises đến một Private Hosted Zone đang chạy trên đám mây. Các điểm cuối Route 53 inbound nhận yêu cầu giải quyết và trả về một phản hồi chứa địa chỉ IP của Interface Endpoint VPC. Sử dụng DNS để giải quyết các địa chỉ IP của điểm cuối cung cấp tính sẵn sàng cao trong trường hợp một Availability Zone gặp sự cố.\n"
},
{
	"uri": "//localhost:1313/vi/4-eventparticipated/",
	"title": "Sự kiện đã tham gia",
	"tags": [],
	"description": "",
	"content": "Sự kiện 1 Tên sự kiện: Vietnam Cloud Day 2025\nThời gian: 13:00, Thứ Năm, ngày 18 tháng 9 năm 2025\nĐịa điểm: Tầng 26, Tòa nhà Bitexco, Số 02 đường Hải Triều, Phường Sài Gòn, Thành phố Hồ Chí Minh\nVai trò: Người tham dự\nTóm tắt sự kiện: Sự kiện Vietnam Cloud Day 2025 (GenAI and Data Track) tập trung vào hệ sinh thái Agentic AI và nền tảng dữ liệu cho GenAI trên AWS. Các diễn giả giới thiệu tầm nhìn Agentic AI của AWS với Amazon Bedrock, Amazon Nova, Strands Agents và Bedrock AgentCore, đồng thời nhấn mạnh tầm quan trọng của nền tảng dữ liệu thống nhất (S3, Lake House, Redshift, Iceberg, SageMaker, DataZone) để phục vụ analytics và AI ở quy mô lớn. Nội dung cũng bao gồm GenAI roadmap \u0026amp; AI-DLC (AI-Driven Development Lifecycle) với ba giai đoạn Inception – Construction – Operation, các nguyên tắc bảo mật và Responsible AI (Well-Architected, MITRE ATLAS, OWASP LLM, NIST, ISO, EU AI Act), cùng với các công cụ nâng cao năng suất như Amazon Q, QuickSight và các AI Agents chuyên biệt. Qua sự kiện, tôi hiểu rõ hơn cách AWS định hình kiến trúc Agentic AI từ dữ liệu, mô hình đến ứng dụng; vai trò then chốt của data foundation trước khi triển khai GenAI; tầm quan trọng của bảo mật, quản trị rủi ro và tuân thủ chuẩn; cũng như cách áp dụng AI-DLC và các dịch vụ như Bedrock, Amazon Q, Guardrails, QuickSight vào việc xây dựng hệ thống GenAI và AI Agents phục vụ doanh nghiệp.\nSự kiện 2 Tên sự kiện: AI-Driven Development Life Cycle: Reimagining Software Engineering\nThời gian: 14:00 – 16:30, ngày 03/10/2025\nĐịa điểm: Tầng 26, Tòa nhà Bitexco, Số 02 đường Hải Triều, Phường Sài Gòn, Thành phố Hồ Chí Minh\nVai trò: Người tham dự\nTóm tắt sự kiện: Sự kiện “Reimagining Software Engineering” tập trung vào việc tái định hình toàn bộ vòng đời phát triển phần mềm trong kỷ nguyên GenAI, thông qua mô hình AI-Driven Development Lifecycle (AI-DLC) và các công cụ như Amazon Q Developer và KIRO – AI IDE. Phần trình bày của Toan Huynh làm rõ sự tiến hóa từ auto-complete → assistant → agents, phân biệt hai cách tiếp cận AI-assisted và AI-managed, và giới thiệu AI-DLC như một “điểm cân bằng” nơi AI hỗ trợ sâu vào planning, kiến trúc, làm rõ yêu cầu, sinh scaffolding, refactor và testing nhưng developer vẫn giữ vai trò chủ động về chuyên môn, quyết định và kiểm chứng. Các khái niệm như mob development, spec-driven development, thiết kế rõ ràng context–input–output, yêu cầu AI ghi lại reasoning, luôn bắt đầu bằng việc yêu cầu AI lập plan, chia nhỏ task và tách session được nhấn mạnh như best practice khi làm việc với GenAI. Phần của My Nguyen giới thiệu KIRO như một AI IDE được thiết kế cho luồng spec → prototype → production, hỗ trợ spec-driven ngay trong IDE, quản lý context, tracking workflow và tích hợp AI-DLC (thông qua thư mục steering, workflow .md, rule nội bộ), đồng thời tương thích với VSCode và Claude models. Từ sự kiện này, tôi học được cách nhìn SDLC dưới góc độ AI-driven: AI có thể tự động hóa phần lớn hoạt động nhưng con người phải thiết kế quy trình, kiểm soát chất lượng và chịu trách nhiệm cuối cùng; cách tận dụng AI hiệu quả là định nghĩa rõ bối cảnh, yêu cầu đầu vào/đầu ra, lưu lại reasoning và dùng AI mạnh nhất ở những phần có cấu trúc (spec, test flow, refactor), đồng thời biết lựa chọn công cụ phù hợp: Amazon Q Developer cho automation xuyên suốt SDLC và KIRO cho các dự án cần luồng prototype-to-production nhanh, trực quan.\nSự kiện 3 Tên sự kiện: AI/ML/GenAI on AWS\nThời gian: 8:30 – 12:00, ngày 15/11/2025\nĐịa điểm: Tầng 26, Tòa nhà Bitexco, Số 02 đường Hải Triều, Phường Sài Gòn, Thành phố Hồ Chí Minh\nVai trò: Người tham dự\nTóm tắt về sự kiện: Sự kiện tập trung vào bức tranh tổng thể về AI/ML và Generative AI trên nền tảng AWS, giới thiệu các tầng dịch vụ từ AI Services đến Amazon SageMaker và Amazon Bedrock. Nội dung chính xoay quanh foundation models (Claude, Llama, Titan), kỹ thuật prompt engineering (zero-shot, few-shot, chain-of-thought), cùng kiến trúc RAG để xây dựng hệ thống hỏi–đáp trên dữ liệu nội bộ doanh nghiệp. Qua buổi này, tôi hiểu rõ hơn sự khác biệt giữa ML truyền thống và GenAI, vai trò của SageMaker trong việc chuẩn hóa pipeline end-to-end, cũng như cách kết hợp Bedrock + embeddings + RAG để giảm hallucination và tận dụng tối đa dữ liệu nội bộ. Đây là nền tảng trực tiếp cho các ý tưởng xây dựng chatbot chuyên biệt (ví dụ chatbot pháp lý, phân tích tài liệu) mà tôi đang triển khai.\nSự kiện 4 Tên sự kiện: DevOps on AWS\nThời gian: 8:30 – 17:00, ngày 17/11/2025\nĐịa điểm: Tầng 26, Tòa nhà Bitexco, Số 02 đường Hải Triều, Phường Sài Gòn, Thành phố Hồ Chí Minh\nVai trò: Người tham dự\nTóm tắt về sự kiện: Sự kiện DevOps on AWS đi từ DevOps mindset đến hệ sinh thái công cụ và kiến trúc vận hành trên AWS: CodeCommit, CodeBuild, CodeDeploy, CodePipeline cho CI/CD; CloudFormation và CDK cho Infrastructure as Code; ECR, ECS, EKS, App Runner cho container; và CloudWatch, X-Ray cho monitoring \u0026amp; observability. Nội dung được trình bày theo một chuỗi logic: từ quy trình build–test–deploy tự động, hạ tầng được mô tả bằng code, đến cách triển khai và giám sát microservices trong môi trường thực tế. Qua buổi này, tôi học được cách nhìn DevOps như một tư duy tổng thể (văn hóa + quy trình + công cụ), hiểu rõ lợi ích của IaC so với ClickOps, nắm được các lựa chọn container phù hợp từng mức độ phức tạp, và nhận thức rằng observability là yếu tố bắt buộc khi hệ thống bắt đầu mở rộng. Những kiến thức này giúp tôi định hình rõ ràng hơn cách thiết kế pipeline CI/CD và môi trường triển khai cho các dự án AI/ML và web app của mình.\nSự kiện 5 Tên sự kiện: AWS Well-Architected Security Pillar\nThời gian: 08:30 – 12:00, ngày 29/11/2025\nĐịa điểm: Tầng 26, Tòa nhà Bitexco, Số 02 đường Hải Triều, Phường Sài Gòn, Thành phố Hồ Chí Minh\nVai trò: Người tham dự\nTóm tắt về sự kiện: Sự kiện tập trung toàn bộ vào Security Pillar trong AWS Well-Architected Framework với 5 trụ cột: Identity \u0026amp; Access Management, Detection, Infrastructure Protection, Data Protection và Incident Response. Nội dung bao phủ từ kiến trúc IAM hiện đại (multi-account, SSO, SCP, permission boundaries, MFA, Access Analyzer), đến detection-as-code với CloudTrail, GuardDuty, Security Hub; bảo mật hạ tầng mạng với VPC segmentation, Security Groups, NACLs, Network Firewall; mã hóa và quản lý khóa/bí mật với KMS, Secrets Manager; và cuối cùng là IR playbook cho các tình huống như compromised IAM key, S3 public exposure, EC2 malware. Qua buổi này, tôi hiểu rõ hơn rằng bảo mật phải được thiết kế từ kiến trúc chứ không phải là phần “vá” sau cùng, biết cách xây dựng nền tảng IAM và logging/detection tối thiểu cho mọi workload, và có cái nhìn cụ thể hơn về việc chuẩn bị playbook, automation cho ứng phó sự cố. Đây là cơ sở quan trọng để tôi thiết kế các hệ thống AI/ML và ứng dụng trên AWS theo hướng an toàn, tuân thủ và có khả năng phục hồi khi xảy ra sự cố.\n"
},
{
	"uri": "//localhost:1313/vi/5-workshop/5.4-s3-onprem/",
	"title": "Truy cập S3 từ môi trường truyền thống",
	"tags": [],
	"description": "",
	"content": "Tổng quan Trong phần này, bạn sẽ tạo một Interface Endpoint để truy cập Amazon S3 từ môi trường truyền thống mô phỏng. Interface Endpoint sẽ cho phép bạn định tuyến đến Amazon S3 qua kết nối VPN từ môi trường truyền thống mô phỏng của bạn.\nTại sao nên sử dụng Interface Endpoint:\nCác Gateway endpoints chỉ hoạt động với các tài nguyên đang chạy trong VPC nơi chúng được tạo. Interface Endpoint hoạt động với tài nguyên chạy trong VPC và cả tài nguyên chạy trong môi trường truyền thống. Khả năng kết nối từ môi trường truyền thống của bạn với aws cloud có thể được cung cấp bởi AWS Site-to-Site VPN hoặc AWS Direct Connect. Interface Endpoint cho phép bạn kết nối với các dịch vụ do AWS PrivateLink cung cấp. Các dịch vụ này bao gồm một số dịch vụ AWS, dịch vụ do các đối tác và khách hàng AWS lưu trữ trong VPC của riêng họ (gọi tắt là Dịch vụ PrivateLink endpoints) và các dịch vụ Đối tác AWS Marketplace. Đối với workshop này, chúng ta sẽ tập trung vào việc kết nối với Amazon S3. "
},
{
	"uri": "//localhost:1313/vi/4-eventparticipated/4.5-event5/",
	"title": "AWS Cloud Mastery Series #3",
	"tags": [],
	"description": "",
	"content": "AWS Well-Architected Security Pillar Thứ Hai, 29/11/2025, từ 8:30 – 17:00 – AWS Vietnam Office I. Thông tin chung về sự kiện Tên sự kiện: AWS Well-Architected Security Pillar\nThời gian: 08:30 – 12:00, ngày 29/11/2025 (morning only)\nĐịa điểm: AWS Vietnam Office\nMục tiêu chính:\nLàm rõ vai trò của Security Pillar trong khung AWS Well-Architected Framework và mô hình Shared Responsibility. Hệ thống hoá 5 trụ cột bảo mật: Identity \u0026amp; Access Management, Detection, Infrastructure Protection, Data Protection, Incident Response. Làm rõ các best practices và “bẫy thường gặp” của doanh nghiệp, đặc biệt trong bối cảnh môi trường cloud tại Việt Nam. Cung cấp góc nhìn thực tế qua các demo nhỏ (IAM policy simulation, detection-as-code, network firewall, IR playbook). II. Nội dung chi tiết theo dòng thời gian 2.1. Opening \u0026amp; Security Foundation (08:30 – 08:50) Phần mở đầu tập trung vào bức tranh tổng thể về bảo mật trên AWS:\nVai trò Security Pillar trong Well-Architected\nSecurity được trình bày như nền tảng bắt buộc, không phải “tùy chọn” sau cùng. Nếu xây dựng kiến trúc mà bỏ qua Security Pillar, hệ thống rất dễ rơi vào các tình huống:\nSecurity breach (rò rỉ dữ liệu, lộ thông tin nhạy cảm). System outages do cấu hình sai, tấn công DDoS hoặc lỗi vận hành. Data corruption hoặc mất dữ liệu do thiếu backup / encryption. Sự cố do lưu lượng cao mà không có cơ chế bảo vệ và giám sát phù hợp. Nguyên tắc cốt lõi:\nLeast Privilege: chỉ cấp đúng và đủ quyền cần thiết. Zero Trust: không mặc định tin tưởng bất kỳ thành phần nào, kể cả trong nội bộ VPC. Defense in Depth: bảo vệ nhiều lớp (identity, network, application, data…). Shared Responsibility Model:\nAWS chịu trách nhiệm “security OF the cloud” (hạ tầng vật lý, vùng sẵn sàng, hypervisor…). Khách hàng chịu trách nhiệm “security IN the cloud” (IAM, cấu hình dịch vụ, mã nguồn, dữ liệu, logging, IR…). Top threats trong môi trường cloud Việt Nam:\nNhấn mạnh các rủi ro phổ biến:\nLộ/lạm dụng long-lived credentials. S3 bucket public ngoài ý muốn. Workload đặt Public Internet không cần thiết. Thiếu logging/giám sát dẫn tới phát hiện muộn sự cố. Phần này tạo nền tảng tư duy: an ninh phải được thiết kế ngay từ đầu, dựa trên 5 pillars và shared responsibility, không phải giải quyết “chữa cháy” khi đã có sự cố.\n2.2. Pillar 1 – Identity \u0026amp; Access Management (08:50 – 09:30) – Modern IAM Architecture Phiên này tập trung vào hiện đại hóa IAM theo hướng multi-account, SSO, quản trị tập trung:\nIAM: Users, Roles, Policies – tránh long-term credentials\nNhấn mạnh: không dùng access key dài hạn gắn với IAM user cho workload; thay bằng IAM Role + temporary credentials. Áp dụng principle of least privilege trong mọi policy; tránh lạm dụng \u0026quot;Action\u0026quot;: \u0026quot;*\u0026quot;, \u0026quot;Resource\u0026quot;: \u0026quot;*\u0026quot;. IAM Identity Center \u0026amp; AWS Organizations\nIAM Identity Center được giới thiệu là giải pháp SSO để quản lý truy cập cho nhiều tài khoản, nhiều ứng dụng cùng lúc. Khi bật SSO thường sẽ đi cùng với AWS Organizations, do đó cần thiết kế organizational structure + account structure rõ ràng từ đầu (prod / non-prod / security / logging…). SCPs – Service Control Policies\nĐược diễn giả ví như “biển cấm”, trong khi IAM policy là “bằng lái”:\nIAM policy cấp quyền. SCP giới hạn trần tối đa quyền có thể được cấp trong một account/OU. Nguyên tắc: SCP không cấp quyền, chỉ filter những gì IAM có thể cấp.\nPermission Boundaries\nĐược mô tả như công cụ “advanced IAM” để giải quyết bài toán phân quyền phức tạp:\nCho phép team tự tạo IAM role/user nhưng vẫn bị giới hạn bởi một “khung quyền tối đa” (boundary). MFA, Credential Rotation, IAM Access Analyzer\nMFA: so sánh TOTP và FIDO2, khuyến nghị dùng MFA cho root và tài khoản quan trọng. Credential rotation: sử dụng AWS Secrets Manager để xoay vòng secret tự động, tránh dùng secret cố định. IAM Access Analyzer: phân tích policy/condition để phát hiện quyền truy cập ngoài ý muốn (public, cross-account…), gửi cảnh báo khi phát hiện rủi ro. Mini Demo: Validate IAM Policy + simulate access\nDemo minh họa việc dùng công cụ để validate IAM policy và “simulate” xem một identity có thực sự được phép làm gì trên một resource, giúp tránh cấu hình sai trước khi đưa lên production. 2.3. Pillar 2 – Detection \u0026amp; Continuous Monitoring (09:30 – 09:55) Phần này do Đức Anh, Tuấn Thịnh, Thanh Đạt trình bày, tập trung vào phát hiện \u0026amp; giám sát liên tục:\nAWS CloudTrail (Đức Anh)\nĐược mô tả là “xương sống” của detection trên AWS:\nGhi log và giám sát tập trung mọi API call trên tất cả tài khoản.\nCung cấp multi-layer security visibility:\nManagement events (thay đổi cấu hình). Data events (truy cập object S3, lambda invoke…). Network activity events. Organization coverage khi bật ở cấp tổ chức. Tích hợp với EventBridge để:\nNhận real-time events. Tự động thông báo hoặc kích hoạt workflow (Lambda, SNS, SQS, Step Functions). Hỗ trợ khái niệm detection-as-code: rule detection cũng được quản lý như code. Amazon GuardDuty (Tuấn Thịnh)\nTập trung vào threat detection dựa trên:\nVPC Flow Logs, CloudTrail, DNS logs và nhiều nguồn khác. Ghi chú của anh có nêu các Advanced Protection Plans:\nBảo vệ thêm cho S3, EKS, RDS, Lambda, runtime monitoring. GuardDuty có thể tích hợp EventBridge để tự động hoá phản ứng (gửi thông báo, cô lập instance…) và cũng phù hợp mô hình detection-as-code.\nAWS Security Hub CSPM (Thanh Đạt)\nGiải quyết bài toán: nhiều dịch vụ, nhiều tài khoản, nhiều tiêu chuẩn compliance → khó quản lý thủ công.\nCác điểm chính:\nChuẩn hoá đầu ra thành ASFF (AWS Security Finding Format). Phát hiện cấu hình sai (misconfiguration), đánh giá security posture. Áp dụng chuẩn AWS Foundational Security Best Practices, CIS Foundations Benchmark. Hỗ trợ mô hình detection-as-code, kiểm soát tập trung multi-account, multi-region. 2.4. Pillar 3 – Infrastructure Protection (10:10 – 10:40) – Network \u0026amp; Workload Security Phần này do anh Kha trình bày, xoay quanh bảo mật mạng và workload:\nCommon Network Attack Vectors \u0026amp; Use Cases\nPhân tích các hướng tấn công thường gặp: inbound, outbound, east–west (giữa các VPC/ subnet/ workload). AWS Layered Security \u0026amp; VPC Controls\nSecurity Groups (SG):\nStateful: cho phép chiều vào thì chiều ra tương ứng được tự động cho phép. Không có rule “deny”, chỉ allow. Hỗ trợ security group sharing (RAM) và security group referencing giữa các VPC/tài khoản. Network ACLs (NACLs):\nGắn ở lớp subnet, thường dùng cho chính sách coarse-grained. Hỗ trợ cả allow và deny. Nhược điểm: giới hạn số lượng rule, độ sâu kiểm tra đơn giản hơn. DNS \u0026amp; Perimeter Protection\nAmazon Route 53: được nhắc đến với vai trò DNS:\nPrivate DNS, VPC DNS, Public DNS. Hỗ trợ DNS filter, quản lý rule và reporting tập trung, dùng cho mô hình cloud-only hoặc hybrid network. AWS Network Firewall\nTập trung vào:\nEgress filtering, environment segmentation, intrusion prevention. Hỗ trợ cả stateless và stateful rules, tích hợp với Transit Gateway, multi-VPC endpoints để kiểm soát lưu lượng giữa nhiều VPC.\nNgoài ra, trong sườn sự kiện còn nhấn mạnh AWS WAF + AWS Shield như lớp bảo vệ ứng dụng web và chống DDoS, được đặt ở biên (ALB/CloudFront) trong mô hình defense-in-depth.\n2.5. Pillar 4 – Data Protection (10:40 – 11:10) – Encryption, Keys \u0026amp; Secrets Phần này do Thịnh Lâm, Việt Nguyễn trình bày, tập trung vào mã hoá và quản lý khóa/bí mật:\nAWS KMS (Key Management Service)\nLàm rõ khái niệm master key và data key, cách data key được sinh và mã hoá bởi master key. Key policy: chỉ các principal được chỉ định trong policy mới có thể sử dụng key, kể cả admin nếu không nằm trong policy cũng không được phép. Phân biệt managed key vs CMK (customer-managed key); CMK có thể cấu hình rotation tự động hoặc thủ công. Data Classification \u0026amp; Guardrails\nGhi chú có nhắc đến Amazon Macie để quét S3 bucket, nhận diện dữ liệu nhạy cảm (PII, tài liệu quan trọng). Thiết lập guardrails: ví dụ policy deny nếu S3 object không được mã hoá, bắt buộc encryption cho dữ liệu nhạy cảm. Encryption in Transit\nDanh sách dịch vụ cần quan tâm:\nS3 \u0026amp; DynamoDB ở mức API-based. RDS (SSL), EBS \u0026amp; Nitro (mã hoá trên đường truyền), ACM (cấp chứng chỉ TLS). Secrets Manager \u0026amp; Rotation\nDùng Secrets Manager để lưu credential, connection string, API key… Hỗ trợ rotation tự động, tích hợp với KMS để mã hoá secrets. 2.6. Pillar 5 – Incident Response (11:10 – 11:40) – IR Playbook \u0026amp; Automation Phần này do anh Long, Tịnh Trương chia sẻ, tập trung vào quy trình ứng phó sự cố (IR):\nBối cảnh:\nMôi trường hiện đại (multi-account, nhiều dịch vụ, hybrid) quá phức tạp để “chữa cháy bằng tay”. Các loại sự cố: security breach, system outages, data corruption, high traffic,… đòi hỏi quy trình bài bản và mức độ automation cao. Security Responsibilities are Shared\nNhắc lại Shared Responsibility Model và liệt kê một số dịch vụ nền tảng cần bật cho security foundation:\nAWS Organizations + SCP CloudTrail AWS Config GuardDuty Security Hub Prevention Guidelines (phòng hơn chữa)\nKill long-lived credentials – loại bỏ access key dài hạn. Never expose S3 – không để S3 public trừ khi thực sự cần và được kiểm soát. No facing internet cho workload không cần public. Everything through IaC – mọi thay đổi hạ tầng đều nên qua code. Double gate high-risk changes – thêm lớp phê duyệt cho thay đổi rủi ro cao. Incident Response Process (theo AWS)\nQuy trình IR chuẩn gồm:\nPrepare – xây dựng playbook, phân vai trò, chuẩn bị sẵn công cụ. Detection \u0026amp; Analysis – phát hiện từ GuardDuty/Security Hub/CloudTrail, phân tích mức độ. Containment – cô lập nguồn gây sự cố (isolate instance, revoke key…). Eradication \u0026amp; Recovery – loại bỏ nguyên nhân, khôi phục hệ thống từ snapshot/backup. Post-incident – review, rút kinh nghiệm, cập nhật playbook. Các playbook cụ thể được đề cập trong sườn:\nCompromised IAM key. S3 public exposure. EC2 malware detection. Các bước chung đều bao gồm: snapshot, isolation, thu thập bằng chứng, và automation bằng Lambda/Step Functions cho những trường hợp lặp lại. 2.7. Wrap-Up \u0026amp; Q\u0026amp;A (11:40 – 12:00) Phần tổng kết nhấn mạnh:\n5 pillars Security phải được nhìn như một “bộ khung” đồng bộ, không tách rời.\nCác common pitfalls của doanh nghiệp Việt Nam:\nThiếu IAM chuẩn hoá (root dùng thường xuyên, credential dài hạn). Không bật đầy đủ CloudTrail/GuardDuty/Security Hub. S3 hoặc endpoint public ngoài ý muốn, không có guardrails. Gợi ý roadmap học tập: AWS Certified Security – Specialty, sau đó Security nâng cao trong lộ trình Solutions Architect Professional.\nIII. Kiến thức và bài học rút ra Security phải được thiết kế từ kiến trúc, không phải xử lý sau khi có sự cố\nViệc liên tục nhắc tới Security Pillar trong Well-Architected giúp tôi nhận thức rõ: nếu kiến trúc không enforce IAM, logging, network segmentation, encryption… ngay từ đầu, chi phí khắc phục sau này sẽ rất lớn. IAM hiện đại = multi-account, SSO, SCP, permission boundaries, rotation, MFA\nIAM không chỉ là “tạo user và gán policy” mà là một kiến trúc đa lớp: Organizations, IAM Identity Center, SCP, permission boundaries, Access Analyzer… kết hợp để vừa linh hoạt vừa an toàn. Detection-as-Code là hướng đi bắt buộc trong môi trường cloud phức tạp\nThay vì xem log thủ công, mọi detection rule (CloudTrail, GuardDuty, Security Hub) cần được mô tả bằng code, có versioning, có pipeline triển khai – giống cách ta quản lý IaC. Bảo mật hạ tầng không chỉ là “đóng port” mà là thiết kế network đúng nguyên tắc\nPhân biệt rõ vai trò của SG vs NACL, vai trò của Route 53, Network Firewall… cho thấy security phải gắn với kiến trúc mạng nhiều lớp. Data Protection và IR là hai mắt xích cuối nhưng cực kỳ quan trọng\nKhông chỉ mã hoá dữ liệu (KMS, encryption in transit) mà còn phải phân loại dữ liệu (Macie), thiết lập guardrails deny non-encrypted, quản lý secrets đúng cách. IR playbook, nếu không được chuẩn bị trước, sẽ khiến đội ngũ “rối loạn” khi xảy ra sự cố thực tế. IV. Định hướng áp dụng vào học tập và dự án cá nhân Chuẩn hoá IAM \u0026amp; multi-account cho các môi trường lab/dự án cá nhân\nÁp dụng mô hình AWS Organizations + IAM Identity Center + SCP tối thiểu, tránh dồn tất cả vào một account duy nhất. Xoá dần long-lived credentials, thay bằng role + temporary credentials, bật MFA cho các tài khoản quan trọng. Thiết lập detection foundation cho mọi workload\nBật CloudTrail ở org-level, kích hoạt GuardDuty và Security Hub trên toàn bộ tài khoản lab của bản thân, ít nhất ở mức baseline. Thử triển khai một số rule detection-as-code (ví dụ: S3 public, security group mở 0.0.0.0/0, credential không rotation…). Thiết kế lại VPC/network theo hướng defense-in-depth\nChia VPC thành public/private subnet rõ ràng; hạn chế tối đa workload trực tiếp public Internet. Dùng security group đúng ngữ nghĩa (theo role của service), NACL ở mức subnet, và xem xét thử nghiệm Network Firewall/Route 53 DNS filter trong các bài lab nâng cao. Áp dụng Data Protection \u0026amp; IR vào các dự án có dữ liệu nhạy cảm\nVới các dự án liên quan đến hợp đồng, dữ liệu người dùng, kế hoạch sử dụng KMS, S3 encryption, RDS encryption, Secrets Manager và Macie.\nXây dựng một IR playbook đơn giản cho lab:\nTrường hợp access key bị lộ. Trường hợp S3 bucket bị public. Thử dùng Lambda/Step Functions để tự động cô lập tài nguyên hoặc revoke credential trong một số kịch bản mô phỏng.\nĐịnh hướng học tiếp Security Specialty\nSự kiện khẳng định đây là mảng kiến thức mà tôi cần đầu tư nghiêm túc nếu muốn xây dựng hệ thống AI/ML và ứng dụng enterprise trên AWS một cách an toàn, bền vững. Trong lộ trình, tôi dự kiến:\nCủng cố thêm Well-Architected – Security Pillar và AWS SRA (Security Reference Architecture). Sau đó hướng tới AWS Certified Security – Specialty như một mục tiêu trung hạn. Bài thu hoạch này giúp tôi tổng hợp lại toàn bộ nội dung buổi 29/11 theo đúng 5 trụ cột Security Pillar và định hình rõ ràng cách áp dụng vào các hệ thống thực tế mà tôi đang và sẽ xây dựng trên AWS.\nV. Một số hình ảnh trong sự kiện "
},
{
	"uri": "//localhost:1313/vi/5-workshop/5.5-policy/",
	"title": "VPC Endpoint Policies",
	"tags": [],
	"description": "",
	"content": "Khi bạn tạo một Interface Endpoint hoặc cổng, bạn có thể đính kèm một chính sách điểm cuối để kiểm soát quyền truy cập vào dịch vụ mà bạn đang kết nối. Chính sách VPC Endpoint là chính sách tài nguyên IAM mà bạn đính kèm vào điểm cuối. Nếu bạn không đính kèm chính sách khi tạo điểm cuối, thì AWS sẽ đính kèm chính sách mặc định cho bạn để cho phép toàn quyền truy cập vào dịch vụ thông qua điểm cuối.\nBạn có thể tạo chính sách chỉ hạn chế quyền truy cập vào các S3 bucket cụ thể. Điều này hữu ích nếu bạn chỉ muốn một số Bộ chứa S3 nhất định có thể truy cập được thông qua điểm cuối.\nTrong phần này, bạn sẽ tạo chính sách VPC Endpoint hạn chế quyền truy cập vào S3 bucket được chỉ định trong chính sách VPC Endpoint.\nKết nối tới EC2 và xác minh kết nối tới S3. Bắt đầu một phiên AWS Session Manager mới trên máy chủ có tên là Test-Gateway-Endpoint. Từ phiên này, xác minh rằng bạn có thể liệt kê nội dung của bucket mà bạn đã tạo trong Phần 1: Truy cập S3 từ VPC. aws s3 ls s3://\u0026lt;your-bucket-name\u0026gt; Nội dung của bucket bao gồm hai tệp có dung lượng 1GB đã được tải lên trước đó.\nTạo một bucket S3 mới; tuân thủ mẫu đặt tên mà bạn đã sử dụng trong Phần 1, nhưng thêm \u0026lsquo;-2\u0026rsquo; vào tên. Để các trường khác là mặc định và nhấp vào Create. Tạo bucket thành công. Policy mặc định cho phép truy cập vào tất cả các S3 Buckets thông qua VPC endpoint.\nTrong giao diện Edit Policy, sao chép và dán theo policy sau, thay thế yourbucketname-2 với tên bucket thứ hai của bạn. Policy này sẽ cho phép truy cập đến bucket mới thông qua VPC endpoint, nhưng không cho phép truy cập đến các bucket còn lại. Chọn Save để kích hoạt policy. { \u0026#34;Id\u0026#34;: \u0026#34;Policy1631305502445\u0026#34;, \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;Stmt1631305501021\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:*\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::yourbucketname-2\u0026#34;, \u0026#34;arn:aws:s3:::yourbucketname-2/*\u0026#34; ], \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34; } ] } Cấu hình policy thành công.\nTừ session của bạn trên Test-Gateway-Endpoint instance, kiểm tra truy cập đến S3 bucket bạn tạo ở bước đầu aws s3 ls s3://\u0026lt;yourbucketname\u0026gt; Câu lệnh trả về lỗi bởi vì truy cập vào S3 bucket không có quyền trong VPC endpoint policy.\nTrở lại home directory của bạn trên EC2 instance cd~ Tạo file fallocate -l 1G test-bucket2.xyz Sao chép file lên bucket thứ 2 aws s3 cp test-bucket2.xyz s3://\u0026lt;your-2nd-bucket-name\u0026gt; Thao tác này được cho phép bởi VPC endpoint policy.\nSau đó chúng ta kiểm tra truy cập vào S3 bucket đầu tiên\naws s3 cp test-bucket2.xyz s3://\u0026lt;your-1st-bucket-name\u0026gt;\nCâu lệnh xảy ra lỗi bởi vì bucket không có quyền truy cập bởi VPC endpoint policy.\nTrong phần này, bạn đã tạo chính sách VPC Endpoint cho Amazon S3 và sử dụng AWS CLI để kiểm tra chính sách. Các hoạt động AWS CLI liên quan đến bucket S3 ban đầu của bạn thất bại vì bạn áp dụng một chính sách chỉ cho phép truy cập đến bucket thứ hai mà bạn đã tạo. Các hoạt động AWS CLI nhắm vào bucket thứ hai của bạn thành công vì chính sách cho phép chúng. Những chính sách này có thể hữu ích trong các tình huống khi bạn cần kiểm soát quyền truy cập vào tài nguyên thông qua VPC Endpoint.\n"
},
{
	"uri": "//localhost:1313/vi/5-workshop/",
	"title": "Workshop",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nĐảm bảo truy cập Hybrid an toàn đến S3 bằng cách sử dụng VPC endpoint Tổng quan AWS PrivateLink cung cấp kết nối riêng tư đến các dịch vụ aws từ VPCs hoặc trung tâm dữ liệu (on-premise) mà không làm lộ lưu lượng truy cập ra ngoài public internet.\nTrong bài lab này, chúng ta sẽ học cách tạo, cấu hình, và kiểm tra VPC endpoints để cho phép workload của bạn tiếp cận các dịch vụ AWS mà không cần đi qua Internet công cộng.\nChúng ta sẽ tạo hai loại endpoints để truy cập đến Amazon S3: gateway vpc endpoint và interface vpc endpoint. Hai loại vpc endpoints này mang đến nhiều lợi ích tùy thuộc vào việc bạn truy cập đến S3 từ môi trường cloud hay từ trung tâm dữ liệu (on-premise).\nGateway - Tạo gateway endpoint để gửi lưu lượng đến Amazon S3 hoặc DynamoDB using private IP addresses. Bạn điều hướng lưu lượng từ VPC của bạn đến gateway endpoint bằng các bảng định tuyến (route tables) Interface - Tạo interface endpoint để gửi lưu lượng đến các dịch vụ điểm cuối (endpoints) sử dụng Network Load Balancer để phân phối lưu lượng. Lưu lượng dành cho dịch vụ điểm cuối được resolved bằng DNS. Nội dung Tổng quan về workshop Chuẩn bị Truy cập đến S3 từ VPC Truy cập đến S3 từ TTDL On-premises VPC Endpoint Policies (làm thêm) Dọn dẹp tài nguyên "
},
{
	"uri": "//localhost:1313/vi/5-workshop/5.6-cleanup/",
	"title": "Dọn dẹp tài nguyên",
	"tags": [],
	"description": "",
	"content": "Dọn dẹp tài nguyên Xin chúc mừng bạn đã hoàn thành xong lab này! Trong lab này, bạn đã học về các mô hình kiến trúc để truy cập Amazon S3 mà không sử dụng Public Internet.\nBằng cách tạo Gateway endpoint, bạn đã cho phép giao tiếp trực tiếp giữa các tài nguyên EC2 và Amazon S3, mà không đi qua Internet Gateway. Bằng cách tạo Interface endpoint, bạn đã mở rộng kết nối S3 đến các tài nguyên chạy trên trung tâm dữ liệu trên chỗ của bạn thông qua AWS Site-to-Site VPN hoặc Direct Connect. Dọn dẹp Điều hướng đến Hosted Zones trên phía trái của bảng điều khiển Route 53. Nhấp vào tên của s3.us-east-1.amazonaws.com zone. Nhấp vào Delete và xác nhận việc xóa bằng cách nhập từ khóa \u0026ldquo;delete\u0026rdquo;. Disassociate Route 53 Resolver Rule - myS3Rule from \u0026ldquo;VPC Onprem\u0026rdquo; and Delete it. 4.Mở console của CloudFormation và xóa hai stack CloudFormation mà bạn đã tạo cho bài thực hành này:\nPLOnpremSetup PLCloudSetup Xóa các S3 bucket Mở bảng điều khiển S3 Chọn bucket chúng ta đã tạo cho lab, nhấp chuột và xác nhận là empty. Nhấp Delete và xác nhận delete. "
},
{
	"uri": "//localhost:1313/vi/6-self-evaluation/",
	"title": "Tự đánh giá",
	"tags": [],
	"description": "",
	"content": "Trong 12 tuần tham gia chương trình First Cloud Journey tại Amazon Web Services (AWS) Việt Nam với vị trí FCJ Cloud Intern, tôi có cơ hội trải nghiệm đầy đủ một hành trình “onboarding lên cloud” bài bản như một nhân sự chính thức: từ tìm hiểu tổng quan về AWS, xây dựng nền tảng hạ tầng, đến thực hành hiện đại hóa ứng dụng và ứng dụng AI tạo sinh vào các bài toán thực tế. Chương trình bắt đầu bằng các tuần làm quen môi trường làm việc, nội quy, văn hóa đội nhóm và hệ thống đào tạo nội bộ; song song đó, tôi được hướng dẫn tạo và cấu hình tài khoản AWS Free Tier, cài đặt và sử dụng AWS CLI, làm quen với AWS Management Console và các nhóm dịch vụ cốt lõi như Compute, Storage, Networking, Database,… Thông qua các bài thực hành cơ bản với Amazon EC2 (tạo instance, SSH, quản lý EBS, Elastic IP), tôi xây dựng được nền tảng vững chắc về cách AWS tổ chức tài nguyên, phân quyền và vận hành hạ tầng trên cloud. Trên nền tảng đó, các tuần tiếp theo tập trung lần lượt vào thiết kế kiến trúc hạ tầng theo hướng chuẩn hóa (VPC, subnet, route, security group, kết nối riêng), quản lý chi phí và bảo mật theo định hướng AWS Well-Architected; sau đó chuyển dần sang khối nội dung về hiện đại hóa ứng dụng với kiến trúc serverless (AWS Lambda, Amazon API Gateway, Amazon DynamoDB, S3, Cognito) và thử nghiệm các dịch vụ AI/ML, đặc biệt là Amazon Bedrock với các mô hình như Claude cho các bài toán xây dựng trợ lý nội bộ, RAG và các kịch bản hỗ trợ nghiệp vụ. Song song với phần kỹ thuật, tôi duy trì Worklog chi tiết hằng tuần, viết proposal, dịch và tóm tắt nhiều bài blog kỹ thuật của AWS, tham gia workshop và các sự kiện như AWS Cloud Mastery Series,… qua đó rèn luyện thêm khả năng đọc hiểu tài liệu tiếng Anh, hệ thống hóa kiến thức và trình bày lại nội dung kỹ thuật cho người khác.\nVề mặt kỹ năng mềm và trải nghiệm môi trường làm việc, tôi được làm việc trong một môi trường rất thân thiện và cởi mở, nhận được sự hỗ trợ sát sao từ mentor và team admin; cách làm việc chú trọng “tự mình thử và giải quyết vấn đề” giúp tôi trưởng thành hơn trong tư duy kỹ thuật và tác phong chuyên nghiệp. Công việc được giao bám sát chuyên ngành Trí tuệ nhân tạo và điện toán đám mây, đồng thời mở rộng sang các kỹ năng thực tế như sử dụng công cụ quản lý công việc, làm việc nhóm, giao tiếp trong môi trường doanh nghiệp và viết tài liệu kỹ thuật. Sau 12 tuần, tôi không chỉ nắm vững hơn các dịch vụ cốt lõi của AWS và cách thiết kế, vận hành hệ thống trên cloud, mà còn hiểu rõ hơn quy trình làm việc, văn hóa và kỳ vọng trong một tổ chức công nghệ toàn cầu như AWS Việt Nam, tạo nền tảng tốt cho con đường phát triển sau này trong lĩnh vực Cloud \u0026amp; AI.\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ✅ ☐ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ☐ ✅ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ✅ ☐ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ✅ ☐ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ☐ ✅ ☐ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ☐ ✅ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ☐ ✅ ☐ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ✅ ☐ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ☐ ✅ ☐ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ✅ ☐ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ✅ ☐ ☐ Cần cải thiện Cải thiện trong cách tư duy giải quyết vấn đề, khả năng thích nghi và học hỏi. Học cách giao tiếp tốt hơn trong môi trường làm việc chuyên nghiệp, các kỹ năng mềm. "
},
{
	"uri": "//localhost:1313/vi/7-feedback/",
	"title": "Chia sẻ, đóng góp ý kiến",
	"tags": [],
	"description": "",
	"content": "Đánh giá chung 1. Môi trường làm việc\nMôi trường làm việc rất thân thiện và cởi mở. Các thành viên trong FCJ luôn sẵn sàng hỗ trợ khi mình gặp khó khăn, kể cả ngoài giờ làm việc. Không gian làm việc gọn gàng, thoải mái, giúp mình tập trung tốt hơn.\n2. Sự hỗ trợ của mentor / team admin\nMentor hướng dẫn rất chi tiết, giải thích rõ ràng khi mình chưa hiểu và luôn khuyến khích mình đặt câu hỏi.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nCông việc mình được giao phù hợp với kiến thức mình đã học ở trường, đồng thời mở rộng thêm những mảng mới mà mình chưa từng được tiếp cận. Nhờ vậy, mình vừa củng cố kiến thức nền tảng, vừa học thêm kỹ năng thực tế liên quan đến DevOps, Cloud.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nTrong quá trình thực tập, mình học được nhiều kỹ năng mới như sử dụng công cụ quản lý dự án, kỹ năng làm việc nhóm, và cả cách giao tiếp chuyên nghiệp trong môi trường công ty. Mentor cũng chia sẻ nhiều kinh nghiệm thực tế giúp mình định hướng tốt hơn cho sự nghiệp.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nVăn hóa công ty rất tích cực: mọi người tôn trọng lẫn nhau, làm việc nghiêm túc nhưng vẫn vui vẻ. Khi có dự án gấp, mọi người cùng nhau cố gắng, hỗ trợ không phân biệt vị trí. Điều này giúp mình cảm thấy mình là một phần của tập thể, dù chỉ là thực tập sinh.\n6. Chính sách / phúc lợi cho thực tập sinh\nCông ty có hỗ trợ phụ cấp thực tập và tạo điều kiện về thời gian linh hoạt khi cần thiết. Ngoài ra, việc được tham gia các buổi đào tạo nội bộ là một điểm cộng lớn.\n"
},
{
	"uri": "//localhost:1313/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]