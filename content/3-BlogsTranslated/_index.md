---
title: "Translated Blogs"
weight: 3
chapter: false
pre: " <b> 3. </b> "
---



### [Blog 1 - A Unified Multimodal Access Layer for Quora’s Poe Using Amazon Bedrock](3.1-Blog1/)

The article describes how the AWS Generative AI Innovation Center and Quora built a unified access layer for Poe to rapidly and reliably integrate multiple Amazon Bedrock models. Instead of implementing separate, bespoke integrations for each model (each with its own API, parameters, streaming mode, and authentication), they designed a “wrapper API framework” that acts as a Generative AI gateway: on the Poe side, it uses a real-time reactive architecture based on ServerSentEvents/WebSocket, while Amazon Bedrock uses REST + SigV4 in a request–response style, with the Converse API further standardizing conversational interface, parameters, multimodality, and memory. This framework addresses a wide range of architectural differences (transport protocols, authentication, response format, streaming, parameter normalization) via a sophisticated protocol translation layer and specialized services: a Bot Factory that automatically creates bots by model type (chat, image, video), a Service Manager that orchestrates tokens, streaming, error handling, and AWS calls, and an AWS service layer responsible for translating requests/responses between Poe and Bedrock (including Claude, Titan, Llama, Mistral…). The core of the solution is a configuration-driven architecture: each bot is just a BotConfig entry combining DEFAULT_CHAT_CONFIG with its own overrides (model_id, region, inference parameters, pricing, multimodal flags, etc.), so adding a new model only requires defining configuration rather than changing core code; at the same time, flags such as enable_image_comprehension, expand_text_attachments, and supports_system_messages allow extending multimodal capabilities or leveraging existing vision features while preserving a unified interface. Operationally, the framework is built on asynchronous processing, uses connection pooling with aiobotocore, retry with exponential backoff, detailed token accounting to optimize cost, standardized and user-friendly error messages, plus comprehensive logging and tracing for each request. From a security perspective, the system combines JWT authentication on the Poe side with SigV4 signing for Bedrock, centralized secret management via AWS Secrets Manager, and a safe connection cleanup mechanism. As a result, Poe can integrate more than 30 Bedrock models (text, image, video), cutting per-model deployment time from 2–3 days down to about 15 minutes, reducing code changes by 95%, and shifting engineers’ time from “API plumbing” to feature development. The article concludes that investing in a robust abstraction layer and configuration-driven architecture is key to rapidly expanding an AI model portfolio while maintaining efficiency, maintainability, and security.


---

### [Blog 2 - Streamline access to ISO-rating content changes with Verisk Rating Insights and Amazon Bedrock](3.2-Blog2/)

This blog describes how Verisk enhanced its ISO Electronic Rating Content (ERC) with a generative AI–powered conversational interface using Amazon Bedrock. It starts from customer pain points—manual downloads of full rating packages, slow comparison of releases, and heavy load on the ERC support team—and shows how Verisk built a Retrieval-Augmented Generation (RAG) system. Documents are chunked and embedded with the Amazon Titan embedding model, stored in Amazon OpenSearch Serverless as vector embeddings, and retrieved dynamically based on user queries. Anthropic Claude 3.5 Sonnet on Amazon Bedrock generates responses, while Amazon ElastiCache stores chat history and LlamaIndex orchestrates data sources. The post also covers evaluation loops, guardrails with Amazon Bedrock Guardrails, SME-driven quality metrics, and an analytics pipeline using Amazon S3 and Snowflake. Business results include cutting analysis time from hours or days to minutes, reducing support workload, speeding onboarding, and giving customers more accurate, explainable insights into rating content changes.


---

### [Blog 3 - How Poland’s Post Bank accelerated digital transformation while maintaining regulatory compliance on AWS](3.3-Blog3/)

This blog tells the story of how Poland’s Post Bank modernized its digital banking platforms on AWS while staying compliant with strict financial regulations. Starting with a cautious migration of a noncritical system in 2019, the bank gradually built cloud skills and confidence, then selected its electronic and mobile banking application as the flagship migration project. Using Terraform-based Infrastructure as Code, a hybrid architecture with redundant AWS Direct Connect links to the Europe (Frankfurt) Region, and a mix of 6R migration strategies (rehost, replatform, repurchase, etc.), the bank achieved predictable latency, high availability on Amazon RDS Multi-AZ, and scalable caching with Auto Scaling. The article highlights strong governance based on AWS Organizations, IAM Identity Center, SCPs, AWS Control Tower, and a hub-and-spoke network security model aligned to the AWS Well-Architected Framework and Security Reference Architecture. Measurable outcomes include reducing deployment time from 2 hours to 10 minutes, cutting CPU usage by 40%, shrinking environment provisioning from 30 days to 30 minutes, and lowering employee turnover from 30% to 5%. The bank now plans further migrations and has already deployed an internal AI assistant using Amazon Bedrock and Anthropic Claude 3.5 to search internal knowledge, demonstrating continuous innovation on a secure, compliant cloud foundation.
